---
layout: link
types: ["link"]
art_title: "â€œChatGPT killed my sonâ€: Parentsâ€™ lawsuit describes suicide notes in chat logs"
art_link: "https://arstechnica.com/tech-policy/2025/08/chatgpt-helped-teen-plan-suicide-after-safeguards-failed-openai-admits/"
sources: ["arstechnica.com"]
date: 2025-08-26T20:38:27-04:00
tags: ["OpenAI","generative AI","ChatGPT","AI"]
title: "ğŸ”— linkblog: â€œChatGPT killed my sonâ€: Parentsâ€™ lawsuit describes suicide notes in chat logs"
---
This is horrifying. Reading the headline is one thing, but reading some of the details is stomach-churning. I'm not a lawyer, and as disgusted as I am with this, I don't know what legal liability should look like here. I feel more comfortable describing this as ethically bankrupt, though. I think I would have many fewer concerns about generative AI if it weren't a platformized consumer product. Whatever the right legal response to this is, OpenAI has some moral responsibility for this sort of thing.