<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>36 M12A: Confidence Intervals | Introduction to Data Science</title>
  <meta name="description" content="36 M12A: Confidence Intervals | Introduction to Data Science" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="36 M12A: Confidence Intervals | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="36 M12A: Confidence Intervals | Introduction to Data Science" />
  
  
  

<meta name="author" content="Spencer P. Greenhalgh, PhD" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="m12u-confident-about-what.html"/>
<link rel="next" href="m12c-explore-confidence-intervals-with-your-own-data.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Home Page</a></li>
<li class="chapter" data-level="2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html"><i class="fa fa-check"></i><b>2</b> M1U: Course Syllabus</a>
<ul>
<li class="chapter" data-level="2.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course"><i class="fa fa-check"></i><b>2.1.1</b> Course</a></li>
<li class="chapter" data-level="2.1.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#instructor"><i class="fa fa-check"></i><b>2.1.2</b> Instructor</a></li>
<li class="chapter" data-level="2.1.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#contact-information"><i class="fa fa-check"></i><b>2.1.3</b> Contact Information</a></li>
<li class="chapter" data-level="2.1.4" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#response-time"><i class="fa fa-check"></i><b>2.1.4</b> Response Time</a></li>
<li class="chapter" data-level="2.1.5" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#office-hours"><i class="fa fa-check"></i><b>2.1.5</b> Office Hours</a></li>
<li class="chapter" data-level="2.1.6" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#meeting-schedule"><i class="fa fa-check"></i><b>2.1.6</b> Meeting Schedule</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#required-materials"><i class="fa fa-check"></i><b>2.2</b> Required Materials</a></li>
<li class="chapter" data-level="2.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#life-is-difficult-statement-inspired-by-dr.-andrew-heiss"><i class="fa fa-check"></i><b>2.3</b> “Life is Difficult” Statement [inspired by [Dr. Andrew Heiss]</a></li>
<li class="chapter" data-level="2.4" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#basic-needs-statement-inspired-by-dr.-sara-goldrick-rab"><i class="fa fa-check"></i><b>2.4</b> Basic Needs Statement [inspired by Dr. Sara Goldrick-Rab]</a></li>
<li class="chapter" data-level="2.5" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-information"><i class="fa fa-check"></i><b>2.5</b> Course Information</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-description"><i class="fa fa-check"></i><b>2.5.1</b> Course Description</a></li>
<li class="chapter" data-level="2.5.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-objectivesi-can-statements"><i class="fa fa-check"></i><b>2.5.2</b> Course Objectives—“I Can Statements”</a></li>
<li class="chapter" data-level="2.5.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-assessment"><i class="fa fa-check"></i><b>2.5.3</b> Course Assessment</a></li>
<li class="chapter" data-level="2.5.4" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#late-work-policy"><i class="fa fa-check"></i><b>2.5.4</b> Late Work Policy</a></li>
<li class="chapter" data-level="2.5.5" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#prep-week"><i class="fa fa-check"></i><b>2.5.5</b> Prep Week</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-policies"><i class="fa fa-check"></i><b>2.6</b> Course Policies</a></li>
<li class="chapter" data-level="2.7" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#plagiarism-cheating-and-generative-ai"><i class="fa fa-check"></i><b>2.7</b> Plagiarism, Cheating, and Generative AI</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#plagiarism-source"><i class="fa fa-check"></i><b>2.7.1</b> Plagiarism [source]</a></li>
<li class="chapter" data-level="2.7.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#cheating-source"><i class="fa fa-check"></i><b>2.7.2</b> Cheating [source]</a></li>
<li class="chapter" data-level="2.7.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#code-plagiarism-and-generative-ai"><i class="fa fa-check"></i><b>2.7.3</b> Code, Plagiarism, and Generative AI</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-schedule"><i class="fa fa-check"></i><b>2.8</b> Course Schedule</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-1-course-introduction-25-aug---31-aug"><i class="fa fa-check"></i><b>2.8.1</b> Module 1: Course Introduction (25 Aug - 31 Aug)</a></li>
<li class="chapter" data-level="2.8.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-2-data-science-1-sep---7-sep"><i class="fa fa-check"></i><b>2.8.2</b> Module 2: Data Science (1 Sep - 7 Sep)</a></li>
<li class="chapter" data-level="2.8.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-3-reproducibility-and-paradigms-8-sep-to-14-sep"><i class="fa fa-check"></i><b>2.8.3</b> Module 3: Reproducibility and Paradigms (8 Sep to 14 Sep)</a></li>
<li class="chapter" data-level="2.8.4" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-4-data-sharing-15-sep---21-sep"><i class="fa fa-check"></i><b>2.8.4</b> Module 4: Data Sharing (15 Sep - 21 Sep)</a></li>
<li class="chapter" data-level="2.8.5" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-5-theory-and-ethics-22-sep---28-sep"><i class="fa fa-check"></i><b>2.8.5</b> Module 5: Theory and Ethics (22 Sep - 28 Sep)</a></li>
<li class="chapter" data-level="2.8.6" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-6-data-cleaning-29-sep---5-oct"><i class="fa fa-check"></i><b>2.8.6</b> Module 6: Data Cleaning (29 Sep - 5 Oct)</a></li>
<li class="chapter" data-level="2.8.7" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-7-data-visualization-6-oct---12-oct"><i class="fa fa-check"></i><b>2.8.7</b> Module 7: Data Visualization (6 Oct - 12 Oct)</a></li>
<li class="chapter" data-level="2.8.8" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-8-descriptive-statistics-13-oct---19-oct"><i class="fa fa-check"></i><b>2.8.8</b> Module 8: Descriptive Statistics (13 Oct - 19 Oct)</a></li>
<li class="chapter" data-level="2.8.9" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-9-basic-regression-20-oct---26-oct"><i class="fa fa-check"></i><b>2.8.9</b> Module 9: Basic Regression (20 Oct - 26 Oct)</a></li>
<li class="chapter" data-level="2.8.10" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-10-multiple-regression-27-oct---2-nov"><i class="fa fa-check"></i><b>2.8.10</b> Module 10: Multiple Regression (27 Oct - 2 Nov)</a></li>
<li class="chapter" data-level="2.8.11" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-11-statistical-sampling-3-nov---9-nov"><i class="fa fa-check"></i><b>2.8.11</b> Module 11: Statistical Sampling (3 Nov - 9 Nov)</a></li>
<li class="chapter" data-level="2.8.12" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-12-confidence-intervals-10-nov---16-nov"><i class="fa fa-check"></i><b>2.8.12</b> Module 12: Confidence Intervals (10 Nov - 16 Nov)</a></li>
<li class="chapter" data-level="2.8.13" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-13-hypothesis-testing-17-nov---23-nov"><i class="fa fa-check"></i><b>2.8.13</b> Module 13: Hypothesis Testing (17 Nov - 23 Nov)</a></li>
<li class="chapter" data-level="2.8.14" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-14-inferential-regression-26-nov---30-nov"><i class="fa fa-check"></i><b>2.8.14</b> Module 14: Inferential Regression (26 Nov - 30 Nov)</a></li>
<li class="chapter" data-level="2.8.15" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-15-course-reflection-1-dec---7-dec"><i class="fa fa-check"></i><b>2.8.15</b> Module 15: Course Reflection (1 Dec - 7 Dec)</a></li>
<li class="chapter" data-level="2.8.16" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-16-final-project-8-dec---10-dec"><i class="fa fa-check"></i><b>2.8.16</b> Module 16: Final Project (8 Dec - 10 Dec)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html"><i class="fa fa-check"></i><b>3</b> M1A: Install R and RStudio</a>
<ul>
<li class="chapter" data-level="3.1" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html#r"><i class="fa fa-check"></i><b>3.2</b> R</a></li>
<li class="chapter" data-level="3.3" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html#rstudio"><i class="fa fa-check"></i><b>3.3</b> RStudio</a></li>
<li class="chapter" data-level="3.4" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html#references"><i class="fa fa-check"></i><b>3.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="m1c-introduce-yourself-to-the-class.html"><a href="m1c-introduce-yourself-to-the-class.html"><i class="fa fa-check"></i><b>4</b> M1C: Introduce Yourself to the Class</a></li>
<li class="chapter" data-level="5" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html"><i class="fa fa-check"></i><b>5</b> M2U: The New(?) and Shiny(?) Science of Data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#data-data-science-and-big-data"><i class="fa fa-check"></i><b>5.1</b> Data, Data Science, and Big Data</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#what-are-data"><i class="fa fa-check"></i><b>5.1.1</b> What Are Data?</a></li>
<li class="chapter" data-level="5.1.2" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#what-is-data-science"><i class="fa fa-check"></i><b>5.1.2</b> What Is Data Science?</a></li>
<li class="chapter" data-level="5.1.3" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#what-does-big-data-mean"><i class="fa fa-check"></i><b>5.1.3</b> What Does “Big Data” Mean?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#the-many-skills-of-data-science"><i class="fa fa-check"></i><b>5.2</b> The Many Skills of Data Science</a></li>
<li class="chapter" data-level="5.3" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#conclusion"><i class="fa fa-check"></i><b>5.3</b> Conclusion</a></li>
<li class="chapter" data-level="5.4" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#references-1"><i class="fa fa-check"></i><b>5.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html"><i class="fa fa-check"></i><b>6</b> M2A: Getting Started with Data in R</a>
<ul>
<li class="chapter" data-level="6.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#r-rstudio"><i class="fa fa-check"></i><b>6.1</b> What are R and RStudio?</a></li>
<li class="chapter" data-level="6.2" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#code"><i class="fa fa-check"></i><b>6.2</b> How do I code in R?</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#programming-concepts"><i class="fa fa-check"></i><b>6.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="6.2.2" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#messages"><i class="fa fa-check"></i><b>6.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="6.2.3" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#tips-code"><i class="fa fa-check"></i><b>6.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#packages"><i class="fa fa-check"></i><b>6.3</b> What are R packages?</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#package-installation"><i class="fa fa-check"></i><b>6.3.1</b> Package installation</a></li>
<li class="chapter" data-level="6.3.2" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#package-loading"><i class="fa fa-check"></i><b>6.3.2</b> Package loading</a></li>
<li class="chapter" data-level="6.3.3" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#package-use"><i class="fa fa-check"></i><b>6.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#nycflights"><i class="fa fa-check"></i><b>6.4</b> Explore your first datasets</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#nycflights23-package"><i class="fa fa-check"></i><b>6.4.1</b> <code>nycflights23</code> package</a></li>
<li class="chapter" data-level="6.4.2" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#flights-data-frame"><i class="fa fa-check"></i><b>6.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="6.4.3" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#exploredataframes"><i class="fa fa-check"></i><b>6.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="6.4.4" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>6.4.4</b> Identification and measurement variables</a></li>
<li class="chapter" data-level="6.4.5" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#help-files"><i class="fa fa-check"></i><b>6.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#conclusion-1"><i class="fa fa-check"></i><b>6.5</b> Conclusion</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#additional-resources"><i class="fa fa-check"></i><b>6.5.1</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html"><i class="fa fa-check"></i><b>7</b> M2C: Set up GitHub</a>
<ul>
<li class="chapter" data-level="7.1" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#gitand-githubin-data-science"><i class="fa fa-check"></i><b>7.2</b> Git—and GitHub—in Data Science</a></li>
<li class="chapter" data-level="7.3" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#github-in-ictlis-661"><i class="fa fa-check"></i><b>7.3</b> GitHub in ICT/LIS 661</a></li>
<li class="chapter" data-level="7.4" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#setting-up-github"><i class="fa fa-check"></i><b>7.4</b> Setting Up GitHub</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#creating-a-github-account"><i class="fa fa-check"></i><b>7.4.1</b> Creating a GitHub Account</a></li>
<li class="chapter" data-level="7.4.2" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#setting-up-a-github-repository-for-class"><i class="fa fa-check"></i><b>7.4.2</b> Setting up a GitHub Repository for Class</a></li>
<li class="chapter" data-level="7.4.3" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#installing-github-desktop"><i class="fa fa-check"></i><b>7.4.3</b> Installing GitHub Desktop</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#moving-forward"><i class="fa fa-check"></i><b>7.5</b> Moving Forward</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html"><i class="fa fa-check"></i><b>8</b> M3U: Research Paradigms and Reproducibility</a>
<ul>
<li class="chapter" data-level="8.1" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#introduction-2"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#reproducibility-and-paradigms"><i class="fa fa-check"></i><b>8.2</b> Reproducibility and Paradigms</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#an-example-paradigm"><i class="fa fa-check"></i><b>8.2.1</b> An Example Paradigm</a></li>
<li class="chapter" data-level="8.2.2" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#another-example-paradigm"><i class="fa fa-check"></i><b>8.2.2</b> Another Example Paradigm</a></li>
<li class="chapter" data-level="8.2.3" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#why-do-paradigms-matter"><i class="fa fa-check"></i><b>8.2.3</b> Why Do Paradigms Matter?</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#supporting-reproducibility"><i class="fa fa-check"></i><b>8.3</b> Supporting Reproducibility</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#open-design"><i class="fa fa-check"></i><b>8.3.1</b> Open Design</a></li>
<li class="chapter" data-level="8.3.2" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#open-analysis"><i class="fa fa-check"></i><b>8.3.2</b> Open Analysis</a></li>
<li class="chapter" data-level="8.3.3" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#open-publication"><i class="fa fa-check"></i><b>8.3.3</b> Open Publication</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#conclusion-2"><i class="fa fa-check"></i><b>8.4</b> Conclusion</a></li>
<li class="chapter" data-level="8.5" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#references-2"><i class="fa fa-check"></i><b>8.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html"><i class="fa fa-check"></i><b>9</b> M3A: Using Projects and Scripts in R</a>
<ul>
<li class="chapter" data-level="9.1" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#introduction-3"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#more-about-r-and-rstudio"><i class="fa fa-check"></i><b>9.2</b> More About R and RStudio</a></li>
<li class="chapter" data-level="9.3" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#the-console-and-the-workspace"><i class="fa fa-check"></i><b>9.3</b> The Console and the Workspace</a></li>
<li class="chapter" data-level="9.4" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#holding-onto-code"><i class="fa fa-check"></i><b>9.4</b> Holding Onto Code</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#rstudio-projects"><i class="fa fa-check"></i><b>9.4.1</b> RStudio Projects</a></li>
<li class="chapter" data-level="9.4.2" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#using-scripts"><i class="fa fa-check"></i><b>9.4.2</b> Using Scripts</a></li>
<li class="chapter" data-level="9.4.3" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#backing-up-your-project-folder"><i class="fa fa-check"></i><b>9.4.3</b> Backing Up Your Project Folder</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#conclusion-3"><i class="fa fa-check"></i><b>9.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html"><i class="fa fa-check"></i><b>10</b> M3C: Writing in R Markdown</a>
<ul>
<li class="chapter" data-level="10.1" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#introduction-4"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#markdown-syntax"><i class="fa fa-check"></i><b>10.2</b> Markdown syntax</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#inline-formatting"><i class="fa fa-check"></i><b>10.2.1</b> Inline formatting</a></li>
<li class="chapter" data-level="10.2.2" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#block-level-elements"><i class="fa fa-check"></i><b>10.2.2</b> Block-level elements</a></li>
<li class="chapter" data-level="10.2.3" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#r-code-chunks"><i class="fa fa-check"></i><b>10.2.3</b> R code chunks</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#trying-out-r-markdown"><i class="fa fa-check"></i><b>10.3</b> Trying out R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html"><i class="fa fa-check"></i><b>11</b> M4U: The Value of Open Data</a>
<ul>
<li class="chapter" data-level="11.1" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#introduction-5"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#positivism-and-the-need-for-data"><i class="fa fa-check"></i><b>11.2</b> Positivism and the Need for Data</a></li>
<li class="chapter" data-level="11.3" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#sharing-data"><i class="fa fa-check"></i><b>11.3</b> Sharing Data</a></li>
<li class="chapter" data-level="11.4" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#sharing-data-and-privacy"><i class="fa fa-check"></i><b>11.4</b> Sharing Data and Privacy</a></li>
<li class="chapter" data-level="11.5" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#how-to-share-data"><i class="fa fa-check"></i><b>11.5</b> How to Share Data</a></li>
<li class="chapter" data-level="11.6" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#benefits-of-sharing-data"><i class="fa fa-check"></i><b>11.6</b> Benefits of Sharing Data</a></li>
<li class="chapter" data-level="11.7" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#downsides-of-sharing-data"><i class="fa fa-check"></i><b>11.7</b> Downsides of Sharing Data</a></li>
<li class="chapter" data-level="11.8" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#incentives-for-sharing-data"><i class="fa fa-check"></i><b>11.8</b> Incentives for Sharing Data</a></li>
<li class="chapter" data-level="11.9" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#conclusion-4"><i class="fa fa-check"></i><b>11.9</b> Conclusion</a></li>
<li class="chapter" data-level="11.10" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#references-3"><i class="fa fa-check"></i><b>11.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html"><i class="fa fa-check"></i><b>12</b> M4A: Find a Dataset Relevant To You</a>
<ul>
<li class="chapter" data-level="12.1" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html#introduction-6"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html#signs-of-a-good-dataset"><i class="fa fa-check"></i><b>12.2</b> Signs of a Good Dataset</a></li>
<li class="chapter" data-level="12.3" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html#finding-a-good-dataset"><i class="fa fa-check"></i><b>12.3</b> Finding a Good Dataset</a></li>
<li class="chapter" data-level="12.4" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html#loading-dataset"><i class="fa fa-check"></i><b>12.4</b> Loading Your Dataset</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html"><i class="fa fa-check"></i><b>13</b> M4C: Show Your Work</a>
<ul>
<li class="chapter" data-level="13.1" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#introduction-7"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#invisible-labor"><i class="fa fa-check"></i><b>13.2</b> Invisible Labor</a></li>
<li class="chapter" data-level="13.3" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#the-invisible-labor-of-data-science"><i class="fa fa-check"></i><b>13.3</b> The Invisible Labor of Data Science</a></li>
<li class="chapter" data-level="13.4" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#time-and-money"><i class="fa fa-check"></i><b>13.4</b> Time and Money</a></li>
<li class="chapter" data-level="13.5" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#crediting-data-work"><i class="fa fa-check"></i><b>13.5</b> Crediting Data Work</a></li>
<li class="chapter" data-level="13.6" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#crediting-emotional-labor-and-care-work"><i class="fa fa-check"></i><b>13.6</b> Crediting Emotional Labor and Care Work</a></li>
<li class="chapter" data-level="13.7" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#show-your-work"><i class="fa fa-check"></i><b>13.7</b> Show Your Work</a></li>
<li class="chapter" data-level="13.8" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#references-4"><i class="fa fa-check"></i><b>13.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html"><i class="fa fa-check"></i><b>14</b> M5U: Numbers Don’t Speak for Themselves</a>
<ul>
<li class="chapter" data-level="14.1" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#introduction-8"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#bigger-is-not-always-better"><i class="fa fa-check"></i><b>14.2</b> Bigger is not Always Better</a></li>
<li class="chapter" data-level="14.3" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#theory"><i class="fa fa-check"></i><b>14.3</b> Theory</a></li>
<li class="chapter" data-level="14.4" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#the-importance-of-theory"><i class="fa fa-check"></i><b>14.4</b> The Importance of Theory</a></li>
<li class="chapter" data-level="14.5" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#research-isnt-just-empirical"><i class="fa fa-check"></i><b>14.5</b> Research isn’t Just Empirical</a></li>
<li class="chapter" data-level="14.6" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#the-importance-of-context"><i class="fa fa-check"></i><b>14.6</b> The Importance of Context</a></li>
<li class="chapter" data-level="14.7" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#conclusion-5"><i class="fa fa-check"></i><b>14.7</b> Conclusion</a></li>
<li class="chapter" data-level="14.8" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#references-5"><i class="fa fa-check"></i><b>14.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html"><i class="fa fa-check"></i><b>15</b> M5A: Are Ethics Enough in Data Science?</a>
<ul>
<li class="chapter" data-level="15.1" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#a-note-on-sources"><i class="fa fa-check"></i><b>15.1</b> A Note on Sources</a></li>
<li class="chapter" data-level="15.2" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#introduction-9"><i class="fa fa-check"></i><b>15.2</b> Introduction</a></li>
<li class="chapter" data-level="15.3" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#ethics-vs.-politics"><i class="fa fa-check"></i><b>15.3</b> Ethics vs. Politics</a></li>
<li class="chapter" data-level="15.4" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#why-politics"><i class="fa fa-check"></i><b>15.4</b> Why Politics?</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#argument-1-i-am-just-an-engineer"><i class="fa fa-check"></i><b>15.4.1</b> Argument 1: “I am Just an Engineer”</a></li>
<li class="chapter" data-level="15.4.2" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#argument-2-we-shouldnt-take-political-stances"><i class="fa fa-check"></i><b>15.4.2</b> Argument 2: “We Shouldn’t Take Political Stances”</a></li>
<li class="chapter" data-level="15.4.3" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#argument-3-dont-let-the-perfect-be-the-enemy-of-the-good"><i class="fa fa-check"></i><b>15.4.3</b> Argument 3: “Don’t Let the Perfect Be the Enemy of the Good”</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#conclusion-6"><i class="fa fa-check"></i><b>15.5</b> Conclusion</a></li>
<li class="chapter" data-level="15.6" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#references-6"><i class="fa fa-check"></i><b>15.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="m5c-reflect-on-theoretical-and-philosophical-constraints.html"><a href="m5c-reflect-on-theoretical-and-philosophical-constraints.html"><i class="fa fa-check"></i><b>16</b> M5C: Reflect on Theoretical and Philosophical Constraints</a></li>
<li class="chapter" data-level="17" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html"><i class="fa fa-check"></i><b>17</b> M6U: Unicorns, Janitors, and Rock Stars</a>
<ul>
<li class="chapter" data-level="17.1" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#introduction-10"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#intentionally-challenging-data-visualization"><i class="fa fa-check"></i><b>17.2</b> Intentionally Challenging Data Visualization</a></li>
<li class="chapter" data-level="17.3" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#sexy-scientists-and-drab-janitors"><i class="fa fa-check"></i><b>17.3</b> Sexy Scientists and… Drab Janitors?</a></li>
<li class="chapter" data-level="17.4" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#strangers-in-the-dataset"><i class="fa fa-check"></i><b>17.4</b> Strangers in the Dataset</a></li>
<li class="chapter" data-level="17.5" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#sharing-work-and-sharing-credit"><i class="fa fa-check"></i><b>17.5</b> Sharing Work and Sharing Credit</a></li>
<li class="chapter" data-level="17.6" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#conclusion-7"><i class="fa fa-check"></i><b>17.6</b> Conclusion</a></li>
<li class="chapter" data-level="17.7" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#references-7"><i class="fa fa-check"></i><b>17.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html"><i class="fa fa-check"></i><b>18</b> M6A: Wrangling and Tidying Data</a>
<ul>
<li class="chapter" data-level="18.1" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#introduction-11"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#wrangling"><i class="fa fa-check"></i><b>18.2</b> Wrangling</a>
<ul>
<li class="chapter" data-level="" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#wrangling-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="18.2.1" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#piping"><i class="fa fa-check"></i><b>18.2.1</b> The pipe operator: <code>|&gt;</code></a></li>
<li class="chapter" data-level="18.2.2" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#filter"><i class="fa fa-check"></i><b>18.2.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="18.2.3" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#mutate"><i class="fa fa-check"></i><b>18.2.3</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="18.2.4" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#arrange"><i class="fa fa-check"></i><b>18.2.4</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="18.2.5" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#joins"><i class="fa fa-check"></i><b>18.2.5</b> <code>join</code> data frames</a></li>
<li class="chapter" data-level="18.2.6" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#normal-forms"><i class="fa fa-check"></i><b>18.2.6</b> Normal forms</a></li>
<li class="chapter" data-level="18.2.7" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#other-verbs"><i class="fa fa-check"></i><b>18.2.7</b> Other verbs</a></li>
<li class="chapter" data-level="18.2.8" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>18.2.8</b> <code>top_n</code> values of a variable</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidying-data"><i class="fa fa-check"></i><b>18.3</b> Tidying Data</a>
<ul>
<li class="chapter" data-level="" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidy-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="18.3.1" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#csv"><i class="fa fa-check"></i><b>18.3.1</b> Importing data</a></li>
<li class="chapter" data-level="18.3.2" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidy-data-ex"><i class="fa fa-check"></i><b>18.3.2</b> “Tidy” data</a></li>
<li class="chapter" data-level="18.3.3" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidy-definition"><i class="fa fa-check"></i><b>18.3.3</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="18.3.4" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>18.3.4</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="18.3.5" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#case-study-tidy"><i class="fa fa-check"></i><b>18.3.5</b> Case study: Democracy in Guatemala</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidyverse-package"><i class="fa fa-check"></i><b>18.4</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="18.5" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#references-8"><i class="fa fa-check"></i><b>18.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="m6c-practice-wrangling-and-tidying-your-own-data.html"><a href="m6c-practice-wrangling-and-tidying-your-own-data.html"><i class="fa fa-check"></i><b>19</b> M6C: Practice Wrangling and Tidying Your Own Data</a></li>
<li class="chapter" data-level="20" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html"><i class="fa fa-check"></i><b>20</b> M7U: Subjectivity in Data Visualization</a>
<ul>
<li class="chapter" data-level="20.1" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#introduction-12"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#persuasion-and-the-god-trick"><i class="fa fa-check"></i><b>20.2</b> Persuasion and the God Trick</a></li>
<li class="chapter" data-level="20.3" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#visualization-as-rhetoric"><i class="fa fa-check"></i><b>20.3</b> Visualization as Rhetoric</a></li>
<li class="chapter" data-level="20.4" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#editorial-choices-in-visualization"><i class="fa fa-check"></i><b>20.4</b> Editorial Choices in Visualization</a></li>
<li class="chapter" data-level="20.5" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#visualization-as-ideological-work"><i class="fa fa-check"></i><b>20.5</b> Visualization as Ideological Work</a></li>
<li class="chapter" data-level="20.6" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#feminist-objectivity"><i class="fa fa-check"></i><b>20.6</b> Feminist Objectivity</a></li>
<li class="chapter" data-level="20.7" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#data-visceralization"><i class="fa fa-check"></i><b>20.7</b> Data Visceralization</a></li>
<li class="chapter" data-level="20.8" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#conclusion-8"><i class="fa fa-check"></i><b>20.8</b> Conclusion</a></li>
<li class="chapter" data-level="20.9" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#references-9"><i class="fa fa-check"></i><b>20.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html"><i class="fa fa-check"></i><b>21</b> M7A: Data Visualization</a>
<ul>
<li class="chapter" data-level="21.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#introduction-13"><i class="fa fa-check"></i><b>21.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#grammarofgraphics"><i class="fa fa-check"></i><b>21.2</b> The grammar of graphics</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#components-of-the-grammar"><i class="fa fa-check"></i><b>21.2.1</b> Components of the grammar</a></li>
<li class="chapter" data-level="21.2.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#gapminder"><i class="fa fa-check"></i><b>21.2.2</b> Gapminder data</a></li>
<li class="chapter" data-level="21.2.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#other-components"><i class="fa fa-check"></i><b>21.2.3</b> Other components</a></li>
<li class="chapter" data-level="21.2.4" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#ggplot2-package"><i class="fa fa-check"></i><b>21.2.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#FiveNG"><i class="fa fa-check"></i><b>21.3</b> Five named graphs - the 5NG</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geompoint"><i class="fa fa-check"></i><b>21.3.1</b> Scatterplots via <code>geom_point</code></a></li>
<li class="chapter" data-level="21.3.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#overplotting"><i class="fa fa-check"></i><b>21.3.2</b> Overplotting</a></li>
<li class="chapter" data-level="21.3.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary"><i class="fa fa-check"></i><b>21.3.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#linegraphs"><i class="fa fa-check"></i><b>21.4</b> 5NG#2: Linegraphs</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geomline"><i class="fa fa-check"></i><b>21.4.1</b> Linegraphs via <code>geom_line</code></a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#histograms"><i class="fa fa-check"></i><b>21.5</b> 5NG#3: Histograms</a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geomhistogram"><i class="fa fa-check"></i><b>21.5.1</b> Histograms via <code>geom_histogram</code></a></li>
<li class="chapter" data-level="21.5.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#adjustbins"><i class="fa fa-check"></i><b>21.5.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="21.5.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary-1"><i class="fa fa-check"></i><b>21.5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#facets"><i class="fa fa-check"></i><b>21.6</b> Facets</a></li>
<li class="chapter" data-level="21.7" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#boxplots"><i class="fa fa-check"></i><b>21.7</b> 5NG#4: Boxplots</a>
<ul>
<li class="chapter" data-level="21.7.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geomboxplot"><i class="fa fa-check"></i><b>21.7.1</b> Boxplots via <code>geom_boxplot</code></a></li>
<li class="chapter" data-level="21.7.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary-2"><i class="fa fa-check"></i><b>21.7.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="21.8" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geombar"><i class="fa fa-check"></i><b>21.8</b> 5NG#5: Barplots</a>
<ul>
<li class="chapter" data-level="21.8.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>21.8.1</b> Barplots via <code>geom_bar</code> or <code>geom_col</code></a></li>
<li class="chapter" data-level="21.8.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#avoid-pie-charts"><i class="fa fa-check"></i><b>21.8.2</b> Avoid pie charts!</a></li>
<li class="chapter" data-level="21.8.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#two-categ-barplot"><i class="fa fa-check"></i><b>21.8.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="21.8.4" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary-3"><i class="fa fa-check"></i><b>21.8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="21.9" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#data-vis-conclusion"><i class="fa fa-check"></i><b>21.9</b> Conclusion</a>
<ul>
<li class="chapter" data-level="21.9.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary-table"><i class="fa fa-check"></i><b>21.9.1</b> Summary table</a></li>
<li class="chapter" data-level="21.9.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#function-argument-specification"><i class="fa fa-check"></i><b>21.9.2</b> Function argument specification</a></li>
<li class="chapter" data-level="21.9.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#additional-resources-1"><i class="fa fa-check"></i><b>21.9.3</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="21.10" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#references-10"><i class="fa fa-check"></i><b>21.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="m7c-practice-visualizing-your-own-data.html"><a href="m7c-practice-visualizing-your-own-data.html"><i class="fa fa-check"></i><b>22</b> M7C: Practice Visualizing Your Own Data</a></li>
<li class="chapter" data-level="23" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html"><i class="fa fa-check"></i><b>23</b> M8U: Statistics and Scientific Racism</a>
<ul>
<li class="chapter" data-level="23.1" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#introduction-14"><i class="fa fa-check"></i><b>23.1</b> Introduction</a></li>
<li class="chapter" data-level="23.2" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#the-origins-of-statistics"><i class="fa fa-check"></i><b>23.2</b> The Origins of Statistics</a></li>
<li class="chapter" data-level="23.3" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#the-importance-of-statistical-humility"><i class="fa fa-check"></i><b>23.3</b> The Importance of Statistical Humility</a></li>
<li class="chapter" data-level="23.4" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#eugenics-a-failure-of-statistical-humility"><i class="fa fa-check"></i><b>23.4</b> Eugenics: A Failure of Statistical Humility</a></li>
<li class="chapter" data-level="23.5" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#the-continuing-legacy-of-eugenics-and-scientific-racism"><i class="fa fa-check"></i><b>23.5</b> The Continuing Legacy of Eugenics and Scientific Racism</a></li>
<li class="chapter" data-level="23.6" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#conclusion-9"><i class="fa fa-check"></i><b>23.6</b> Conclusion</a></li>
<li class="chapter" data-level="23.7" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#references-11"><i class="fa fa-check"></i><b>23.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html"><i class="fa fa-check"></i><b>24</b> M8A: Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="24.1" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#introduction-15"><i class="fa fa-check"></i><b>24.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#wrangling-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#summarize"><i class="fa fa-check"></i><b>24.2</b> <code>summarize</code> variables</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#mean"><i class="fa fa-check"></i><b>24.2.1</b> Mean</a></li>
<li class="chapter" data-level="24.2.2" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#standard-deviation"><i class="fa fa-check"></i><b>24.2.2</b> Standard Deviation</a></li>
<li class="chapter" data-level="24.2.3" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#calculating-mean-with-mean-and-standard-deviation-with-sd"><i class="fa fa-check"></i><b>24.2.3</b> Calculating Mean with <code>mean()</code> and Standard Deviation with <code>sd()</code></a></li>
<li class="chapter" data-level="24.2.4" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#percentiles-quartiles-and-iqr"><i class="fa fa-check"></i><b>24.2.4</b> Percentiles, Quartiles and <code>IQR()</code></a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#groupby"><i class="fa fa-check"></i><b>24.3</b> <code>group_by</code> rows</a></li>
<li class="chapter" data-level="24.4" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#conclusion-10"><i class="fa fa-check"></i><b>24.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="m8c-calculate-descriptive-statistics-for-your-own-data.html"><a href="m8c-calculate-descriptive-statistics-for-your-own-data.html"><i class="fa fa-check"></i><b>25</b> M8C: Calculate Descriptive Statistics for Your Own Data</a></li>
<li class="chapter" data-level="26" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html"><i class="fa fa-check"></i><b>26</b> M9U: Linear Regression</a>
<ul>
<li class="chapter" data-level="26.1" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#introduction-16"><i class="fa fa-check"></i><b>26.1</b> Introduction</a></li>
<li class="chapter" data-level="26.2" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#linear-equations"><i class="fa fa-check"></i><b>26.2</b> Linear Equations</a></li>
<li class="chapter" data-level="26.3" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#linear-relationships-and-scatterplots"><i class="fa fa-check"></i><b>26.3</b> Linear Relationships and Scatterplots</a></li>
<li class="chapter" data-level="26.4" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#the-regression-equation"><i class="fa fa-check"></i><b>26.4</b> The Regression Equation</a></li>
<li class="chapter" data-level="26.5" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#least-squares-criteria-for-best-fit"><i class="fa fa-check"></i><b>26.5</b> Least Squares Criteria for Best Fit</a></li>
<li class="chapter" data-level="26.6" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#correlation-coefficients"><i class="fa fa-check"></i><b>26.6</b> Correlation Coefficients</a></li>
<li class="chapter" data-level="26.7" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#conclusion-11"><i class="fa fa-check"></i><b>26.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html"><i class="fa fa-check"></i><b>27</b> M9A: Basic Regression</a>
<ul>
<li class="chapter" data-level="27.1" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#introduction-17"><i class="fa fa-check"></i><b>27.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#reg-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="27.2" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model1"><i class="fa fa-check"></i><b>27.2</b> One numerical explanatory variable</a>
<ul>
<li class="chapter" data-level="27.2.1" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model1EDA"><i class="fa fa-check"></i><b>27.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="27.2.2" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model1table"><i class="fa fa-check"></i><b>27.2.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="27.2.3" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model1points"><i class="fa fa-check"></i><b>27.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model2"><i class="fa fa-check"></i><b>27.3</b> One categorical explanatory variable</a>
<ul>
<li class="chapter" data-level="27.3.1" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model2EDA"><i class="fa fa-check"></i><b>27.3.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="27.3.2" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model2table"><i class="fa fa-check"></i><b>27.3.2</b> Linear regression</a></li>
<li class="chapter" data-level="27.3.3" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model2points"><i class="fa fa-check"></i><b>27.3.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#reg-related-topics"><i class="fa fa-check"></i><b>27.4</b> Related topics</a>
<ul>
<li class="chapter" data-level="27.4.1" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#correlation-is-not-causation"><i class="fa fa-check"></i><b>27.4.1</b> Correlation is not necessarily causation</a></li>
<li class="chapter" data-level="27.4.2" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#leastsquares"><i class="fa fa-check"></i><b>27.4.2</b> Best-fitting line</a></li>
<li class="chapter" data-level="27.4.3" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#underthehood"><i class="fa fa-check"></i><b>27.4.3</b> get_regression_x() functions</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#reg-conclusion"><i class="fa fa-check"></i><b>27.5</b> Conclusion</a></li>
<li class="chapter" data-level="27.6" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#references-12"><i class="fa fa-check"></i><b>27.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="m9c-perform-a-basic-regression-with-your-own-data.html"><a href="m9c-perform-a-basic-regression-with-your-own-data.html"><i class="fa fa-check"></i><b>28</b> M9C: Perform a Basic Regression With Your Own Data</a></li>
<li class="chapter" data-level="29" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html"><i class="fa fa-check"></i><b>29</b> M10U: Consequences of Failed Predictions</a>
<ul>
<li class="chapter" data-level="29.1" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#introduction-18"><i class="fa fa-check"></i><b>29.1</b> Introduction</a></li>
<li class="chapter" data-level="29.2" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#regression-and-automated-content-moderation"><i class="fa fa-check"></i><b>29.2</b> Regression and Automated Content Moderation</a></li>
<li class="chapter" data-level="29.3" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#the-problem-with-automated-content-moderation"><i class="fa fa-check"></i><b>29.3</b> The Problem with Automated Content Moderation</a></li>
<li class="chapter" data-level="29.4" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#an-example-from-instagram"><i class="fa fa-check"></i><b>29.4</b> An Example from Instagram</a></li>
<li class="chapter" data-level="29.5" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#conclusion-12"><i class="fa fa-check"></i><b>29.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html"><i class="fa fa-check"></i><b>30</b> M10A: Multiple Regression</a>
<ul>
<li class="chapter" data-level="" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#mult-reg-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="30.1" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4"><i class="fa fa-check"></i><b>30.1</b> One numerical and one categorical explanatory variable</a>
<ul>
<li class="chapter" data-level="30.1.1" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>30.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="30.1.2" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>30.1.2</b> Model with interactions</a></li>
<li class="chapter" data-level="30.1.3" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>30.1.3</b> Model without interactions</a></li>
<li class="chapter" data-level="30.1.4" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>30.1.4</b> Observed responses, fitted values, and residuals</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model3"><i class="fa fa-check"></i><b>30.2</b> Two numerical explanatory variables</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>30.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="30.2.2" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>30.2.2</b> Multiple regression with two numerical regressors</a></li>
<li class="chapter" data-level="30.2.3" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>30.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#mult-reg-conclusion"><i class="fa fa-check"></i><b>30.3</b> Conclusion</a></li>
<li class="chapter" data-level="30.4" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#references-13"><i class="fa fa-check"></i><b>30.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="m10c-perform-a-multiple-regression-with-your-own-data.html"><a href="m10c-perform-a-multiple-regression-with-your-own-data.html"><i class="fa fa-check"></i><b>31</b> M10C: Perform a Multiple Regression With Your Own Data</a></li>
<li class="chapter" data-level="32" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html"><i class="fa fa-check"></i><b>32</b> M11U: Samples and Populations</a>
<ul>
<li class="chapter" data-level="32.1" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#introduction-19"><i class="fa fa-check"></i><b>32.1</b> Introduction</a></li>
<li class="chapter" data-level="32.2" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#samples"><i class="fa fa-check"></i><b>32.2</b> Samples</a>
<ul>
<li class="chapter" data-level="32.2.1" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#variation-in-samples"><i class="fa fa-check"></i><b>32.2.1</b> Variation in Samples</a></li>
<li class="chapter" data-level="32.2.2" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#sample-sizes"><i class="fa fa-check"></i><b>32.2.2</b> Sample Sizes</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#probability"><i class="fa fa-check"></i><b>32.3</b> Probability</a></li>
<li class="chapter" data-level="32.4" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#expected-values-and-the-law-of-large-numbers"><i class="fa fa-check"></i><b>32.4</b> Expected Values and the Law of Large Numbers</a></li>
<li class="chapter" data-level="32.5" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#probability-and-sampling"><i class="fa fa-check"></i><b>32.5</b> Probability and Sampling</a></li>
<li class="chapter" data-level="32.6" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#probability-and-the-normal-distribution"><i class="fa fa-check"></i><b>32.6</b> Probability and the Normal Distribution</a></li>
<li class="chapter" data-level="32.7" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#conclusion-13"><i class="fa fa-check"></i><b>32.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="m11a-sampling.html"><a href="m11a-sampling.html"><i class="fa fa-check"></i><b>33</b> M11A: Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="33.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>33.1</b> First activity: red balls</a>
<ul>
<li class="chapter" data-level="33.1.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#population-proportion"><i class="fa fa-check"></i><b>33.1.1</b> The proportion of red balls in the bowl</a></li>
<li class="chapter" data-level="33.1.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-manual"><i class="fa fa-check"></i><b>33.1.2</b> Manual sampling</a></li>
<li class="chapter" data-level="33.1.3" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>33.1.3</b> Virtual sampling</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>33.2</b> Sampling framework</a>
<ul>
<li class="chapter" data-level="33.2.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>33.2.1</b> Population, sample, and the sampling distribution</a></li>
</ul></li>
<li class="chapter" data-level="33.3" data-path="m11a-sampling.html"><a href="m11a-sampling.html#central-limit-theorem"><i class="fa fa-check"></i><b>33.3</b> The Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#random-variables"><i class="fa fa-check"></i><b>33.3.1</b> Random variables</a></li>
<li class="chapter" data-level="33.3.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#the-sampling-distribution-using-random-variables"><i class="fa fa-check"></i><b>33.3.2</b> The sampling distribution using random variables</a></li>
<li class="chapter" data-level="33.3.3" data-path="m11a-sampling.html"><a href="m11a-sampling.html#the-center-of-the-distribution-the-expected-value"><i class="fa fa-check"></i><b>33.3.3</b> The center of the distribution: the expected value</a></li>
<li class="chapter" data-level="33.3.4" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-variation"><i class="fa fa-check"></i><b>33.3.4</b> Sampling variation: standard deviation and standard error</a></li>
<li class="chapter" data-level="33.3.5" data-path="m11a-sampling.html"><a href="m11a-sampling.html#summary-4"><i class="fa fa-check"></i><b>33.3.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-activity-mean"><i class="fa fa-check"></i><b>33.4</b> Second activity: chocolate-covered almonds</a>
<ul>
<li class="chapter" data-level="33.4.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#population-mean"><i class="fa fa-check"></i><b>33.4.1</b> The population mean weight of almonds in the bowl</a></li>
<li class="chapter" data-level="33.4.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#resampling-tactile-bowl"><i class="fa fa-check"></i><b>33.4.2</b> Manual sampling and sample means</a></li>
<li class="chapter" data-level="33.4.3" data-path="m11a-sampling.html"><a href="m11a-sampling.html#virtual-samples-mean-bowl"><i class="fa fa-check"></i><b>33.4.3</b> Virtual sampling</a></li>
<li class="chapter" data-level="33.4.4" data-path="m11a-sampling.html"><a href="m11a-sampling.html#the-sampling-distribution-of-the-sample-mean"><i class="fa fa-check"></i><b>33.4.4</b> The sampling distribution of the sample mean</a></li>
<li class="chapter" data-level="33.4.5" data-path="m11a-sampling.html"><a href="m11a-sampling.html#random-variable-sample-mean"><i class="fa fa-check"></i><b>33.4.5</b> Random variables</a></li>
<li class="chapter" data-level="33.4.6" data-path="m11a-sampling.html"><a href="m11a-sampling.html#CLT-mean"><i class="fa fa-check"></i><b>33.4.6</b> The Central Limit Theorem revisited</a></li>
</ul></li>
<li class="chapter" data-level="33.5" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-other-scenarios"><i class="fa fa-check"></i><b>33.5</b> The sampling distribution in other scenarios</a>
<ul>
<li class="chapter" data-level="33.5.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-distribution-for-two-samples"><i class="fa fa-check"></i><b>33.5.1</b> Sampling distribution for two samples</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-final-remarks"><i class="fa fa-check"></i><b>33.6</b> Summary and final remarks</a>
<ul>
<li class="chapter" data-level="33.6.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#summary-of-scenarios"><i class="fa fa-check"></i><b>33.6.1</b> Summary of scenarios</a></li>
<li class="chapter" data-level="33.6.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#whats-to-come"><i class="fa fa-check"></i><b>33.6.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="34" data-path="m11c-explore-sampling-with-your-own-data.html"><a href="m11c-explore-sampling-with-your-own-data.html"><i class="fa fa-check"></i><b>34</b> M11C: Explore Sampling With Your Own Data</a></li>
<li class="chapter" data-level="35" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html"><i class="fa fa-check"></i><b>35</b> M12U: Confident About What?</a>
<ul>
<li class="chapter" data-level="35.1" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html#introduction-20"><i class="fa fa-check"></i><b>35.1</b> Introduction</a></li>
<li class="chapter" data-level="35.2" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html#travelingwhiletrans"><i class="fa fa-check"></i><b>35.2</b> #TravelingWhileTrans</a></li>
<li class="chapter" data-level="35.3" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html#conclusion-14"><i class="fa fa-check"></i><b>35.3</b> Conclusion</a></li>
<li class="chapter" data-level="35.4" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html#references-14"><i class="fa fa-check"></i><b>35.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="36" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>36</b> M12A: Confidence Intervals</a>
<ul>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#CI-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="36.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#theory-based-CI"><i class="fa fa-check"></i><b>36.1</b> Tying the sampling distribution to estimation</a>
<ul>
<li class="chapter" data-level="36.1.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#revisit-almond"><i class="fa fa-check"></i><b>36.1.1</b> Revisiting the almond activity for estimation</a></li>
<li class="chapter" data-level="36.1.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#the-normal-distribution"><i class="fa fa-check"></i><b>36.1.2</b> The normal distribution</a></li>
<li class="chapter" data-level="36.1.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#CI-general"><i class="fa fa-check"></i><b>36.1.3</b> The confidence interval</a></li>
<li class="chapter" data-level="36.1.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#t-distribution-CI"><i class="fa fa-check"></i><b>36.1.4</b> The t distribution</a></li>
<li class="chapter" data-level="36.1.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#interpreting-confidence-intervals"><i class="fa fa-check"></i><b>36.1.5</b> Interpreting confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#simulation-based-CI"><i class="fa fa-check"></i><b>36.2</b> Estimation with the bootstrap</a>
<ul>
<li class="chapter" data-level="36.2.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#revisit-almond-bootstrap"><i class="fa fa-check"></i><b>36.2.1</b> Bootstrap samples: revisiting the almond activity</a></li>
<li class="chapter" data-level="36.2.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#bootstrap-process"><i class="fa fa-check"></i><b>36.2.2</b> Confidence intervals and the bootstrap: original workflow</a></li>
<li class="chapter" data-level="36.2.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#infer-workflow"><i class="fa fa-check"></i><b>36.2.3</b> The <code>infer</code> package workflow:</a></li>
<li class="chapter" data-level="36.2.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#conf-int-infer"><i class="fa fa-check"></i><b>36.2.4</b> Confidence intervals using bootstrap samples with <code>infer</code></a></li>
</ul></li>
<li class="chapter" data-level="36.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>36.3</b> Case study: is yawning contagious?</a>
<ul>
<li class="chapter" data-level="36.3.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#mythbusters-study-data"><i class="fa fa-check"></i><b>36.3.1</b> <em>Mythbusters</em> study data</a></li>
<li class="chapter" data-level="36.3.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#sampling-scenario"><i class="fa fa-check"></i><b>36.3.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="36.3.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ci-build"><i class="fa fa-check"></i><b>36.3.3</b> Constructing the confidence interval</a></li>
<li class="chapter" data-level="36.3.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#interpreting-the-confidence-interval"><i class="fa fa-check"></i><b>36.3.4</b> Interpreting the confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="36.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#summary-CI"><i class="fa fa-check"></i><b>36.4</b> Summary and final remarks</a>
<ul>
<li class="chapter" data-level="36.4.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#additional-resources-2"><i class="fa fa-check"></i><b>36.4.1</b> Additional resources</a></li>
<li class="chapter" data-level="36.4.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#whats-to-come-1"><i class="fa fa-check"></i><b>36.4.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="37" data-path="m12c-explore-confidence-intervals-with-your-own-data.html"><a href="m12c-explore-confidence-intervals-with-your-own-data.html"><i class="fa fa-check"></i><b>37</b> M12C: Explore Confidence Intervals With Your Own Data</a></li>
<li class="chapter" data-level="38" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html"><i class="fa fa-check"></i><b>38</b> M13U: The Dangers of False Positives</a>
<ul>
<li class="chapter" data-level="38.1" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#introduction-21"><i class="fa fa-check"></i><b>38.1</b> Introduction</a></li>
<li class="chapter" data-level="38.2" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#the-dartmouth-cheating-scandal"><i class="fa fa-check"></i><b>38.2</b> The Dartmouth Cheating Scandal</a></li>
<li class="chapter" data-level="38.3" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#what-was-wrong-with-dartmouths-investigation"><i class="fa fa-check"></i><b>38.3</b> What Was Wrong With Dartmouth’s Investigation</a></li>
<li class="chapter" data-level="38.4" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#investigations-of-students-must-start-with-concrete-evidence"><i class="fa fa-check"></i><b>38.4</b> Investigations of Students Must Start With Concrete Evidence</a></li>
<li class="chapter" data-level="38.5" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#a-problem-with-companies-and-transparency"><i class="fa fa-check"></i><b>38.5</b> A Problem with Companies and Transparency</a></li>
<li class="chapter" data-level="38.6" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#not-just-dartmouth"><i class="fa fa-check"></i><b>38.6</b> Not Just Dartmouth</a></li>
<li class="chapter" data-level="38.7" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#conclusion-15"><i class="fa fa-check"></i><b>38.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html"><i class="fa fa-check"></i><b>39</b> M13: Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="39.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#introduction-22"><i class="fa fa-check"></i><b>39.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#nhst-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="39.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-activity"><i class="fa fa-check"></i><b>39.2</b> Promotions activity</a>
<ul>
<li class="chapter" data-level="39.2.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#does-gender-affect-promotions-at-a-bank"><i class="fa fa-check"></i><b>39.2.1</b> Does gender affect promotions at a bank?</a></li>
<li class="chapter" data-level="39.2.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#shuffling-once"><i class="fa fa-check"></i><b>39.2.2</b> Shuffling once</a></li>
<li class="chapter" data-level="39.2.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#shuffling-16-times"><i class="fa fa-check"></i><b>39.2.3</b> Shuffling 16 times</a></li>
<li class="chapter" data-level="39.2.4" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-what-did-we-just-do"><i class="fa fa-check"></i><b>39.2.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="39.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#understanding-ht"><i class="fa fa-check"></i><b>39.3</b> Understanding hypothesis tests</a></li>
<li class="chapter" data-level="39.4" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-infer"><i class="fa fa-check"></i><b>39.4</b> Conducting hypothesis tests</a>
<ul>
<li class="chapter" data-level="39.4.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#infer-workflow-ht"><i class="fa fa-check"></i><b>39.4.1</b> <code>infer</code> package workflow</a></li>
<li class="chapter" data-level="39.4.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#comparing-infer-workflows"><i class="fa fa-check"></i><b>39.4.2</b> Comparison with confidence intervals</a></li>
<li class="chapter" data-level="39.4.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#only-one-test"><i class="fa fa-check"></i><b>39.4.3</b> “There is only one test”</a></li>
</ul></li>
<li class="chapter" data-level="39.5" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-interpretation"><i class="fa fa-check"></i><b>39.5</b> Interpreting hypothesis tests</a>
<ul>
<li class="chapter" data-level="39.5.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#trial"><i class="fa fa-check"></i><b>39.5.1</b> Two possible outcomes</a></li>
<li class="chapter" data-level="39.5.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#types-of-errors"><i class="fa fa-check"></i><b>39.5.2</b> Types of errors</a></li>
<li class="chapter" data-level="39.5.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#choosing-alpha"><i class="fa fa-check"></i><b>39.5.3</b> How do we choose alpha?</a></li>
</ul></li>
<li class="chapter" data-level="39.6" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-case-study"><i class="fa fa-check"></i><b>39.6</b> Case study: Are action or romance movies rated higher?</a>
<ul>
<li class="chapter" data-level="39.6.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#imdb-data"><i class="fa fa-check"></i><b>39.6.1</b> IMDb ratings data</a></li>
<li class="chapter" data-level="39.6.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#sampling-scenario-1"><i class="fa fa-check"></i><b>39.6.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="39.6.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#conducting-the-hypothesis-test"><i class="fa fa-check"></i><b>39.6.3</b> Conducting the hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="39.7" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#nhst-conclusion"><i class="fa fa-check"></i><b>39.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="m13c-explore-hypothesis-testing-with-your-own-data.html"><a href="m13c-explore-hypothesis-testing-with-your-own-data.html"><i class="fa fa-check"></i><b>40</b> M13C: Explore Hypothesis Testing With Your Own Data</a></li>
<li class="chapter" data-level="41" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html"><i class="fa fa-check"></i><b>41</b> M14U: Small Stories vs. Big Data</a>
<ul>
<li class="chapter" data-level="41.1" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#introduction-23"><i class="fa fa-check"></i><b>41.1</b> Introduction</a></li>
<li class="chapter" data-level="41.2" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#the-origins-of-autoethnography"><i class="fa fa-check"></i><b>41.2</b> The Origins of Autoethnography</a></li>
<li class="chapter" data-level="41.3" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#what-does-autoethnography-look-like"><i class="fa fa-check"></i><b>41.3</b> What does Autoethnography Look Like?</a></li>
<li class="chapter" data-level="41.4" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#how-do-autoethnographers-measure-quality"><i class="fa fa-check"></i><b>41.4</b> How do Autoethnographers Measure Quality?</a></li>
<li class="chapter" data-level="41.5" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#conclusion-16"><i class="fa fa-check"></i><b>41.5</b> Conclusion</a></li>
<li class="chapter" data-level="41.6" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#references-15"><i class="fa fa-check"></i><b>41.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="42" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html"><i class="fa fa-check"></i><b>42</b> M14A: Inferential Regression</a>
<ul>
<li class="chapter" data-level="42.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#introduction-24"><i class="fa fa-check"></i><b>42.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#inf-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-refresher"><i class="fa fa-check"></i><b>42.2</b> Regression refresher</a>
<ul>
<li class="chapter" data-level="42.2.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#teaching-evaluations-analysis"><i class="fa fa-check"></i><b>42.2.1</b> Teaching evaluations analysis</a></li>
<li class="chapter" data-level="42.2.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#sampling-scenario-2"><i class="fa fa-check"></i><b>42.2.2</b> Sampling scenario</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-interp"><i class="fa fa-check"></i><b>42.3</b> Interpreting regression tables</a>
<ul>
<li class="chapter" data-level="42.3.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-se"><i class="fa fa-check"></i><b>42.3.1</b> Standard error</a></li>
<li class="chapter" data-level="42.3.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-test-statistic"><i class="fa fa-check"></i><b>42.3.2</b> Test statistic</a></li>
<li class="chapter" data-level="42.3.3" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#p-value"><i class="fa fa-check"></i><b>42.3.3</b> p-value</a></li>
<li class="chapter" data-level="42.3.4" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#confidence-interval"><i class="fa fa-check"></i><b>42.3.4</b> Confidence interval</a></li>
<li class="chapter" data-level="42.3.5" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-table-computation"><i class="fa fa-check"></i><b>42.3.5</b> How does R compute the table?</a></li>
</ul></li>
<li class="chapter" data-level="42.4" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-conditions"><i class="fa fa-check"></i><b>42.4</b> Conditions for inference for regression</a>
<ul>
<li class="chapter" data-level="42.4.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#residuals-refresher"><i class="fa fa-check"></i><b>42.4.1</b> Residuals refresher</a></li>
<li class="chapter" data-level="42.4.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#linearity-of-relationship"><i class="fa fa-check"></i><b>42.4.2</b> Linearity of relationship</a></li>
<li class="chapter" data-level="42.4.3" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#independence-of-residuals"><i class="fa fa-check"></i><b>42.4.3</b> Independence of residuals</a></li>
<li class="chapter" data-level="42.4.4" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#normality-of-residuals"><i class="fa fa-check"></i><b>42.4.4</b> Normality of residuals</a></li>
<li class="chapter" data-level="42.4.5" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#equality-of-variance"><i class="fa fa-check"></i><b>42.4.5</b> Equality of variance</a></li>
<li class="chapter" data-level="42.4.6" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#what-is-the-conclusion"><i class="fa fa-check"></i><b>42.4.6</b> What’s the conclusion?</a></li>
</ul></li>
<li class="chapter" data-level="42.5" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#infer-regression"><i class="fa fa-check"></i><b>42.5</b> Simulation-based inference for regression</a>
<ul>
<li class="chapter" data-level="42.5.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#confidence-interval-for-slope"><i class="fa fa-check"></i><b>42.5.1</b> Confidence interval for slope</a></li>
<li class="chapter" data-level="42.5.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#hypothesis-test-for-slope"><i class="fa fa-check"></i><b>42.5.2</b> Hypothesis test for slope</a></li>
</ul></li>
<li class="chapter" data-level="42.6" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#inference-conclusion"><i class="fa fa-check"></i><b>42.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="43" data-path="m14c-perform-an-inferential-regression-with-your-own-data.html"><a href="m14c-perform-an-inferential-regression-with-your-own-data.html"><i class="fa fa-check"></i><b>43</b> M14C: Perform an Inferential Regression With Your Own Data</a></li>
<li class="chapter" data-level="44" data-path="m15u-reflect-on-your-understanding-of-data-science.html"><a href="m15u-reflect-on-your-understanding-of-data-science.html"><i class="fa fa-check"></i><b>44</b> M15U: Reflect on Your Understanding of Data Science</a></li>
<li class="chapter" data-level="45" data-path="m15a-reflect-on-your-application-of-data-science.html"><a href="m15a-reflect-on-your-application-of-data-science.html"><i class="fa fa-check"></i><b>45</b> M15A: Reflect on Your Application of Data Science</a></li>
<li class="chapter" data-level="46" data-path="m15c-reflect-on-your-connection-of-data-science.html"><a href="m15c-reflect-on-your-connection-of-data-science.html"><i class="fa fa-check"></i><b>46</b> M15C: Reflect on Your Connection of Data Science</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="confidence-intervals" class="section level1 hasAnchor" number="36">
<h1><span class="header-section-number">36</span> M12A: Confidence Intervals<a href="confidence-intervals.html#confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This content draws on material from <em><a href="https://moderndive.com/v2">Statistical Inference via Data Science: A ModernDive into R and the Tidyverse [Second Edition]</a></em> by <a href="https://chester.rbind.io/">Chester Ismay</a>, <a href="https://rudeboybert.rbind.io/">Albert Y. Kim</a>, and <a href="https://avaldivi6.github.io/">Arturo Valdivia</a> licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p>
<p>Changes to the source material include addition of new material; light editing; rearranging, removing, and combining original material; adding and changing links; and adding first-person language from current author.</p>
<p>The resulting content is licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a>.</p>
<p>In the last module, we studied sampling. Recall, for example, getting many random samples of red and white balls from a bowl, finding the sample proportions of red balls from each of those samples, and studying the distribution of the sample proportions. We can summarize our findings as follows:</p>
<ul>
<li>the sampling distribution of the sample proportion follows, approximately, the normal distribution,</li>
<li>the expected value of the sample proportion, located at the center of the distribution, is exactly equal to the population proportion, and</li>
<li>the sampling variation, measured by the standard error of the sample proportion, is equal to the standard deviation of the population divided by the square root of the sample size used to collect the samples.</li>
</ul>
<p>Similarly, when sampling chocolate-covered almonds and getting the sample mean weight from each sample, the characteristics described above are also encountered in the sampling distribution of the sample mean; namely,</p>
<ul>
<li>the sampling distribution of the sample mean follows, approximately, the normal distribution;</li>
<li>the expected value of the sample mean is the population mean, and</li>
<li>the standard error of the sample mean is the standard deviation of the population divided by the square root of the sample size.</li>
</ul>
<p>Moreover, these characteristics also apply to sampling distributions for the difference in sample means, the difference in sample proportions, and others. Recall that the sampling distribution is not restricted by the distribution of the population. As long as the samples taken are fairly large and we use the appropriate standard error, we can generalize these results appropriately.</p>
<p>The study of the sampling distribution is motivated by another question we have not yet answered: how can we determine the average weight of all the almonds if we do not have access to the entire bowl? We have seen by using simulations that the average of the sample means, derived from many random samples, will be fairly close to the expected value of the sample mean, which is precisely the population mean weight.</p>
<p>However, in real-life situations, <strong>we do not have access to many random samples, only to a single random sample</strong>. This chapter introduces methods and techniques that can help us approximate the information of the entire population, such as the population mean weight, by using a single random sample from this population. This undertaking is called <strong>estimation</strong>, and it is central to statistics and data science.</p>
<p>We’re going to look at some statistical jargon about estimation (hooray?). If we are using a sample statistic to <strong>estimate</strong> a population parameter, e.g., using the sample mean from a random sample to estimate the population mean, we call this statistic a <strong>point estimate</strong> to make emphasis that it is a single value that is used to estimate the parameter of interest. Now, you may recall that, due to sampling variation, the sample mean typically does not match the population mean exactly, even if the sample is large. To account for this variation, we use an interval to estimate the parameter instead of a single value, and appropriately call it an <strong>interval estimate</strong> or, if given some level of accuracy, a <strong>confidence interval</strong> of the population parameter. In this chapter, we’ll look at how to find confidence intervals, the advantages of using them, and the different methods that can be used to determine them.</p>
<p>In Section <a href="confidence-intervals.html#theory-based-CI">36.1</a> we’ll look at a method to build a confidence interval for the population mean that uses the random sample taken and theoretical characteristics of the sampling distribution discussed during the last module.
We can call this the <em>theory-based approach</em> for constructing intervals. In Section <a href="confidence-intervals.html#simulation-based-CI">36.2</a>, I’ll introduce another method, called the bootstrap, that produces confidence intervals by resampling a large number of times from the original sample. Since resampling is done via simulations, we can call this the <em>simulation-based approach</em> for constructing confidence intervals. Finally, in Section <a href="confidence-intervals.html#summary-CI">36.4</a> I’ll summarize and present extensions of these methods.</p>
<div id="CI-packages" class="section level2 unnumbered hasAnchor">
<h2>Needed packages<a href="confidence-intervals.html#CI-packages" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If needed, read Section <a href="m2a-getting-started-with-data-in-r.html#packages">6.3</a> for information on how to install and load R packages.</p>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="confidence-intervals.html#cb305-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb305-2"><a href="confidence-intervals.html#cb305-2" tabindex="-1"></a><span class="fu">library</span>(moderndive)</span>
<span id="cb305-3"><a href="confidence-intervals.html#cb305-3" tabindex="-1"></a><span class="fu">library</span>(infer)</span></code></pre></div>
<p>Recall that loading the <code>tidyverse</code> package loads many packages that we have encountered earlier. For details refer to Section <a href="m6a-wrangling-and-tidying-data.html#tidyverse-package">18.4</a>. The packages <code>moderndive</code> and <code>infer</code> contain functions and data frames that will be used in this chapter.</p>
</div>
<div id="theory-based-CI" class="section level2 hasAnchor" number="36.1">
<h2><span class="header-section-number">36.1</span> Tying the sampling distribution to estimation<a href="confidence-intervals.html#theory-based-CI" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we’ll revisit the chocolate-covered almonds example we looked at previously, as well as the results from the sampling distribution of the sample mean weight of almonds. This time, though, we’ll use this information in the context of estimation.</p>
<p>Let’s start by introducing or reviewing some terminology using the almonds example. The bowl of chocolate-covered almonds is the population of interest. The parameter of interest is the <em>population mean</em> weight of almonds in the bowl, <span class="math inline">\(\mu\)</span>. This is the quantity we want to estimate.</p>
<p>We want to use the sample mean to estimate this parameter. So we’ll call the sample mean an <strong>estimator</strong> or an <strong>estimate</strong> of <span class="math inline">\(\mu\)</span>, the population mean weight. The difference between estimator and estimate is worth discussing.</p>
<p>As an illustration, let’s decide to take a random sample of 100 almonds from the bowl and use its sample mean weight to estimate the population mean weight. In other words, we want to sum 100 almonds’ weights, divide this sum by 100, and use this value to estimate the population mean weight. When we refer to the <em>sample mean</em> to describe this process via an equation, the sample mean weight is called an <strong>estimator</strong> of the population mean weight. Since different samples produce different sample means, the sample mean as an estimator is the random variable <span class="math inline">\(\overline  X\)</span> described in Section <a href="m11a-sampling.html#random-variable-sample-mean">33.4.5</a>. As we have learned previously studying the sampling distribution, we know that this <strong>estimator</strong> follows, approximately, a normal distribution; its expected value is equal to the population mean weight. Its standard deviation, also called standard error, is</p>
<p><span class="math display">\[SE(\bar x) = \frac{\sigma}{\sqrt{n}}\]</span></p>
<p>where <span class="math inline">\(n = 100\)</span> in this example and <span class="math inline">\(\sigma\)</span> is the population standard deviation of almonds’ weights.</p>
<p>Let’s take a random sample of 100 almonds’ weights such and store it in the <code>moderndive</code> package with the same name:</p>
<div class="sourceCode" id="cb306"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb306-1"><a href="confidence-intervals.html#cb306-1" tabindex="-1"></a>almonds_sample_100</span></code></pre></div>
<pre><code># A tibble: 100 × 3
# Groups:   replicate [1]
   replicate    ID weight
       &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;
 1         1   166    4.2
 2         1  1215    4.2
 3         1  1899    3.9
 4         1  1912    3.8
 5         1  4637    3.3
 6         1   511    3.5
 7         1   127    4  
 8         1  4419    3.5
 9         1  4729    4.2
10         1  2574    4.1
# ℹ 90 more rows</code></pre>
<p>We can use it to calculate the sample mean weight:</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="confidence-intervals.html#cb308-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span></span>
<span id="cb308-2"><a href="confidence-intervals.html#cb308-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">sample_mean =</span> <span class="fu">mean</span>(weight))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  replicate sample_mean
      &lt;int&gt;       &lt;dbl&gt;
1         1       3.682</code></pre>
<p>Then <span class="math inline">\(\overline{x} = 3.682\)</span> grams is an <strong>estimate</strong> of the population mean weight. In summary, the <strong>estimator</strong> is the procedure, equation, or method that will be used on a sample to estimate a parameter before the sample has been retrieved and has many useful properties discussed in the sampling walkthrough. The moment a sample is taken and the equation of a sample mean is applied to this sample, the resulting number is an <strong>estimate</strong>.</p>
<p>The sample mean, as an estimator or estimate of the population mean, will be a central component of the material developed in this chapter. Note, though, that it is not the only quantity of interest. For example, the <em>population standard deviation</em> of the almonds’ weight, denoted by the Greek letter <span class="math inline">\(\sigma\)</span>, is a parameter and the <em>sample standard deviation</em> can be an <strong>estimator</strong> or <strong>estimate</strong> of this parameter.</p>
<p>Furthermore, we saw in our walkthrough on sampling that the expected value of the sample mean is equal to the population mean. When this happens, we call the sample mean an <strong>unbiased</strong> estimator of the population mean. This does not mean that any sample mean will be equal to the population mean; some sample means will be greater while others will be smaller but, on average, they will be equal to the population mean. In general, when the expected value of an estimator is equal to the parameter it is trying to estimate, we call the estimator <strong>unbiased</strong>. If it is not, the estimator is <strong>biased</strong>.</p>
<p>Let’s now revisit the almond activity and study how the sampling distribution of the sample mean can help us build interval estimates for the population mean.</p>
<div id="revisit-almond" class="section level3 hasAnchor" number="36.1.1">
<h3><span class="header-section-number">36.1.1</span> Revisiting the almond activity for estimation<a href="confidence-intervals.html#revisit-almond" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>During our sampling walkthrough one of the activities was to take many random samples of size 100 from a bowl of 5,000 chocolate-covered almonds. Since we have access to the contents of the entire bowl, we can compute the population parameters:</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="confidence-intervals.html#cb310-1" tabindex="-1"></a>almonds_bowl <span class="sc">|&gt;</span> </span>
<span id="cb310-2"><a href="confidence-intervals.html#cb310-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">population_mean =</span> <span class="fu">mean</span>(weight), </span>
<span id="cb310-3"><a href="confidence-intervals.html#cb310-3" tabindex="-1"></a>            <span class="at">population_sd =</span> <span class="fu">pop_sd</span>(weight))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  population_mean population_sd
            &lt;dbl&gt;         &lt;dbl&gt;
1         3.64496      0.392070</code></pre>
<p>The total number of almonds in the bowl is 5,000. The population mean is</p>
<p><span class="math display">\[\mu = \sum_{i=1}^{5000}\frac{x_i}{5000}=3.645,\]</span></p>
<p>and the population standard deviation, <a href="https://moderndive.github.io/moderndive/reference/pop_sd.html"><code>pop_sd()</code></a>, from <code>moderndive</code>, is defined as</p>
<p><span class="math display">\[\sigma = \sum_{i=1}^{5000} \frac{(x_i - \mu)^2}{5000}=0.392.\]</span></p>
<p>We keep those numbers for future reference to determine how well our methods of estimation are doing, but remember that in real-life situations <strong>we do not have access to the population values</strong> and the population mean <span class="math inline">\(\mu\)</span> is unknown. All we have is the information from one random sample. In our example, we assume that all we know is the <code>almonds_sample_100</code> object stored in <code>moderndive</code>. Its <code>ID</code> variable shows the almond chosen from the bowl and its corresponding <code>weight</code>. Using this sample we calculate some sample statistics:</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="confidence-intervals.html#cb312-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb312-2"><a href="confidence-intervals.html#cb312-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight), </span>
<span id="cb312-3"><a href="confidence-intervals.html#cb312-3" tabindex="-1"></a>            <span class="at">sd_weight =</span> <span class="fu">sd</span>(weight), </span>
<span id="cb312-4"><a href="confidence-intervals.html#cb312-4" tabindex="-1"></a>            <span class="at">sample_size =</span> <span class="fu">n</span>())</span></code></pre></div>
<pre><code># A tibble: 1 × 4
  replicate mean_weight sd_weight sample_size
      &lt;int&gt;       &lt;dbl&gt;     &lt;dbl&gt;       &lt;int&gt;
1         1       3.682  0.362199         100</code></pre>
<p>In one of our sampling activities, we took many random samples, calculated their sample means, constructed a histogram using these sample means, and showed how the histogram is a good approximation of the sampling distribution of the sample mean. Let’s redraw Figure <a href="m11a-sampling.html#fig:sample-mean-100-with-normal">33.26</a> here as Figure <a href="confidence-intervals.html#fig:sample-mean-100-with-normal-redraw">36.1</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sample-mean-100-with-normal-redraw"></span>
<img src="_main_files/figure-html/sample-mean-100-with-normal-redraw-1.png" alt="The distribution of the sample mean." width="\textwidth" />
<p class="caption">
Figure 36.1: The distribution of the sample mean.
</p>
</div>
<p>The histogram in Figure <a href="confidence-intervals.html#fig:sample-mean-100-with-normal-redraw">36.1</a> is drawn using many sample mean weights from random samples of size <span class="math inline">\(n=100\)</span>.The added red smooth curve is the density curve for the normal distribution with the appropriate expected value and standard error calculated from the sample distribution. The red dot represents the population mean <span class="math inline">\(\mu\)</span>, the unknown parameter we are trying to estimate. The blue right is the sample mean <span class="math inline">\(\overline{x} = 3.682\)</span> from the random sample stored in <code>almonds_sample_100</code>.</p>
<p>In real-life applications, a sample mean is taken from a sample, but the distribution of the population and the population mean are unknown, so the location of the blue dot with respect to the red dot is also unknown. However, if we construct an interval centered on the blue dot, as long as it is wide enough the interval will contain the red dot. To understand this better, we need to learn a few additional properties of the normal distribution.</p>
</div>
<div id="the-normal-distribution" class="section level3 hasAnchor" number="36.1.2">
<h3><span class="header-section-number">36.1.2</span> The normal distribution<a href="confidence-intervals.html#the-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A random variable can take on different values. When those values can be represented by one or more intervals, the likelihood of those values can be expressed graphically by a density curve on a Cartesian coordinate system in two dimensions. The horizontal axis (X-axis) represents the values that the random variable can take and the height of density curve (Y-axis) provides a graphical representation of the likelihood of those values; the higher the curve the more likely those values are. In addition, the total area under a density curve is always equal to 1. The set of values a random variable can take alongside their likelihood is what we call the distribution of a random variable.</p>
<p>The normal distribution is the distribution of a special type of random variable. Its density curve has a distinctive bell shape, and it is fully defined by two values: (1) the mean or expected value of the random variable, <span class="math inline">\(\mu\)</span>, which is located on the X-axis at the center of the density curve (its highest point), and (2) the standard deviation, <span class="math inline">\(\sigma\)</span>, which reflects the dispersion of the random variable; the greater the standard deviation is the wider the curve appears.</p>
<p>In Figure <a href="confidence-intervals.html#fig:normal-curves">36.2</a>, we can see the density curves of three random variables, all following normal distributions:</p>
<ol style="list-style-type: decimal">
<li>The solid line represents a normal distribution with <span class="math inline">\(\mu = 5\)</span> &amp; <span class="math inline">\(\sigma = 2\)</span>.</li>
<li>The dotted line represents a normal distribution with <span class="math inline">\(\mu = 5\)</span> &amp; <span class="math inline">\(\sigma = 5\)</span>.</li>
<li>The dashed line represents a normal distribution with <span class="math inline">\(\mu = 15\)</span> &amp; <span class="math inline">\(\sigma = 2\)</span>.</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:normal-curves"></span>
<img src="_main_files/figure-html/normal-curves-1.png" alt="Three normal distributions." width="\textwidth" />
<p class="caption">
Figure 36.2: Three normal distributions.
</p>
</div>
<p>A random variable that follows a normal distribution can take any values in the real line, but those values (on the X-axis) that correspond to the peak of the density curve are more likely than those corresponding to the tails. The density curve drawn with a solid line has the same mean as the one drawn with a dotted line, <span class="math inline">\(\mu = 5\)</span>, but the former exhibits less dispersion, measured by the standard deviation <span class="math inline">\(\sigma =2\)</span>, than the latter, <span class="math inline">\(\sigma = 5\)</span>. Since the total area under any density curve is equal to 1, the wider curve has to be shorter in height to preserve this property. On the other hand, the density curve drawn with a solid line has the same standard deviation as the one drawn with a dashed line, <span class="math inline">\(\sigma = 2\)</span>, but the latter has a greater mean, <span class="math inline">\(\mu = 15\)</span>, than the former, <span class="math inline">\(\mu = 5\)</span>, so they do look the same but the latter is centered farther to the right on the X-axis than the former.</p>
<div id="the-standard-normal-distribution" class="section level4 unnumbered hasAnchor">
<h4>The standard normal distribution<a href="confidence-intervals.html#the-standard-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A special normal distribution has mean <span class="math inline">\(\mu\)</span> = 0 and standard deviation <span class="math inline">\(\sigma\)</span> = 1. It is called the <em>standard normal distribution</em>, and it is represented by a density curve called the <em><span class="math inline">\(z\)</span>-curve</em>. If a random variable <span class="math inline">\(Z\)</span> follows the standard normal distribution, a realization of this random variable is called a standard value or <span class="math inline">\(z\)</span>-value. The <span class="math inline">\(z\)</span>-value also represents the number of standard deviations above the mean, if positive, or below the mean, if negative. For example, if <span class="math inline">\(z=5\)</span>, the value observed represents a realization of the random variable <span class="math inline">\(Z\)</span> that is five standard deviations above the mean, <span class="math inline">\(\mu = 0\)</span>.</p>
</div>
<div id="linear-transformations-of-random-variables-that-follow-the-normal-distribution" class="section level4 unnumbered hasAnchor">
<h4>Linear transformations of random variables that follow the normal distribution<a href="confidence-intervals.html#linear-transformations-of-random-variables-that-follow-the-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A linear transformation of a random variable transforms the original variable into a new random variable by adding, subtracting, multiplying, or dividing constants to the original values. The resulting random variable could have a different mean and standard deviation. The most interesting transformation is turning a random variable into another with <span class="math inline">\(\mu = 0\)</span> and <span class="math inline">\(\sigma = 1\)</span>. When this happens we say that the random variable has been standardized.</p>
<p>A property of the normal distribution is that any linear transformation of a random variable that follows the normal distribution results in a new random variable that also follows a normal distribution, potentially with different mean and standard deviation. In particular, we can turn any random variable that follows the normal distribution into a random variable that follows the standard normal distribution. For example, if a value <span class="math inline">\(x = 11\)</span> comes from a normal distribution with mean <span class="math inline">\(\mu =5\)</span> and standard deviation <span class="math inline">\(\sigma = 2\)</span>, the <span class="math inline">\(z\)</span>-value</p>
<p><span class="math display">\[z = \frac{x - \mu}{\sigma} = \frac{11 - 5}{2} = 3\]</span>
is the corresponding value in a standard normal curve. Moreover, we have determined that <span class="math inline">\(x = 11\)</span> for this example is precisely <span class="math inline">\(3\)</span> standard deviations above the mean.</p>
</div>
<div id="finding-probabilities-under-a-density-curve" class="section level4 unnumbered hasAnchor">
<h4>Finding probabilities under a density curve<a href="confidence-intervals.html#finding-probabilities-under-a-density-curve" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>When a random variable can be represented by a density curve, the probability that the random variable takes a value in any given interval (on the X-axis) is equal to the area under the density curve for that interval. If we know the equation that represents the density curve, we could use the mathematical technique from calculus known as integration to determine this area. In the case of the normal curve, the integral for any interval does not have a close-form solution, and the solution is calculated using numerical approximations.</p>
<p>Let’s assume that a random variable <span class="math inline">\(Z\)</span> follows a standard normal distribution. We would like to know how likely it is for this random variable to take a value that is within one standard deviation from the mean. Equivalently, what is the probability that the observed value <span class="math inline">\(z\)</span> (in the X-axis) is between -1 and 1 as shown in Figure <a href="confidence-intervals.html#fig:normal-curve-shaded-1a">36.3</a>?</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:normal-curve-shaded-1a"></span>
<img src="_main_files/figure-html/normal-curve-shaded-1a-1.png" alt="Normal area within one standard deviation." width="\textwidth" />
<p class="caption">
Figure 36.3: Normal area within one standard deviation.
</p>
</div>
<p>Calculations show that this area is 0.6827 (68.27%) of the total area under the curve. This is equivalent to saying that the probability of getting a value between <span class="math inline">\(-1\)</span> and 1 on a standard normal is 68.27%. This also means that if a random variable representing an experiment follows a normal distribution, the probability that the outcome of this experiment is within one standard deviation from the mean is 68.27%. Similarly, the area under the standard normal density curve between -2 and 2 is shown in Figure <a href="confidence-intervals.html#fig:normal-curve-shaded-2a">36.4</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:normal-curve-shaded-2a"></span>
<img src="_main_files/figure-html/normal-curve-shaded-2a-1.png" alt="Normal area within two standard deviations." width="\textwidth" />
<p class="caption">
Figure 36.4: Normal area within two standard deviations.
</p>
</div>
<p>Calculations show that this area is equal to 0.9545 or 95.45%. If a random variable representing an experiment follows a normal distribution, the probability that the outcome of this experiment is within two standard deviations from the mean is 95.45%. It is also common practice to use the exact number of standard deviations that correspond to an area around the mean exactly equal to 95% (instead of 95.45%).
Please see <a href="https://moderndive.com/v2/appendixa">Appendix A online</a> to produce these or other calculations in R.
The result is that the area under the density curve around the mean that is exactly equal to 0.95, or 95%, is the area within 1.96 standard deviation from the mean. Remember this number, as it will be used a few times in later sections.</p>
<p>In summary, if the possible outcomes of an experiment can be expressed as a random variable that follows the normal distribution, the probability of getting a result that is within one standard deviation from the mean is about 68.27%, within 2 standard deviations form the mean is 95.45%, within 1.96 standard deviations from the mean is 95%, and within 3 standard deviations from the mean is about 99.73%, to name a few.</p>
<p>Spend a few moments grasping this idea; observe, for example, that it is almost impossible to observe an outcome represented by a number that is five standard deviations above the mean as the chances of that happening are near zero. We are now ready to return to our main goal: how to find an interval estimate of the population mean based on a single sample.</p>
</div>
</div>
<div id="CI-general" class="section level3 hasAnchor" number="36.1.3">
<h3><span class="header-section-number">36.1.3</span> The confidence interval<a href="confidence-intervals.html#CI-general" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s continue using the example where we try to estimate the population mean weight of almonds with a random sample of 100 almonds. We saw in the last module that the sampling distribution of the sample mean weight of almonds approximates a normal distribution with expected value equal to the population mean weight of almonds and a standard error equal to</p>
<p><span class="math display">\[SE(\bar x) = \frac{\sigma}{\sqrt {100}}.\]</span>
In Subsection <a href="confidence-intervals.html#revisit-almond">36.1.1</a> we showed that for the population of almonds, <span class="math inline">\(\mu =3.645\)</span> grams and <span class="math inline">\(\sigma = 0.392\)</span>, so the standard error for the sampling distribution is</p>
<p><span class="math display">\[SE(\bar x) = \frac{\sigma}{\sqrt{100}} = \frac{0.392}{\sqrt{100}} = 0.039\]</span>
grams. In Figure <a href="confidence-intervals.html#fig:normal-curve-1">36.5</a> we plot the density curve for this distribution using these values.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:normal-curve-1"></span>
<img src="_main_files/figure-html/normal-curve-1-1.png" alt="Normal density curve for the sample mean weight of almonds." width="90%" />
<p class="caption">
Figure 36.5: Normal density curve for the sample mean weight of almonds.
</p>
</div>
<p>The horizontal axis (X-axis) represents the sample means that we can determine from all the possible random samples of 100 almonds. The red dot represents the expected value of the sampling distribution, <span class="math inline">\(\mu = 3.64\)</span>, located on the X-axis at the center of the distribution. The density curve’s height can be thought of as how likely those sample means are to be observed. For example, it is more likely to get a random sample with a sample mean around <span class="math inline">\(3.645\)</span> grams (which corresponds to the highest point of the curve) than it is to get a sample with a sample mean of around <span class="math inline">\(3.5\)</span> grams, since the curve’s height is almost zero at that value. The blue dot is the sample mean from our sample of 100 almonds, <span class="math inline">\(\overline{x} = 3.682\)</span> grams. It is located 0.037 grams above the population mean weight. How far is 0.037 grams? It is helpful to express this distance in standardized values:</p>
<p><span class="math display">\[\frac{3.682 - 3.645}{0.039} = 0.945\]</span></p>
<p>so 0.037 more grams is about 0.945 standard errors above the population mean.</p>
<p>In real-life situations, the population mean, <span class="math inline">\(\mu\)</span>, is unknown so the distance from the sample mean to <span class="math inline">\(\mu\)</span> is also unknown. On the other hand, the sampling distribution of the sample mean follows a normal distribution. Based on our earlier discussion about areas under the normal curve, there is a 95% chance that the value observed is within 1.96 standard deviations from the mean. In the context of our problem, there is a 95% chance that the sample mean weight is within 1.96 standard errors from the population mean weight. As shown earlier, the sample mean calculated in our example was 0.945 standard errors above the population mean, well within the reasonable range.</p>
<p>Think about this result. If we were to take a different random sample of 100 almonds, the sample mean will likely be different, but you still have a 95% chance that the new sample mean will be within 1.96 standard errors from the population mean.</p>
<p>We can finally construct an interval estimate that takes advantage of this configuration. We center our interval at the sample mean observed and then extend to each side the magnitude equivalent to 1.96 standard errors. The lower and upper bounds of this interval are:</p>
<p><span class="math display">\[\begin{aligned}\left(\overline{x} - 1.96 \frac{\sigma}{\sqrt{n}},\quad \overline{x} + 1.96 \frac{\sigma}{\sqrt{n}}\right) &amp;= \left(3.682 - 1.96 \cdot \frac{0.392}{\sqrt{100}},\quad 3.682 + 1.96 \cdot \frac{0.392}{\sqrt{100}}\right)\\
&amp;= (3.605, 3.759)\end{aligned}\]</span></p>
<p>Here is R code that can be used to calculate these lower and upper bounds:</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="confidence-intervals.html#cb314-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span></span>
<span id="cb314-2"><a href="confidence-intervals.html#cb314-2" tabindex="-1"></a>  <span class="fu">summarize</span>(</span>
<span id="cb314-3"><a href="confidence-intervals.html#cb314-3" tabindex="-1"></a>    <span class="at">sample_mean =</span> <span class="fu">mean</span>(weight),</span>
<span id="cb314-4"><a href="confidence-intervals.html#cb314-4" tabindex="-1"></a>    <span class="at">lower_bound =</span> <span class="fu">mean</span>(weight) <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">length</span>(weight)),</span>
<span id="cb314-5"><a href="confidence-intervals.html#cb314-5" tabindex="-1"></a>    <span class="at">upper_bound =</span> <span class="fu">mean</span>(weight) <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">length</span>(weight))</span>
<span id="cb314-6"><a href="confidence-intervals.html#cb314-6" tabindex="-1"></a>  )</span></code></pre></div>
<pre><code># A tibble: 1 × 4
  replicate sample_mean lower_bound upper_bound
      &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
1         1       3.682     3.60515     3.75885</code></pre>
<p>The functions <code>mean()</code> and <code>length()</code> find the sample mean weight and sample size, respectively, from the sample of almonds’ weights in <code>almonds_sample_100</code>. The number 1.96 corresponds to the number of standard errors needed to get a 95% area under the normal distribution and the population standard deviation <code>sigma</code> of 0.392 was found in Subsection <a href="confidence-intervals.html#revisit-almond">36.1.1</a>. Figure <a href="confidence-intervals.html#fig:normal-curve-2">36.6</a> shows this interval as a horizontal blue line. Observe how the population mean <span class="math inline">\(\mu\)</span> is part of this interval.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:normal-curve-2"></span>
<img src="_main_files/figure-html/normal-curve-2-1.png" alt="Is the population mean in the interval?" width="90%" />
<p class="caption">
Figure 36.6: Is the population mean in the interval?
</p>
</div>
<p>Since 1.96 standard errors were used on the construction of this interval, we call this a 95% confidence interval. A confidence interval can be viewed as an interval estimator of the population mean. Compare an interval estimator with the sample mean that is a point estimator. The latter estimates the parameter with a single number, the former provides an entire interval to account for the location of the parameter. An apt analogy involves fishing. Imagine that there is a single fish swimming in murky water. The fish is not visible but its movement produces ripples on the surface that can provide some limited information about the fish’s location. To capture the fish, one could use a spear or a net. Because the information is limited, throwing the spear at the ripples may capture the fish but likely will miss it.</p>
<p>Throwing a net around the ripples, on the other hand, may give a much higher likelihood of capturing the fish. Using the sample mean only to estimate the population mean is like throwing a spear at the ripples in the hopes of capturing the fish. Constructing a confidence interval that may include the population mean is like throwing a net to surround the ripples. Keep this analogy in mind, as we will revisit it in later sections.</p>
</div>
<div id="t-distribution-CI" class="section level3 hasAnchor" number="36.1.4">
<h3><span class="header-section-number">36.1.4</span> The t distribution<a href="confidence-intervals.html#t-distribution-CI" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Remember that due to the Central Limit Theorem, the sampling distribution of the sample mean was approximately normal with mean equal to the population mean <span class="math inline">\(\mu\)</span> and standard deviation given by the standard error <span class="math inline">\(SE(\overline X) = \sigma/\sqrt{n}\)</span>. We can standardize this for any sample mean <span class="math inline">\(\overline{x}\)</span> such that</p>
<p><span class="math display">\[z = \frac{\overline{x} - \mu}{\sigma/\sqrt{n}}\]</span></p>
<p>is the corresponding value of the standard normal distribution.</p>
<p>In the construction of the interval in Figure <a href="confidence-intervals.html#fig:normal-curve-2">36.6</a> we have assumed the population standard deviation, <span class="math inline">\(\sigma\)</span>, was known, and therefore we have used it to find the confidence interval. Nevertheless, in real-life applications, the population standard deviation is also unknown.
Instead, we use the sample standard deviation, <span class="math inline">\(s\)</span>, from the sample we have, as an estimator of the population standard deviation <span class="math inline">\(\sigma\)</span>. Our estimated standard error is given by</p>
<p><span class="math display">\[\widehat{SE}(\overline X) = \frac{s}{\sqrt n}.\]</span></p>
<p>When using the sample standard deviation to estimate the standard error, we are introducing additional uncertainty in our model. For example, if we try to standardize this value, we get</p>
<p><span class="math display">\[t = \frac{\overline{x} - \mu}{s/\sqrt{n}}.\]</span></p>
<p>Because we are using the sample standard deviation in this equation and since the sample standard deviation changes from sample to sample, the additional uncertainty makes the values <span class="math inline">\(t\)</span> no longer normal. Instead they follow a new distribution called the <span class="math inline">\(t\)</span> distribution.</p>
<p>The <span class="math inline">\(t\)</span> distribution is similar to the standard normal; its density curve is also bell-shaped, and it is symmetric around zero, but the tails of the <span class="math inline">\(t\)</span> distribution are a little thicker than those of the standard normal.
In addition, the <span class="math inline">\(t\)</span> distribution requires one additional parameter, the degrees of freedom. For sample mean problems, the degrees of freedom needed are exactly <span class="math inline">\(n-1\)</span>, the size of the sample minus one. Figure <a href="confidence-intervals.html#fig:t-curve-1">36.7</a> shows the density curves of</p>
<ul>
<li>the standard normal density curve, in black,</li>
<li>a <span class="math inline">\(t\)</span> density curve for a t distribution with 2 degrees of freedom, in dotted blue, and</li>
<li>a <span class="math inline">\(t\)</span> density curve for a t distribution with 10 degrees of freedom, in dashed red.</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:t-curve-1"></span>
<img src="_main_files/figure-html/t-curve-1-1.png" alt="The standard normal and two t-distributions." width="\textwidth" />
<p class="caption">
Figure 36.7: The standard normal and two t-distributions.
</p>
</div>
<p>Observe how the <span class="math inline">\(t\)</span> density curve in dashed red (<span class="math inline">\(t\)</span> with 10 degrees of freedom) gets closer to the standard normal density curve, or <span class="math inline">\(z\)</span>-curve, in solid black, than the <span class="math inline">\(t\)</span> curve in dotted blue (<span class="math inline">\(t\)</span> with 2 degrees of freedom). The greater the number of degrees of freedom, the closer the <span class="math inline">\(t\)</span> density curve is from the <span class="math inline">\(z\)</span> curve. This change makes our calculations slightly different.</p>
<p>Please see <a href="https://moderndive.com/v2/appendixa">Appendix A online</a> for calculations of probabilities for <span class="math inline">\(t\)</span> density curves with different degrees of freedom.
Using that knowledge, the calculation for our specific example shows that 95% of the sample means are within 1.98 standard errors from the population mean weight. The number of standard errors needed is not that different from before, 1.98 versus 1.96, because the degrees of freedom are fairly large.</p>
<p>Using this information, we can construct the 95% confidence interval based entirely on our sample information and using the sample mean and sample standard deviation. We calculate those values again for <code>almonds_sample_100</code>:</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="confidence-intervals.html#cb316-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span></span>
<span id="cb316-2"><a href="confidence-intervals.html#cb316-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">sample_mean =</span> <span class="fu">mean</span>(weight), <span class="at">sample_sd =</span> <span class="fu">sd</span>(weight))</span></code></pre></div>
<pre><code># A tibble: 1 × 3
  replicate sample_mean sample_sd
      &lt;int&gt;       &lt;dbl&gt;     &lt;dbl&gt;
1         1       3.682  0.362199</code></pre>
<p>Observe that the sample standard deviation is <span class="math inline">\(s = 0.362\)</span> which is not that different from the population standard deviation of <span class="math inline">\(\sigma = 0.392\)</span>. We again center the confidence interval at the observed sample mean but now extend the interval by 1.98 standard errors to each side. The lower and upper bounds of this confidence interval are:</p>
<p><span class="math display">\[
\begin{aligned}
\left(\overline{x} - 1.98 \frac{s}{\sqrt{n}},\quad \overline{x} + 1.98 \frac{s}{\sqrt{n}}\right) &amp;= \left(3.682 - 1.98 \cdot \frac{0.362}{\sqrt{100}}, 3.682 + 1.98 \cdot \frac{0.362}{\sqrt{100}}\right) \\
&amp;= (3.498, 3.846))
\end{aligned}
\]</span></p>
<p>We can also compute these lower and upper bounds:</p>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="confidence-intervals.html#cb318-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span></span>
<span id="cb318-2"><a href="confidence-intervals.html#cb318-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">sample_mean =</span> <span class="fu">mean</span>(weight), <span class="at">sample_sd =</span> <span class="fu">sd</span>(weight),</span>
<span id="cb318-3"><a href="confidence-intervals.html#cb318-3" tabindex="-1"></a>            <span class="at">lower_bound =</span> <span class="fu">mean</span>(weight) <span class="sc">-</span> <span class="fl">1.98</span><span class="sc">*</span><span class="fu">sd</span>(weight)<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">length</span>(weight)),</span>
<span id="cb318-4"><a href="confidence-intervals.html#cb318-4" tabindex="-1"></a>            <span class="at">upper_bound =</span> <span class="fu">mean</span>(weight) <span class="sc">+</span> <span class="fl">1.98</span><span class="sc">*</span><span class="fu">sd</span>(weight)<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">length</span>(weight)))</span></code></pre></div>
<pre><code># A tibble: 1 × 5
  replicate sample_mean sample_sd lower_bound upper_bound
      &lt;int&gt;       &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
1         1       3.682  0.362199     3.61028     3.75372</code></pre>
<p>The confidence interval computed here, using the sample standard deviation and a <span class="math inline">\(t\)</span> distribution, is almost the same as the one attained using the population standard deviation and the standard normal distribution, the difference is about 0.005 units for the upper and lower bound. This happens because with a sample size of 100, the <span class="math inline">\(t\)</span>-curve and <span class="math inline">\(z\)</span>-curve are almost identical and also because the sample standard deviation was very similar to the population standard deviation. This does not have to be always the case and occasionally we can observe greater differences; but, in general, the results are fairly similar.</p>
<p>More importantly, the confidence interval constructed here contains the population mean of <span class="math inline">\(\mu = 3.645\)</span>, which is the result we needed. Recall that a confidence interval is an interval estimate of the parameter of interest, the population mean weight of almonds.</p>
<p>Let’s summarize the results so far:</p>
<ul>
<li>If the size used for your random sample is large enough, the sampling distribution of the sample mean follows, approximately, the normal distribution.</li>
<li>Using the sample mean observed and the standard error of the sampling distribution, we can construct 95% confidence intervals for the population mean. The formula for these intervals (where <span class="math inline">\(n\)</span> is the sample size used) is given by</li>
</ul>
<p><span class="math display">\[\left(\overline{x} - 1.96 \frac{\sigma}{\sqrt{n}},\quad \overline{x} + 1.96 \frac{\sigma}{\sqrt{n}}\right).\]</span></p>
<ul>
<li>When the population standard deviation is unknown (which is almost always the case), the sample standard deviation is used to estimate the standard error. This produces additional variability and the standardized values follow a <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. The formula for 95% confidence intervals when the sample size is <span class="math inline">\(n=100\)</span> is given by</li>
</ul>
<p><span class="math display">\[\left(\overline{x} - 1.98 \frac{s}{\sqrt{100}},\quad \overline{x} + 1.98 \frac{s}{\sqrt{100}}\right).\]</span></p>
<ul>
<li>The method to construct 95% confidence intervals guarantees that in the long-run for 95% of the possible samples, the intervals determined will include the population mean. It also guarantees that 5% of the possible samples will lead to intervals that do not include the population mean.</li>
<li>As we have constructed intervals with a 95% level of confidence, we can construct intervals with any level of confidence. The only change in the equations will be the number of standard errors needed.</li>
</ul>
</div>
<div id="interpreting-confidence-intervals" class="section level3 hasAnchor" number="36.1.5">
<h3><span class="header-section-number">36.1.5</span> Interpreting confidence intervals<a href="confidence-intervals.html#interpreting-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We have used the sample <code>almonds_sample_100</code>, constructed a 95% confidence interval for the population mean weight of almonds, and showed that the interval contained this population. This result is not surprising as we expect intervals such as this to include the population mean for 95% of the possible random samples. We repeat this interval construction for many random samples. Figure <a href="confidence-intervals.html#fig:almond-mean-cis">36.8</a> presents the results for one hundred 95% confidence intervals.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:almond-mean-cis"></span>
<img src="_main_files/figure-html/almond-mean-cis-1.png" alt="One hundred 95% confidence intervals and whether the population mean is captured in each." width="\textwidth" />
<p class="caption">
Figure 36.8: One hundred 95% confidence intervals and whether the population mean is captured in each.
</p>
</div>
<p>Note that each interval was built using a different random sample. The red vertical line is drawn at the location of the population mean weight, <span class="math inline">\(\mu = 3.645\)</span>. The horizontal lines represent the one hundred 95% confidence intervals found. The gray confidence intervals cross the red vertical line so they contain the population mean. The black confidence intervals do not.</p>
<p>This result motivates the meaning of a 95% confidence interval: If you could construct intervals using the procedure described earlier for every possible random sample, then 95% of these intervals will include the population mean and 5% of them will not.</p>
<p>Of course, in most situations, it would be impractical or impossible to take every possible random sample. Still, for a large number of random samples, this result is approximately correct. In Figure <a href="confidence-intervals.html#fig:almond-mean-cis">36.8</a>, for example, 5 out of 100 confidence intervals do not include the population mean, and 95% do. It won’t always match up perfectly like this, but the proportions should match pretty close to the confidence level chosen.</p>
<p>The term “95% confidence” might make us think we are talking about probabilities or chances. We are, but in a subtle way that might not come to mind at first. Before a random sample has been procured, there is a 95% chance that when a confidence interval is constructed using the prospective random sample, this interval will contain the population mean. The moment a random sample has been attained, the interval constructed either contains the population mean or it does not; with certainty, there is no longer a chance involved. This is true even if we do not know what the population mean is.</p>
<p>So the 95% confidence refers to the method or process to be used on a prospective sample. We are confident that if we follow the process to construct the interval, 95% of the time the random sample attained will lead us to produce an interval that contains the population mean.</p>
<p>On the other hand, it would be improper to say that… “there is a 95% chance that the confidence interval contains the population mean.” Looking at Figure <a href="confidence-intervals.html#fig:almond-mean-cis">36.8</a>, each of the confidence intervals either does or does not contain <span class="math inline">\(\mu\)</span>. Once the confidence interval is determined, either the population mean is included or not.</p>
<p>In the literature, this explanation has been encapsulated in a short-hand version: we are 95% confident that the interval contains the population parameter. For example, in Subsection <a href="confidence-intervals.html#t-distribution-CI">36.1.4</a> the 95% confidence interval for the population mean weight of almonds was (3.498, 3.846), and we would say: “We are 95% confident that the population mean weight of almonds is between 3.498 and 3.846 grams.”</p>
<p>It is perfectly acceptable to use the short-hand statement, but always remember that the 95% confidence refers to the process, or method, and can be thought of as a chance or probability only before the random sample has been acquired. To further ensure that the probability-type of language is not misused, quotation marks are sometimes put around “95% confident” to emphasize that it is a short-hand version of the more accurate explanation.</p>
<div id="ci-width" class="section level4 unnumbered hasAnchor">
<h4>Understanding the width of a confidence interval<a href="confidence-intervals.html#ci-width" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A confidence interval is an estimator of a population parameter. In the case of the almonds’ bowl we constructed a confidence interval for the population mean. The equation to construct a 95% confidence interval was</p>
<p><span class="math display">\[\left(\overline{x} - 1.96 \frac{\sigma}{\sqrt{n}}, \overline{x} + 1.96 \frac{\sigma}{\sqrt{n}}\right)\]</span>
Observe that the confidence interval is centered at the sample mean and it extends to each side 1.96 standard errors <span class="math inline">\(1.96\cdot \sigma / \sqrt{n}\)</span>. This quantity is exactly half the width of your confidence interval, and it is called the <strong>margin of error</strong>. The value of the population standard deviation, <span class="math inline">\(\sigma\)</span>, is beyond our control, as it is determined by the distribution of the experiment or phenomenon studied. The sample mean, <span class="math inline">\(\overline{x}\)</span>, is a result that depends on your random sample exclusively. On the other hand, the number 1.96 and the sample size, <span class="math inline">\(n\)</span>, are values that can be changed by the researcher or practitioner. They play an important role on the width of the confidence interval. We study each of them separately.</p>
<div id="the-confidence-level" class="section level5 unnumbered hasAnchor">
<h5>The confidence level<a href="confidence-intervals.html#the-confidence-level" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>We mentioned earlier that the number 1.96 relates to a 95% confidence process but we did not show how to determine this value. The level of confidence is a decision of the practitioner. If you want to be more confident, say 98% or 99% confident, you just need to adjust the appropriate number of standard errors needed. We show how to determine this number, and use Figure <a href="confidence-intervals.html#fig:normal-curve-shaded-3a">36.9</a> to illustrate this process.</p>
<ul>
<li>If the confidence level is 0.95 (or 95%), the area in the middle of the standard normal distribution is 0.95. This area is shaded in Figure <a href="confidence-intervals.html#fig:normal-curve-shaded-3a">36.9</a>.</li>
<li>We construct <span class="math inline">\(\alpha = 1 - \text{confidence level} = 1 - 0.95 = 0.05\)</span>. Think of <span class="math inline">\(\alpha\)</span> as the total area on both tails.</li>
<li>Since the normal distribution is symmetric, the area on each tail is <span class="math inline">\(\alpha/2 = 0.05/2 = 0.025\)</span>.</li>
<li>We need the exact number of standard deviations that produces the shaded area. Since the center of a standard normal density curve is zero, as shown in Figure <a href="confidence-intervals.html#fig:normal-curve-shaded-3a">36.9</a>, and the normal curve is symmetric, the number of standard deviations can be represented by <span class="math inline">\(-q\)</span> and <span class="math inline">\(q\)</span>, the same magnitude but one positive and the other negative.</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:normal-curve-shaded-3a"></span>
<img src="_main_files/figure-html/normal-curve-shaded-3a-1.png" alt="Normal curve with the shaded middle area being 0.95" width="\textwidth" />
<p class="caption">
Figure 36.9: Normal curve with the shaded middle area being 0.95
</p>
</div>
<p>In R, the function <code>qnorm()</code> finds the value of <span class="math inline">\(q\)</span> when the area under this curve to the left of this value <span class="math inline">\(q\)</span> is given. In our example the area to the left of <span class="math inline">\(-q\)</span> is <span class="math inline">\(\alpha/2 = 0.05/2 = 0.025\)</span>, so</p>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="confidence-intervals.html#cb320-1" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.025</span>)</span></code></pre></div>
<pre><code>[1] -1.96</code></pre>
<p>or 1.96 standard deviation below the mean. Similarly, the total area under the curve to the left of <span class="math inline">\(q\)</span> is the total shaded area, 0.95, plus the small white area on the left tail, <span class="math inline">\(0.025\)</span>, and <span class="math inline">\(0.95 + 0.025 = 0.975\)</span>, so</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="confidence-intervals.html#cb322-1" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.975</span>)</span></code></pre></div>
<pre><code>[1] 1.96</code></pre>
<p>That is the reason we use 1.96 standard deviation when calculating 95% confidence intervals. What if we want to retrieve a 90% confidence interval? We follow the same procedure:</p>
<ul>
<li>The confidence level is 0.90.</li>
<li><span class="math inline">\(\alpha = 1 - \text{confidence level} = 1 - 0.90 = 0.10\)</span>.</li>
<li>The area on each tail is <span class="math inline">\(\alpha/2 = 0.10/2 = 0.05\)</span>.</li>
<li>The area needed to find <span class="math inline">\(q\)</span> is <span class="math inline">\(0.90+0.05 = 0.95\)</span>.</li>
</ul>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="confidence-intervals.html#cb324-1" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>[1] 1.65</code></pre>
<p>If we want to determine a 90% confidence interval, we need to use 1.645 standard errors in our calculations. We can update the R code to calculate the lower and upper bounds of a 90% confidence interval:</p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="confidence-intervals.html#cb326-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span></span>
<span id="cb326-2"><a href="confidence-intervals.html#cb326-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">sample_mean =</span> <span class="fu">mean</span>(weight),</span>
<span id="cb326-3"><a href="confidence-intervals.html#cb326-3" tabindex="-1"></a>            <span class="at">lower_bound =</span> <span class="fu">mean</span>(weight) <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.95</span>)<span class="sc">*</span>sigma<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">length</span>(weight)),</span>
<span id="cb326-4"><a href="confidence-intervals.html#cb326-4" tabindex="-1"></a>            <span class="at">upper_bound =</span> <span class="fu">mean</span>(weight) <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.95</span>)<span class="sc">*</span>sigma<span class="sc">/</span><span class="fu">sqrt</span>(<span class="fu">length</span>(weight)))</span></code></pre></div>
<pre><code># A tibble: 1 × 4
  replicate sample_mean lower_bound upper_bound
      &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
1         1       3.682     3.61751     3.74649</code></pre>
<p>Let’s do one more. If we want an 80% confidence interval, <span class="math inline">\(1 - 0.8 = 0.2\)</span>, <span class="math inline">\(0.2/2 = 0.1\)</span>, and <span class="math inline">\(0.8+0.1 = 0.9\)</span>, so</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="confidence-intervals.html#cb328-1" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="fl">0.9</span>)</span></code></pre></div>
<pre><code>[1] 1.28</code></pre>
<p>When you want to calculate an 80%, 90%, or 95% confidence interval, you need to construct your interval using 1.282, 1.645, or 1.96 standard errors, respectively. The more confident you want to be, the larger the number of standard errors you need to use, and the wider your confidence interval becomes. But a confidence interval is an estimator of the population mean, the narrower it is, the more useful it is for practical reasons. So there is a trade-off between the width of a confidence interval and the confidence you want to have.</p>
</div>
<div id="the-sample-size" class="section level5 unnumbered hasAnchor">
<h5>The sample size<a href="confidence-intervals.html#the-sample-size" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>As we studied changes to the confidence level, we can determine how big is the random sample used. The margin of error for a 95% confidence interval is</p>
<p><span class="math display">\[1.96\cdot \frac{\sigma}{\sqrt{n}}.\]</span></p>
<p>If the sample size increases, the margin of error decreases proportional to the square root of the sample size. For example, if we secure a random sample of size 25, <span class="math inline">\(1/\sqrt{25} = 0.2\)</span>, and if we draw a sample of size 100, <span class="math inline">\(1/\sqrt{100} = 0.1\)</span>. By choosing a larger sample size, four times larger, we produce a confidence interval that is half the width. This result is worth considering.</p>
<p>A confidence interval is an estimator of the parameter of interest, such as the population mean weight of almonds. Ideally, we would like to build a confidence interval with a high level of confidence, for example, 95% confidence. But we also want an interval that is narrow enough to provide useful information. For example, assume we get the following 95% confidence intervals for the population mean weight of almonds:</p>
<ul>
<li>between 2 and 4 grams, or</li>
<li>between 3.51 and 3.64 grams, or</li>
<li>between 3.539 and 3.545 grams.</li>
</ul>
<p>The first interval does not seem useful at all, the second works better, and the third is tremendously accurate, as we are 95% confident that the population mean is within 0.006 grams. Obviously, we always prefer narrower intervals, but there are trade-offs we need to consider. We always prefer high levels of confidence, but the more confident we want to be the wider the interval will be. In addition, the larger the random sample used, the narrower the confidence interval will be. Using a large sample is always a preferred choice, but the trade-offs are often external; collecting large samples could be expensive and time-consuming. The construction of confidence intervals needs to take into account all these considerations.</p>
<p>We’ve now concluded the theory-based approach to construct confidence intervals. In the next section we’ll explore a completely different approach to construct confidence intervals, and in later sections we will make comparisons of these methods.</p>
</div>
</div>
</div>
</div>
<div id="simulation-based-CI" class="section level2 hasAnchor" number="36.2">
<h2><span class="header-section-number">36.2</span> Estimation with the bootstrap<a href="confidence-intervals.html#simulation-based-CI" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In 1979, Brad Efron published an article introducing a method called the bootstrap <span class="citation">[@Efron1979]</span> that is next summarized. A random sample of size <span class="math inline">\(n\)</span> is taken from the population.
This sample is used to find another sample, with replacement, also of size <span class="math inline">\(n\)</span>. This is called <em>resampling with replacement</em> and the resulting sample is called a <em>bootstrap sample</em>. For example, if the original sample is <span class="math inline">\(\{4,2,5,4,1,3,7,4,6,1\}\)</span>, one particular bootstrap sample could be <span class="math inline">\(\{6, 4, 7, 4, 2, 7, 2, 5, 4, 1\}.\)</span></p>
<p>Notice that the number 7 appears once in the original sample, but twice in the bootstrap sample;
similarly, the number 3 in the original sample does not appear in the bootstrap sample. This is not uncommon for a bootstrap sample, some of the numbers in the original sample are repeated and others are not included.</p>
<p>The basic idea of the bootstrap is to gain a large number of bootstrap samples, all drawn from the same original sample. Then, we use all these bootstrap samples to find estimates of population parameters, standard errors, or even the density curve of the population. Using them we can construct confidence intervals, perform hypothesis testing, and other inferential methods.</p>
<p>This method takes advantage of the large number of bootstrap samples that can be determined. In several respects, this exercise is not different from the sampling distribution explained in the last module. The only difference, albeit an important one, is that we are not sampling from the population, we are sampling from the original sample.</p>
<p>How many different bootstrap samples could we get from a single sample? A very large number, actually. If the original sample has 10 numbers, as the one shown above, each possible bootstrap sample of size 10 is determined by sampling 10 times with replacement, so the total number of bootstrap samples is <span class="math inline">\(10^{10}\)</span> or 10 billion different bootstrap samples. If the original sample has 20 numbers, the number of bootstrap samples is <span class="math inline">\(20^{20}\)</span>, a number greater than the total number of stars in the universe.</p>
<p>Even with modern powerful computers, it would be an onerous task to calculate every possible bootstrap sample. Instead, a thousand or so bootstrap samples are retrieved, similar to the sampling simulations we previously performed, and this number is often large enough to provide useful results.</p>
<p>Ever since Efron <span class="citation">[@Efron1979]</span> proposed the bootstrap, the statistical community embraced this method. During the 1980s and 1990s, many theoretical and empirical results were presented showing the strength of bootstrap methods. As an illustration, Efron <span class="citation">[@Efron1979]</span>, Hall <span class="citation">[@Hall1986]</span>, Efron and Tibshirani<span class="citation">[@EfronTibshi1986]</span>, and Hall <span class="citation">[@Hall1988]</span> showed that bootstrapping was at least as good if not better than existing methods for estimating the standard error of an estimator or finding the confidence intervals of a parameter. Modifications were proposed to improve the algorithm in situations where the basic method was not producing accurate results. With the continuous improvement of computing power and speed, and the advantages of having ready-to-use statistical software for its implementation, the use of the bootstrap has become more and more popular in many fields.</p>
<p>As an illustration, if we are interested in the mean of the population, <span class="math inline">\(\mu\)</span>, and we have collected one random sample, we can gain a large number of bootstrap samples from this original sample, use them to calculate sample means, order the sample means from smallest to largest, and choose the interval that contains the middle 95% of these sample means. This will be the simplest way to find a confidence interval based on the bootstrap. In the next few subsections, we explore how to incorporate this and similar methods to construct confidence intervals.</p>
<div id="revisit-almond-bootstrap" class="section level3 hasAnchor" number="36.2.1">
<h3><span class="header-section-number">36.2.1</span> Bootstrap samples: revisiting the almond activity<a href="confidence-intervals.html#revisit-almond-bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To study and understand the behavior of bootstrap samples, we return to our example of the chocolate-covered almonds in a bowl. Recall that the bowl is considered the population of almonds, and we are interested in estimating the population mean weight of almonds.</p>
<p>As we did before, we only have access to a single random sample. In this section, we use the data frame <code>almonds_sample_100</code>, a random sample of 100 almonds taken earlier. We call this the original sample, and it is used in this section to create the bootstrap samples.
The first 10 rows are shown:</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="confidence-intervals.html#cb330-1" tabindex="-1"></a>almonds_sample_100</span></code></pre></div>
<pre><code># A tibble: 100 × 3
# Groups:   replicate [1]
   replicate    ID weight
       &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;
 1         1   166    4.2
 2         1  1215    4.2
 3         1  1899    3.9
 4         1  1912    3.8
 5         1  4637    3.3
 6         1   511    3.5
 7         1   127    4  
 8         1  4419    3.5
 9         1  4729    4.2
10         1  2574    4.1
# ℹ 90 more rows</code></pre>
<div id="constructing-a-bootstrap-sample-resampling-once" class="section level4 unnumbered hasAnchor">
<h4>Constructing a bootstrap sample: resampling once<a href="confidence-intervals.html#constructing-a-bootstrap-sample-resampling-once" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We start by constructing one bootstrap sample of 100 almonds from the original sample of 100 almonds. These are the steps needed to perform this task manually:</p>
<p><strong>Step 1</strong>: Place the original sample of 100 almonds into a bag or hat.</p>
<p><strong>Step 2</strong>: Mix the bag contents, draw one almond, weigh it, and record the weight as seen in Figure <a href="confidence-intervals.html#fig:tactile-resampling-2">36.10</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tactile-resampling-2"></span>
<img src="images/sampling/almonds/one-almond.png" alt="Step 2: Weighing one almond at random." width="30%" />
<p class="caption">
Figure 36.10: Step 2: Weighing one almond at random.
</p>
</div>
<p><strong>Step 3</strong>: Put the almond back into the bag! In other words, replace it as seen in Figure <a href="confidence-intervals.html#fig:tactile-resampling-4">36.11</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tactile-resampling-4"></span>
<img src="images/sampling/pennies/tactile_simulation/4_put_it_back.png" alt="Step 3: Replacing almond." width="50%" />
<p class="caption">
Figure 36.11: Step 3: Replacing almond.
</p>
</div>
<p><strong>Step 4</strong>: Repeat Steps 2 and 3 a total of 99 more times, resulting in 100 weights.</p>
<p>These steps describe <em>resampling with replacement</em>, and the resulting sample is called a <em>bootstrap sample</em>. This procedure results in some almonds being chosen more than once and other almonds not being chosen at all. Resampling with replacement induces <em>sampling variation</em>, so every bootstrap sample can be different than any other.</p>
<p>This activity can be performed manually following the steps described above. We can also take advantage of the R code we reviewed when discussing sampling and do this virtually.
The data frame <code>almonds_sample_100</code> contains the random sample of almonds taken from the population. We show selected rows from this sample.</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="confidence-intervals.html#cb332-1" tabindex="-1"></a>almonds_sample_100 <span class="ot">&lt;-</span> almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb332-2"><a href="confidence-intervals.html#cb332-2" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">|&gt;</span> </span>
<span id="cb332-3"><a href="confidence-intervals.html#cb332-3" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>replicate)</span>
<span id="cb332-4"><a href="confidence-intervals.html#cb332-4" tabindex="-1"></a>almonds_sample_100</span></code></pre></div>
<pre><code># A tibble: 100 × 2
      ID weight
   &lt;int&gt;  &lt;dbl&gt;
 1   166    4.2
 2  1215    4.2
 3  1899    3.9
 4  1912    3.8
 5  4637    3.3
 6   511    3.5
 7   127    4  
 8  4419    3.5
 9  4729    4.2
10  2574    4.1
# ℹ 90 more rows</code></pre>
<p>We use <code>ungroup()</code> and <code>select</code> to eliminate the variable <code>replicate</code> from the <code>almonds_sample_100</code> as this variable may create clutter when resampling. We can now create a bootstrap sample also of size 100 by resampling with replacement once.</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="confidence-intervals.html#cb334-1" tabindex="-1"></a>boot_sample <span class="ot">&lt;-</span> almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb334-2"><a href="confidence-intervals.html#cb334-2" tabindex="-1"></a>  <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">reps =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>We used this type of R syntax many times when sampling.
We first select the data frame <code>almonds_sample_100</code> that contains the almonds’ weights in the original sample.
We then perform resampling with replacement once: we resample by using <code>rep_sample_n()</code>, a sample of size 100 by setting <code>size = 100</code>, with replacement by adding the argument <code>replace = TRUE</code>, and one time by setting <code>reps = 1</code>.
The object <code>boot_sample</code> is a bootstrap sample of 100 almonds’ weights gained from the original sample of 100 almonds’ weights. We show the first ten rows of <code>boot_sample</code>:</p>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="confidence-intervals.html#cb335-1" tabindex="-1"></a>boot_sample</span></code></pre></div>
<pre><code># A tibble: 100 × 3
# Groups:   replicate [1]
   replicate    ID weight
       &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;
 1         1  2105    3.1
 2         1  4529    3.8
 3         1  1146    4.2
 4         1  2993    3.2
 5         1  1535    3.2
 6         1  2294    3.7
 7         1   438    3.8
 8         1  4419    3.5
 9         1  1674    3.5
10         1  1146    4.2
# ℹ 90 more rows</code></pre>
<p>We can also study some of the characteristics of this bootstrap sample, such as its sample mean:</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="confidence-intervals.html#cb337-1" tabindex="-1"></a>boot_sample <span class="sc">|&gt;</span> </span>
<span id="cb337-2"><a href="confidence-intervals.html#cb337-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  replicate mean_weight
      &lt;int&gt;       &lt;dbl&gt;
1         1       3.702</code></pre>
<p>By using <code>summarize()</code> and <code>mean()</code> on the bootstrap sample <code>boot_sample</code>, we determine that the mean weight is 3.702 grams. Recall that the sample mean of the original sample was found in the previous subsection as 3.682. So, the sample mean of the bootstrap sample is different than the sample mean of the original sample. This variation is induced by resampling with replacement, the method for finding the bootstrap sample. We can also compare the histogram of <code>weight</code>s for the bootstrap sample with the histogram of <code>weight</code>s for the original sample.</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="confidence-intervals.html#cb339-1" tabindex="-1"></a><span class="fu">ggplot</span>(boot_sample, <span class="fu">aes</span>(<span class="at">x =</span> weight)) <span class="sc">+</span></span>
<span id="cb339-2"><a href="confidence-intervals.html#cb339-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.1</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb339-3"><a href="confidence-intervals.html#cb339-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Resample of 100 weights&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="confidence-intervals.html#cb340-1" tabindex="-1"></a><span class="fu">ggplot</span>(almonds_sample_100, <span class="fu">aes</span>(<span class="at">x =</span> weight)) <span class="sc">+</span></span>
<span id="cb340-2"><a href="confidence-intervals.html#cb340-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.1</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb340-3"><a href="confidence-intervals.html#cb340-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Original sample of 100 weights&quot;</span>)</span></code></pre></div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:origandresample"></span>
<img src="_main_files/figure-html/origandresample-1.png" alt="Comparing weight in the resampled boot_sample with the original sample almonds_sample_100." width="\textwidth" />
<p class="caption">
Figure 36.12: Comparing <code>weight</code> in the resampled <code>boot_sample</code> with the original sample <code>almonds_sample_100</code>.
</p>
</div>
<p>Observe in Figure <a href="confidence-intervals.html#fig:origandresample">36.12</a> that while the general shapes of both distributions of <code>weight</code>s are roughly similar, they are not identical.
This is the typical behavior of bootstrap samples. They are samples that have been determined from the original sample, but because replacement is used before each new observation is attained, some values often appear more than once while others often do not appear at all.</p>
</div>
<div id="replicates" class="section level4 unnumbered hasAnchor">
<h4>Many bootstrap samples: resampling multiple times<a href="confidence-intervals.html#replicates" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In this subsection, we’ll take full advantage of resampling with replacement by taking many bootstrap samples and study relevant information, such as the variability of their sample means. We can start by using the R syntax we used before, this time for 35 replications.</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="confidence-intervals.html#cb341-1" tabindex="-1"></a>bootstrap_samples_35 <span class="ot">&lt;-</span> almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb341-2"><a href="confidence-intervals.html#cb341-2" tabindex="-1"></a>  <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">reps =</span> <span class="dv">35</span>)</span>
<span id="cb341-3"><a href="confidence-intervals.html#cb341-3" tabindex="-1"></a>bootstrap_samples_35</span></code></pre></div>
<pre><code># A tibble: 3,500 × 3
# Groups:   replicate [35]
   replicate    ID weight
       &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;
 1         1  1459    3.6
 2         1  2972    3.4
 3         1  1215    4.2
 4         1  1381    3.4
 5         1  1264    3.5
 6         1   199    3.4
 7         1   476    3.8
 8         1  4806    3.7
 9         1  3169    4.1
10         1  2265    3.4
# ℹ 3,490 more rows</code></pre>
<p>The syntax is the same as before, but this time we set <code>reps =</code> 35 to get 35 bootstrap samples.
The resulting data frame, <code>bootstrap_samples</code>, has 35 <span class="math inline">\(\cdot\)</span> 100 = 3500 rows corresponding to 35 resamples of 100 almonds’ weights. Let’s now compute the resulting 35 sample means using the same <code>dplyr</code> code as we did in the previous section:</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="confidence-intervals.html#cb343-1" tabindex="-1"></a>boot_means <span class="ot">&lt;-</span> bootstrap_samples_35 <span class="sc">|&gt;</span> </span>
<span id="cb343-2"><a href="confidence-intervals.html#cb343-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight))</span>
<span id="cb343-3"><a href="confidence-intervals.html#cb343-3" tabindex="-1"></a>boot_means</span></code></pre></div>
<pre><code># A tibble: 35 × 2
   replicate mean_weight
       &lt;int&gt;       &lt;dbl&gt;
 1         1       3.68 
 2         2       3.688
 3         3       3.632
 4         4       3.68 
 5         5       3.679
 6         6       3.675
 7         7       3.678
 8         8       3.706
 9         9       3.643
10        10       3.68 
# ℹ 25 more rows</code></pre>
<p>Observe that <code>boot_means</code> has 35 rows, corresponding to the 35 bootstrap sample means. Furthermore, observe that the values of <code>mean_weight</code> vary as shown in Figure <a href="confidence-intervals.html#fig:resampling-35">36.13</a>.</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="confidence-intervals.html#cb345-1" tabindex="-1"></a><span class="fu">ggplot</span>(boot_means, <span class="fu">aes</span>(<span class="at">x =</span> mean_weight)) <span class="sc">+</span></span>
<span id="cb345-2"><a href="confidence-intervals.html#cb345-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.01</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb345-3"><a href="confidence-intervals.html#cb345-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;sample mean weight in grams&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:resampling-35"></span>
<img src="_main_files/figure-html/resampling-35-1.png" alt="Distribution of 35 sample means from 35 bootstrap samples." width="\textwidth" />
<p class="caption">
Figure 36.13: Distribution of 35 sample means from 35 bootstrap samples.
</p>
</div>
<p>This histogram highlights the variation of the sample mean weights. Since we have only used 35 bootstrap samples, the histogram looks a little coarse.
To improve our perception of this variation, we find 1000 bootstrap samples and their sample means:</p>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="confidence-intervals.html#cb346-1" tabindex="-1"></a><span class="co"># Retrieve 1000 bootstrap samples</span></span>
<span id="cb346-2"><a href="confidence-intervals.html#cb346-2" tabindex="-1"></a>bootstrap_samples <span class="ot">&lt;-</span> almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb346-3"><a href="confidence-intervals.html#cb346-3" tabindex="-1"></a>  <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb346-4"><a href="confidence-intervals.html#cb346-4" tabindex="-1"></a></span>
<span id="cb346-5"><a href="confidence-intervals.html#cb346-5" tabindex="-1"></a><span class="co"># Compute sample means from the bootstrap samples</span></span>
<span id="cb346-6"><a href="confidence-intervals.html#cb346-6" tabindex="-1"></a>boot_means <span class="ot">&lt;-</span> bootstrap_samples <span class="sc">|&gt;</span> </span>
<span id="cb346-7"><a href="confidence-intervals.html#cb346-7" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight))</span></code></pre></div>
<p>We can combine these two operations into a single chain of pipe (<code>|&gt;</code>) operators:</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="confidence-intervals.html#cb347-1" tabindex="-1"></a>boot_means <span class="ot">&lt;-</span> almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb347-2"><a href="confidence-intervals.html#cb347-2" tabindex="-1"></a>  <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb347-3"><a href="confidence-intervals.html#cb347-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight))</span>
<span id="cb347-4"><a href="confidence-intervals.html#cb347-4" tabindex="-1"></a>boot_means</span></code></pre></div>
<pre><code># A tibble: 1,000 × 2
   replicate mean_weight
       &lt;int&gt;       &lt;dbl&gt;
 1         1       3.68 
 2         2       3.688
 3         3       3.632
 4         4       3.68 
 5         5       3.679
 6         6       3.675
 7         7       3.678
 8         8       3.706
 9         9       3.643
10        10       3.68 
# ℹ 990 more rows</code></pre>
<p>The data frame <code>boot_means</code> contains 1000 sample mean weights. Each is calculated from a different bootstrap sample and visualized in Figure <a href="confidence-intervals.html#fig:one-thousand-sample-means">36.14</a>.</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="confidence-intervals.html#cb349-1" tabindex="-1"></a><span class="fu">ggplot</span>(boot_means, <span class="fu">aes</span>(<span class="at">x =</span> mean_weight)) <span class="sc">+</span></span>
<span id="cb349-2"><a href="confidence-intervals.html#cb349-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.01</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb349-3"><a href="confidence-intervals.html#cb349-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;sample mean weight in grams&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:one-thousand-sample-means"></span>
<img src="_main_files/figure-html/one-thousand-sample-means-1.png" alt="Histogram of 1000 bootstrap sample mean weights of almonds." width="\textwidth" />
<p class="caption">
Figure 36.14: Histogram of 1000 bootstrap sample mean weights of almonds.
</p>
</div>
<p>The histogram is a graphical approximation of the <em>bootstrap distribution of the sample mean</em>. This distribution is constructed by getting all the sample means from every bootstrap sample constructed based on the original sample. Since the total number of possible bootstraps is really large, we have not used all of them here, but 1000 of them already provides a good visual approximation.</p>
<p>Observe also that the bootstrap distribution itself can approximate the <em>sampling distribution</em> of the sample mean, a concept we studied the last module, where we took multiple samples from the population. The key difference here is that we resample from a single sample, the original sample, not from the entire population.</p>
<p>By inspecting the histogram in Figure <a href="confidence-intervals.html#fig:one-thousand-sample-means">36.14</a>, the bell-shape is apparent. We can also approximate the center and the spread of this distribution by computing the mean and the standard deviation of these 1000 bootstrap sample means:</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="confidence-intervals.html#cb350-1" tabindex="-1"></a>boot_means <span class="sc">|&gt;</span> </span>
<span id="cb350-2"><a href="confidence-intervals.html#cb350-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_of_means =</span> <span class="fu">mean</span>(mean_weight),</span>
<span id="cb350-3"><a href="confidence-intervals.html#cb350-3" tabindex="-1"></a>            <span class="at">sd_of_means =</span> <span class="fu">sd</span>(mean_weight))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  mean_of_means sd_of_means
          &lt;dbl&gt;       &lt;dbl&gt;
1       3.67998   0.0356615</code></pre>
<p>Everything we learned when studying the sampling distribution of the sample mean applies here. For example, observe that the mean of these bootstrap sample means is near 3.68 grams, very close to the mean of the original sample: 3.682 grams. Our intention is not to study the distribution of the bootstrap samples, but rather to use them to estimate population values, such as the population mean. In the next section, we discuss how can we use these bootstrap samples to construct <em>confidence intervals</em>.</p>
</div>
</div>
<div id="bootstrap-process" class="section level3 hasAnchor" number="36.2.2">
<h3><span class="header-section-number">36.2.2</span> Confidence intervals and the bootstrap: original workflow<a href="confidence-intervals.html#bootstrap-process" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The process of determining bootstrap samples and using them for <em>estimation</em> is called <em>bootstrapping</em>.
We can estimate population parameters such as the mean, median, or standard deviation. We can also construct confidence intervals.</p>
<p>In this subsection, let’s focus on the latter and construct confidence intervals based on bootstrap samples. For this, we review the R syntax and workflow we have already used in previous sections and also introduce a new package: the <code>infer</code> package for tidy and transparent statistical inference.</p>
<div id="original-workflow" class="section level4 unnumbered hasAnchor">
<h4>Original workflow<a href="confidence-intervals.html#original-workflow" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Recall that we took bootstrap samples, then calculated the sample means from these samples. Let’s revisit the original workflow using <code>dplyr</code> verbs and the <code>|&gt;</code> operator.</p>
<p>First, we’ll use <code>rep_sample_n()</code> to resample from the original sample <code>almonds_sample_100</code> of 25 almonds. Let’s set <code>size = 100</code> to generate bootstrap samples of the same size as the original sample, and we resample with replacement by setting <code>replace = TRUE</code>. We’ll create 1000 bootstrap samples by setting <code>reps = 1000</code>:</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="confidence-intervals.html#cb352-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb352-2"><a href="confidence-intervals.html#cb352-2" tabindex="-1"></a>  <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">reps =</span> <span class="dv">1000</span>)</span></code></pre></div>
<p>Second, let’s add another pipe followed by <code>summarize()</code> to compute the sample <code>mean()</code> weight for each <code>replicate</code>:</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="confidence-intervals.html#cb353-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb353-2"><a href="confidence-intervals.html#cb353-2" tabindex="-1"></a>  <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb353-3"><a href="confidence-intervals.html#cb353-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight))</span></code></pre></div>
<p>For this simple case, all we needed was to use the <code>rep_sample_n()</code> function and a <code>dplyr</code> verb. However, using only <code>dplyr</code> verbs provides us with a limited set of tools that is not ideal when working with more complicated situations. This is the reason we introduce the <code>infer</code> package.</p>
</div>
</div>
<div id="infer-workflow" class="section level3 hasAnchor" number="36.2.3">
<h3><span class="header-section-number">36.2.3</span> The <code>infer</code> package workflow:<a href="confidence-intervals.html#infer-workflow" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <code>infer</code> package is an R package for statistical inference. It makes efficient use of the <code>|&gt;</code> pipe operator we introduced in Section <a href="m6a-wrangling-and-tidying-data.html#piping">18.2.1</a> to spell out the sequence of steps necessary to perform statistical inference in a “tidy” and transparent fashion. Just as the <code>dplyr</code> package provides functions with verb-like names to perform data wrangling, the <code>infer</code> package provides functions with intuitive verb-like names to perform statistical inference, such as constructing confidence intervals or performing hypothesis testing. We have discussed the theory-based implementation of the former in section <a href="confidence-intervals.html#CI-general">36.1.3</a> and we’ll introduce the latter when we discuss hypothesis testing in the next module.</p>
<p>Using the example of almonds’ weights, let’s introduce <code>infer</code>by comparing its implementation with <code>dplyr</code>. Remember that to calculate a sample statistic or point estimate from a sample, such as the sample mean, when using <code>dplyr</code> we use <code>summarize()</code> and <code>mean()</code>:</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="confidence-intervals.html#cb354-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb354-2"><a href="confidence-intervals.html#cb354-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">stat =</span> <span class="fu">mean</span>(weight))</span></code></pre></div>
<p>If we want to use <code>infer</code> instead, we use the functions <code>specify()</code> and <code>calculate()</code> as shown:</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="confidence-intervals.html#cb355-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb355-2"><a href="confidence-intervals.html#cb355-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">response =</span> weight) <span class="sc">|&gt;</span> </span>
<span id="cb355-3"><a href="confidence-intervals.html#cb355-3" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;mean&quot;</span>)</span></code></pre></div>
<p>The new structure using <code>infer</code> seems slightly more complicated than the one using <code>dplyr</code> for this simple calculation. However, these functions will provide three chief benefits moving forward.</p>
<ul>
<li><p>First, the <code>infer</code> verb names better align with the overall simulation-based framework you need to understand to construct confidence intervals and to conduct hypothesis tests (in the next module).</p></li>
<li><p>Third, the <code>infer</code> workflow is much simpler for conducting inference when you have <em>more than one variable</em>. Later, we’ll look at <em>two-sample</em> inference where the sample data is collected from two groups, and this will come in handy there.</p></li>
</ul>
<p>Let’s now illustrate the sequence of verbs necessary to construct a confidence interval for <span class="math inline">\(\mu\)</span>, the population mean weight of almonds.</p>
<div id="specify-variables" class="section level4 unnumbered hasAnchor">
<h4>1. <code>specify</code> variables<a href="confidence-intervals.html#specify-variables" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:infer-specify"></span>
<img src="images/flowcharts/infer/specify.png" alt="Diagram of the specify() verb." width="40%" />
<p class="caption">
Figure 36.15: Diagram of the specify() verb.
</p>
</div>
<p>As shown in Figure <a href="confidence-intervals.html#fig:infer-specify">36.15</a>, the <code>specify()</code> function is used to choose which variables in a data frame are the focus of our statistical inference. We do this by <code>specify</code>ing the <code>response</code> argument. For example, in our <code>almonds_sample_100</code> data frame of the 100 almonds sampled from the bowl, the variable of interest is <code>weight</code>:</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="confidence-intervals.html#cb356-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb356-2"><a href="confidence-intervals.html#cb356-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">response =</span> weight)</span></code></pre></div>
<pre><code>Response: weight (numeric)
# A tibble: 100 × 1
   weight
    &lt;dbl&gt;
 1    4.2
 2    4.2
 3    3.9
 4    3.8
 5    3.3
 6    3.5
 7    4  
 8    3.5
 9    4.2
10    4.1
# ℹ 90 more rows</code></pre>
<p>Notice how the data itself does not change, but the <code>Response: weight (numeric)</code> <em>meta-data</em> does. This is similar to how the <code>group_by()</code> verb from <code>dplyr</code> doesn’t change the data, but only adds “grouping” meta-data, as we saw in Section <a href="m8a-descriptive-statistics.html#groupby">24.3</a>.</p>
<p>We can also specify which variables are the focus of the study by introducing a <code>formula = y ~ x</code> in <code>specify()</code>. This is the same formula notation you saw when first working with regression models: the response variable <code>y</code> is separated from the explanatory variable <code>x</code> by a <code>~</code> (“tilde”). The following use of <code>specify()</code> with the <code>formula</code> argument yields the same result seen previously:</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="confidence-intervals.html#cb358-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb358-2"><a href="confidence-intervals.html#cb358-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">formula =</span> weight <span class="sc">~</span> <span class="cn">NULL</span>)</span></code></pre></div>
<p>In the case of almonds, we only have a response variable and no explanatory variable of interest. Thus, we set the <code>x</code> on the right-hand side of the <code>~</code> to be <code>NULL</code>.</p>
<p>In cases where inference is focused on a single sample, as it is the almonds’ weights example, either specification works. In the examples we present in later sections, the <code>formula</code> specification is simpler and more flexible.</p>
</div>
<div id="generate-replicates" class="section level4 unnumbered hasAnchor">
<h4>2. <code>generate</code> replicates<a href="confidence-intervals.html#generate-replicates" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:infer-generate"></span>
<img src="images/flowcharts/infer/generate.png" alt="Diagram of generate() replicates." width="40%" />
<p class="caption">
Figure 36.16: Diagram of generate() replicates.
</p>
</div>
<p>After we <code>specify()</code> the variables of interest, we pipe the results into the <code>generate()</code> function to generate replicates. This is the function that produces the bootstrap samples or performs the similar resampling process a large number of times, based on the variable(s) specified previously, as shown in Figure <a href="confidence-intervals.html#fig:infer-generate">36.16</a>. Recall we did this 1000 times.</p>
<p>The <code>generate()</code> function’s first argument is <code>reps</code>, which sets the number of replicates we would like to generate. Since we want to resample the 100 almonds in <code>almonds_sample_100</code> with replacement 1000 times, we set <code>reps = 1000</code>.</p>
<p>The second argument <code>type</code> determines the type of computer simulation used. Setting this to <code>type = "bootstrap"</code> produces bootstrap samples using resampling with replacement. We’ll see different options for <code>type</code> in a later walkthrough.</p>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="confidence-intervals.html#cb359-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb359-2"><a href="confidence-intervals.html#cb359-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">response =</span> weight) <span class="sc">|&gt;</span> </span>
<span id="cb359-3"><a href="confidence-intervals.html#cb359-3" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>, <span class="at">type =</span> <span class="st">&quot;bootstrap&quot;</span>)</span></code></pre></div>
<pre><code>Response: weight (numeric)
# A tibble: 100,000 × 2
# Groups:   replicate [1,000]
   replicate weight
       &lt;int&gt;  &lt;dbl&gt;
 1         1    3.6
 2         1    3.4
 3         1    4.2
 4         1    3.4
 5         1    3.5
 6         1    3.4
 7         1    3.8
 8         1    3.7
 9         1    4.1
10         1    3.4
# ℹ 99,990 more rows</code></pre>
<p>Notice that the resulting data frame has 100,000 rows. This is because we have found 1000 bootstrap samples, each with 100 rows.</p>
<p>The variable <code>replicate</code> indicates the bootstrap sample each row belongs to, from <code>1</code> to 1000, each replicate repeated 100 times. The default value of the <code>type</code> argument is <code>"bootstrap"</code> in this scenario, so the inclusion was only made for completeness. If the last line was written simply as <code>generate(reps = 1000)</code>, the result would be the same.</p>
<p><strong>Comparing with original workflow</strong>: Note that the steps of the <code>infer</code> workflow so far produce the same results as the original workflow using the <code>rep_sample_n()</code> function we saw earlier. In other words, the following two code chunks produce similar results:</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="confidence-intervals.html#cb361-1" tabindex="-1"></a><span class="co"># infer workflow:                   # Original workflow:</span></span>
<span id="cb361-2"><a href="confidence-intervals.html#cb361-2" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span>               almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb361-3"><a href="confidence-intervals.html#cb361-3" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">response =</span> weight) <span class="sc">|&gt;</span>        <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, </span>
<span id="cb361-4"><a href="confidence-intervals.html#cb361-4" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>)                             <span class="at">reps =</span> <span class="dv">1000</span>)              </span></code></pre></div>
</div>
<div id="calculate-summary-statistics" class="section level4 unnumbered hasAnchor">
<h4>3. <code>calculate</code> summary statistics<a href="confidence-intervals.html#calculate-summary-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:infer-calculate"></span>
<img src="images/flowcharts/infer/calculate.png" alt="Diagram of calculate() summary statistics." width="50%" />
<p class="caption">
Figure 36.17: Diagram of calculate() summary statistics.
</p>
</div>
<p>After we <code>generate()</code> 1000 bootstrap samples, we want to summarize each of them, for example, by calculating the sample mean of each one of them. As Figure <a href="confidence-intervals.html#fig:infer-calculate">36.17</a> shows, the <code>calculate()</code> function does this.</p>
<p>In our example, we calculate the mean <code>weight</code> for each bootstrap sample by setting the <code>stat</code> argument equal to <code>"mean"</code> inside the <code>calculate()</code> function. The <code>stat</code> argument can be used for other common summary statistics such as <code>"median"</code>, <code>"sum"</code>, <code>"sd"</code> (standard deviation), and <code>"prop"</code> (proportion). To see a list of other possible summary statistics you can use, type <code>?calculate</code> and read the help file.</p>
<p>Let’s save the result in a data frame called <code>bootstrap_means</code> and explore its contents:</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="confidence-intervals.html#cb362-1" tabindex="-1"></a>bootstrap_means <span class="ot">&lt;-</span> almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb362-2"><a href="confidence-intervals.html#cb362-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">response =</span> weight) <span class="sc">|&gt;</span> </span>
<span id="cb362-3"><a href="confidence-intervals.html#cb362-3" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb362-4"><a href="confidence-intervals.html#cb362-4" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;mean&quot;</span>)</span></code></pre></div>
<pre><code>Setting `type = &quot;bootstrap&quot;` in `generate()`.</code></pre>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="confidence-intervals.html#cb364-1" tabindex="-1"></a>bootstrap_means</span></code></pre></div>
<pre><code>Response: weight (numeric)
# A tibble: 1,000 × 2
   replicate  stat
       &lt;int&gt; &lt;dbl&gt;
 1         1 3.68 
 2         2 3.688
 3         3 3.632
 4         4 3.68 
 5         5 3.679
 6         6 3.675
 7         7 3.678
 8         8 3.706
 9         9 3.643
10        10 3.68 
# ℹ 990 more rows</code></pre>
<p>Observe that the resulting data frame has 1000 rows and 2 columns corresponding to the 1000 <code>replicate</code> values. It also has the mean weight for each bootstrap sample saved in the variable <code>stat</code>.</p>
<p><strong>Comparing with original workflow</strong>: You may have recognized at this point that the <code>calculate()</code> step in the <code>infer</code> workflow produces the same output as the <code>summarize()</code> step in the original workflow.</p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="confidence-intervals.html#cb366-1" tabindex="-1"></a><span class="co"># infer workflow:                   # Original workflow:</span></span>
<span id="cb366-2"><a href="confidence-intervals.html#cb366-2" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span>                  almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb366-3"><a href="confidence-intervals.html#cb366-3" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">response =</span> weight) <span class="sc">|&gt;</span>        <span class="fu">rep_sample_n</span>(<span class="at">size =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, </span>
<span id="cb366-4"><a href="confidence-intervals.html#cb366-4" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span>                          <span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span>              </span>
<span id="cb366-5"><a href="confidence-intervals.html#cb366-5" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;mean&quot;</span>)             <span class="fu">summarize</span>(<span class="at">stat =</span> <span class="fu">mean</span>(weight))</span></code></pre></div>
</div>
<div id="visualize-the-results" class="section level4 unnumbered hasAnchor">
<h4>4. <code>visualize</code> the results<a href="confidence-intervals.html#visualize-the-results" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:infer-visualize"></span>
<img src="images/flowcharts/infer/visualize.png" alt="Diagram of visualize() results." width="60%" />
<p class="caption">
Figure 36.18: Diagram of visualize() results.
</p>
</div>
<p>The <code>visualize()</code> verb provides a quick way to visualize the bootstrap distribution as a histogram of the numerical <code>stat</code> variable’s values as shown in Figure <a href="confidence-intervals.html#fig:bootstrap-distribution-infer">36.19</a>. The pipeline of the main <code>infer</code> verbs used for exploring bootstrap distribution results is shown in Figure <a href="confidence-intervals.html#fig:infer-visualize">36.18</a>.</p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="confidence-intervals.html#cb367-1" tabindex="-1"></a><span class="fu">visualize</span>(bootstrap_means)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bootstrap-distribution-infer"></span>
<img src="_main_files/figure-html/bootstrap-distribution-infer-1.png" alt="Bootstrap distribution." width="\textwidth" />
<p class="caption">
Figure 36.19: Bootstrap distribution.
</p>
</div>
<p><strong>Comparing with original workflow</strong>: In fact, <code>visualize()</code> is a <em>wrapper function</em> for the <code>ggplot()</code> function that uses a <code>geom_histogram()</code> layer. Recall that we illustrated the concept of a wrapper function in Figure <a href="m9a-basic-regression.html#fig:moderndive-figure-wrapper">27.5</a> in Subsection <a href="m9a-basic-regression.html#model1table">27.2.2</a>.</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="confidence-intervals.html#cb368-1" tabindex="-1"></a><span class="co"># infer workflow:                    # Original workflow:</span></span>
<span id="cb368-2"><a href="confidence-intervals.html#cb368-2" tabindex="-1"></a><span class="fu">visualize</span>(bootstrap_means)           <span class="fu">ggplot</span>(bootstrap_means, <span class="fu">aes</span>(<span class="at">x =</span> stat)) <span class="sc">+</span></span>
<span id="cb368-3"><a href="confidence-intervals.html#cb368-3" tabindex="-1"></a>                                        <span class="fu">geom_histogram</span>()</span></code></pre></div>
<p>The <code>visualize()</code> function can take many other arguments to customize the plot further. In later sections, we’ll take advantage of this flexibility. In addition, it works with helper functions to add shading of the histogram values corresponding to the confidence interval values.</p>
<p>We’ve now considered the different elements of the <code>infer</code> workflow for constructing a bootstrap distribution and visualizing it. A summary of these steps is presented in Figure <a href="confidence-intervals.html#fig:infer-workflow-ci">36.20</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:infer-workflow-ci"></span>
<img src="images/flowcharts/infer/ci_diagram.png" alt="infer package workflow for confidence intervals." width="80%" />
<p class="caption">
Figure 36.20: infer package workflow for confidence intervals.
</p>
</div>
</div>
</div>
<div id="conf-int-infer" class="section level3 hasAnchor" number="36.2.4">
<h3><span class="header-section-number">36.2.4</span> Confidence intervals using bootstrap samples with <code>infer</code><a href="confidence-intervals.html#conf-int-infer" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now, we’re ready to introduce confidence intervals using the bootstrap via <code>infer</code>. Let’s look at two different methods for constructing 95% confidence intervals as interval estimates of an unknown population parameter: the <em>percentile method</em> and the <em>standard error method</em>{Bootstrap!standard error method}. Let’s now check out the <code>infer</code> package code that explicitly constructs these. There are also some additional neat functions to visualize the resulting confidence intervals built-in to the <code>infer</code> package.</p>
<div id="percentile-method-infer" class="section level4 unnumbered hasAnchor">
<h4>Percentile method<a href="confidence-intervals.html#percentile-method-infer" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Recall that in Subsection <a href="confidence-intervals.html#infer-workflow">36.2.3</a>, we generated 1000 bootstrap samples and stored them in data frame <code>bootstrap_means</code>:</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="confidence-intervals.html#cb369-1" tabindex="-1"></a>bootstrap_means</span></code></pre></div>
<pre><code>Response: weight (numeric)
# A tibble: 1,000 × 2
   replicate  stat
       &lt;int&gt; &lt;dbl&gt;
 1         1 3.68 
 2         2 3.688
 3         3 3.632
 4         4 3.68 
 5         5 3.679
 6         6 3.675
 7         7 3.678
 8         8 3.706
 9         9 3.643
10        10 3.68 
# ℹ 990 more rows</code></pre>
<p>The sample means stored in <code>bootstrap_means</code> represent a good approximation to the bootstrap distribution of all possible bootstrap samples. The percentile method for constructing 95% confidence intervals sets the lower endpoint of the confidence interval at the 2.5th percentile of <code>bootstrap_means</code> and similarly sets the upper endpoint at the 97.5th percentile. The resulting interval captures the middle 95% of the values of the sample mean weights of almonds in <code>bootstrap_means</code>. This is the interval estimate of the population mean weight of almonds in the entire bowl.</p>
<p>We can compute the 95% confidence interval by piping <code>bootstrap_means</code> into the <code>get_confidence_interval()</code> function from the <code>infer</code> package, with the confidence <code>level</code> set to 0.95 and the confidence interval <code>type</code> to be <code>"percentile"</code>. We save the results in <code>percentile_ci</code>.</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="confidence-intervals.html#cb371-1" tabindex="-1"></a>percentile_ci <span class="ot">&lt;-</span> bootstrap_means <span class="sc">|&gt;</span> </span>
<span id="cb371-2"><a href="confidence-intervals.html#cb371-2" tabindex="-1"></a>  <span class="fu">get_confidence_interval</span>(<span class="at">level =</span> <span class="fl">0.95</span>, <span class="at">type =</span> <span class="st">&quot;percentile&quot;</span>)</span>
<span id="cb371-3"><a href="confidence-intervals.html#cb371-3" tabindex="-1"></a>percentile_ci</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  lower_ci upper_ci
     &lt;dbl&gt;    &lt;dbl&gt;
1  3.61198    3.756</code></pre>
<p>Alternatively, we can visualize the interval (3.61, 3.76) by piping the <code>bootstrap_means</code> data frame into the <code>visualize()</code> function and adding a <code>shade_confidence_interval()</code> layer. We set the <code>endpoints</code> argument to be <code>percentile_ci</code>.</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="confidence-intervals.html#cb373-1" tabindex="-1"></a><span class="fu">visualize</span>(bootstrap_means) <span class="sc">+</span> </span>
<span id="cb373-2"><a href="confidence-intervals.html#cb373-2" tabindex="-1"></a>  <span class="fu">shade_confidence_interval</span>(<span class="at">endpoints =</span> percentile_ci)</span></code></pre></div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:percentile-ci-viz"></span>
<img src="_main_files/figure-html/percentile-ci-viz-1.png" alt="Percentile method 95% confidence interval shaded corresponding to potential values." width="\textwidth" />
<p class="caption">
Figure 36.21: Percentile method 95% confidence interval shaded corresponding to potential values.
</p>
</div>
<p>Notice in Figure <a href="confidence-intervals.html#fig:percentile-ci-viz">36.21</a> that 95% of the sample means stored in the <code>stat</code> variable in <code>bootstrap_means</code> fall between the two endpoints marked with the darker lines, with 2.5% of the sample means to the left of the shaded area and 2.5% of the sample means to the right. You also have the option to change the colors of the shading using the <code>color</code> and <code>fill</code> arguments.</p>
<p>The <code>infer</code> package has incorporated a shorter named function <code>shade_ci()</code> that produces the same results. Try out the following code:</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="confidence-intervals.html#cb374-1" tabindex="-1"></a><span class="fu">visualize</span>(bootstrap_means) <span class="sc">+</span> </span>
<span id="cb374-2"><a href="confidence-intervals.html#cb374-2" tabindex="-1"></a>  <span class="fu">shade_ci</span>(<span class="at">endpoints =</span> percentile_ci, <span class="at">color =</span> <span class="st">&quot;hotpink&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;khaki&quot;</span>)</span></code></pre></div>
</div>
<div id="se-infer" class="section level4 unnumbered hasAnchor">
<h4>Standard error method<a href="confidence-intervals.html#se-infer" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In Subsection <a href="confidence-intervals.html#CI-general">36.1.3</a> we introduced theory-based confidence intervals. A 95% confidence interval can be constructed as</p>
<p><span class="math display">\[\left(\overline{x} - 1.96 \cdot SE(\bar x), \quad \overline{x} + 1.96 \cdot SE(\bar x)\right)\]</span></p>
<p>where <span class="math inline">\(\overline{x}\)</span> is the sample mean of the original sample, 1.96 is the number of standard errors around the mean needed to account for 95% of the area under the density curve (when the distribution is normal), and <span class="math inline">\(SE(\bar x)\)</span> is the standard error of the sample mean that can be computed as <span class="math inline">\(\sigma /\sqrt{n}\)</span> if the population standard deviation is known, or estimated as <span class="math inline">\(s/\sqrt{n}\)</span> if we have to use the sample standard deviation, <span class="math inline">\(s\)</span>, and the sample size, <span class="math inline">\(n\)</span>.</p>
<p>We can use the same structure to construct confidence intervals but using the bootstrap sample means to estimate the standard error of <span class="math inline">\(\overline{x}\)</span>.
Thus, the 95% confidence interval for the population mean, <span class="math inline">\(\mu\)</span>, using the standard error estimated via bootstrapping, <span class="math inline">\(SE_\text{boot}\)</span>, is:</p>
<p><span class="math display">\[\left(\overline{x} - 1.96 \cdot SE_{\text{boot}}, \quad \overline{x} + 1.96 \cdot SE_{\text{boot}}\right)\]</span></p>
<p>We can compute this confidence interval using <code>dplyr</code>. First, we calculate the estimated standard error:</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="confidence-intervals.html#cb375-1" tabindex="-1"></a>SE_boot <span class="ot">&lt;-</span> bootstrap_means <span class="sc">|&gt;</span></span>
<span id="cb375-2"><a href="confidence-intervals.html#cb375-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">SE =</span> <span class="fu">sd</span>(stat)) <span class="sc">|&gt;</span></span>
<span id="cb375-3"><a href="confidence-intervals.html#cb375-3" tabindex="-1"></a>  <span class="fu">pull</span>(SE)</span>
<span id="cb375-4"><a href="confidence-intervals.html#cb375-4" tabindex="-1"></a>SE_boot</span></code></pre></div>
<pre><code>[1] 0.0357</code></pre>
<p>and then use the original sample mean to calculate the 95% confidence interval:</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="confidence-intervals.html#cb377-1" tabindex="-1"></a>almonds_sample_100 <span class="sc">|&gt;</span></span>
<span id="cb377-2"><a href="confidence-intervals.html#cb377-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">lower_bound =</span> <span class="fu">mean</span>(weight) <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> SE_boot,</span>
<span id="cb377-3"><a href="confidence-intervals.html#cb377-3" tabindex="-1"></a>            <span class="at">upper_bound =</span> <span class="fu">mean</span>(weight) <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> SE_boot)</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  lower_bound upper_bound
        &lt;dbl&gt;       &lt;dbl&gt;
1     3.61210     3.75190</code></pre>
<p>Alternatively, computation of the 95% confidence interval can once again be done via <code>infer</code>. Let’s find the sample mean of the original sample and store it in variable <code>x_bar</code></p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="confidence-intervals.html#cb379-1" tabindex="-1"></a>x_bar <span class="ot">&lt;-</span> almonds_sample_100 <span class="sc">|&gt;</span> </span>
<span id="cb379-2"><a href="confidence-intervals.html#cb379-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">response =</span> weight) <span class="sc">|&gt;</span> </span>
<span id="cb379-3"><a href="confidence-intervals.html#cb379-3" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;mean&quot;</span>)</span>
<span id="cb379-4"><a href="confidence-intervals.html#cb379-4" tabindex="-1"></a>x_bar</span></code></pre></div>
<pre><code>Response: weight (numeric)
# A tibble: 1 × 1
   stat
  &lt;dbl&gt;
1 3.682</code></pre>
<p>Now, we can pipe the <code>bootstrap_means</code> data frame we created into the <code>get_confidence_interval()</code> function. We’ll set the <code>type</code> argument to be <code>"se"</code> and specify the <code>point_estimate</code> argument to be <code>x_bar</code> in order to set the center of the confidence interval to the sample mean of the original sample.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="confidence-intervals.html#cb381-1" tabindex="-1"></a>standard_error_ci <span class="ot">&lt;-</span> bootstrap_means <span class="sc">|&gt;</span> </span>
<span id="cb381-2"><a href="confidence-intervals.html#cb381-2" tabindex="-1"></a>  <span class="fu">get_confidence_interval</span>(<span class="at">type =</span> <span class="st">&quot;se&quot;</span>, <span class="at">point_estimate =</span> x_bar, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb381-3"><a href="confidence-intervals.html#cb381-3" tabindex="-1"></a>standard_error_ci</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  lower_ci upper_ci
     &lt;dbl&gt;    &lt;dbl&gt;
1  3.61210  3.75190</code></pre>
<p>The results are the same whether <code>dplyr</code> or <code>infer</code> is used, but as explained earlier, the latter provides more flexibility for other tests.</p>
<p>If we would like to visualize the interval (3.61, 3.75), we can once again pipe the <code>bootstrap_means</code> data frame into the <code>visualize()</code> function and add a <code>shade_confidence_interval()</code> layer to our plot. We set the <code>endpoints</code> argument to be <code>standard_error_ci</code>. The resulting standard-error method based on a 95% confidence interval for <span class="math inline">\(\mu\)</span> can be seen in Figure <a href="confidence-intervals.html#fig:se-ci-viz">36.22</a>.</p>

<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="confidence-intervals.html#cb383-1" tabindex="-1"></a><span class="fu">visualize</span>(bootstrap_means) <span class="sc">+</span> </span>
<span id="cb383-2"><a href="confidence-intervals.html#cb383-2" tabindex="-1"></a>  <span class="fu">shade_confidence_interval</span>(<span class="at">endpoints =</span> standard_error_ci)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:se-ci-viz"></span>
<img src="_main_files/figure-html/se-ci-viz-1.png" alt="Standard-error method 95% confidence interval." width="\textwidth" />
<p class="caption">
Figure 36.22: Standard-error method 95% confidence interval.
</p>
</div>
<p>Because we are using bootstrap samples to construct these intervals, we call the percentile and standard error methods simulation-based methods. We can compare the 95% confidence intervals from using both simulation-based methods as well as the one attained using the theory-based method described in <a href="confidence-intervals.html#CI-general">36.1.3</a>:</p>
<ul>
<li>Percentile method: (3.61, 3.76)</li>
<li>Standard error method: (3.61, 3.75)</li>
<li>Theory-based method: (3.61, 3.76)</li>
</ul>
</div>
</div>
</div>
<div id="case-study-two-prop-ci" class="section level2 hasAnchor" number="36.3">
<h2><span class="header-section-number">36.3</span> Case study: is yawning contagious?<a href="confidence-intervals.html#case-study-two-prop-ci" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s apply our knowledge of confidence intervals to answer the question: “Is yawning contagious?”. If you see someone else yawn, are you more likely to yawn? In an episode of the US show <em>Mythbusters</em> that aired on Discovery, the hosts conducted an experiment to answer this question. More information about the episode is available on <a href="https://www.imdb.com/title/tt0768479/">IMDb</a>.</p>
<div id="mythbusters-study-data" class="section level3 hasAnchor" number="36.3.1">
<h3><span class="header-section-number">36.3.1</span> <em>Mythbusters</em> study data<a href="confidence-intervals.html#mythbusters-study-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Fifty adult participants who thought they were being considered for an appearance on the show were interviewed by a show recruiter. In the interview, the recruiter either yawned or did not. Participants then sat by themselves in a large van and were asked to wait. While in the van, the <em>Mythbusters</em> team watched the participants using a hidden camera to see if they yawned. The data frame containing the results of their experiment is available as <code>mythbusters_yawn</code> included in the <code>moderndive</code> package: </p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="confidence-intervals.html#cb384-1" tabindex="-1"></a>mythbusters_yawn</span></code></pre></div>
<pre><code># A tibble: 50 × 3
    subj group   yawn 
   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
 1     1 seed    yes  
 2     2 control yes  
 3     3 seed    no   
 4     4 seed    yes  
 5     5 seed    no   
 6     6 control no   
 7     7 seed    yes  
 8     8 control no   
 9     9 control no   
10    10 seed    no   
# ℹ 40 more rows</code></pre>
<p>The variables are:</p>
<ul>
<li><code>subj</code>: The participant ID with values 1 through 50.</li>
<li><code>group</code>: A binary <em>treatment</em> variable indicating whether the participant was exposed to yawning. <code>"seed"</code> indicates the participant was exposed to yawning while <code>"control"</code> indicates the participant was not.</li>
<li><code>yawn</code>: A binary <em>response</em> variable indicating whether the participant ultimately yawned.</li>
</ul>
<p>Recall that you learned about treatment and response variables in our discussion on confounding variables.</p>
<p>Let’s use some data wrangling to calculate counts of the four possible outcomes:</p>
<div class="sourceCode" id="cb386"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb386-1"><a href="confidence-intervals.html#cb386-1" tabindex="-1"></a>mythbusters_yawn <span class="sc">|&gt;</span> </span>
<span id="cb386-2"><a href="confidence-intervals.html#cb386-2" tabindex="-1"></a>  <span class="fu">group_by</span>(group, yawn) <span class="sc">|&gt;</span> </span>
<span id="cb386-3"><a href="confidence-intervals.html#cb386-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">count =</span> <span class="fu">n</span>(), <span class="at">.groups =</span> <span class="st">&quot;keep&quot;</span>)</span></code></pre></div>
<pre><code># A tibble: 4 × 3
# Groups:   group, yawn [4]
  group   yawn  count
  &lt;chr&gt;   &lt;chr&gt; &lt;int&gt;
1 control no       12
2 control yes       4
3 seed    no       24
4 seed    yes      10</code></pre>
<p>Let’s first focus on the <code>"control"</code> group participants who were not exposed to yawning. 12 such participants did not yawn, while 4 such participants did. So out of the 16 people who were not exposed to yawning, 4/16 = 0.25 = 25% did yawn.</p>
<p>Let’s now focus on the <code>"seed"</code> group participants who were exposed to yawning where 24 such participants did not yawn, while 10 such participants did yawn. So out of the 34 people who were exposed to yawning, 10/34 = 0.294 = 29.4% did yawn. Comparing these two percentages, the participants who were exposed to yawning yawned 29.4% - 25% = 4.4% more often than those who were not.</p>
</div>
<div id="sampling-scenario" class="section level3 hasAnchor" number="36.3.2">
<h3><span class="header-section-number">36.3.2</span> Sampling scenario<a href="confidence-intervals.html#sampling-scenario" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s review the terminology and notation related to sampling we studied in Subsection <a href="m11a-sampling.html#terminology-and-notation">33.2.1</a>. In the walkthrough on sampling, our <em>study population</em> was the bowl of <span class="math inline">\(N\)</span> = 2400 balls. Our <em>population parameter</em> of interest was the <em>population proportion</em> of these balls that were red, denoted mathematically by <span class="math inline">\(p\)</span>. In order to estimate <span class="math inline">\(p\)</span>, we extracted a sample of 50 balls using the shovel and computed the relevant <em>point estimate</em>: the <em>sample proportion</em> that were red, denoted mathematically by <span class="math inline">\(\widehat{p}\)</span>.</p>
<p>Who is the study population here? All humans? All the people who watch the show <em>Mythbusters</em>? It’s hard to say! This question can only be answered if we know how the show’s hosts recruited participants! In other words, what was the <em>sampling methodology</em> used by the <em>Mythbusters</em> to recruit participants? Alas, we do not have access to this information. For the purposes of this case study, however, we’ll <em>assume</em> that the 50 participants are a representative sample of all Americans given the popularity of this show. Thus, we’ll be assuming that any results of this experiment will generalize to all <span class="math inline">\(N\)</span> = 346 million Americans (2024 population estimate).</p>
<p>Just like with our sampling bowl, the population parameter here will involve proportions. However, in this case, it will be the <em>difference in population proportions</em> <span class="math inline">\(p_{seed} - p_{control}\)</span>, where <span class="math inline">\(p_{seed}\)</span> is the proportion of <em>all</em> Americans who if exposed to yawning will yawn themselves, and <span class="math inline">\(p_{control}\)</span> is the proportion of <em>all</em> Americans who if not exposed to yawning still yawn themselves. Correspondingly, the point estimate/sample statistic based on the <em>Mythbusters</em>’ sample of participants will be the <em>difference in sample proportions</em> <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span>. Let’s extend Table <a href="confidence-intervals.html#tab:table-ch8-c">36.1</a> of scenarios of sampling for inference to include our latest scenario.</p>
<table class="table" style="font-size: 16px; color: black; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:table-ch8-c">Table 36.1: </span>Scenarios of sampling for inference
</caption>
<thead>
<tr>
<th style="text-align:right;">
Scenario
</th>
<th style="text-align:left;">
Population parameter
</th>
<th style="text-align:left;">
Notation
</th>
<th style="text-align:left;">
Point estimate
</th>
<th style="text-align:left;">
Symbol(s)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;width: 0.5in; ">
1
</td>
<td style="text-align:left;width: 1.5in; ">
Population proportion
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 1.6in; ">
Sample proportion
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(\widehat{p}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
2
</td>
<td style="text-align:left;width: 1.5in; ">
Population mean
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 1.6in; ">
Sample mean
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{\mu}\)</span>
</td>
</tr>
<tr>
<td style="text-align:right;width: 0.5in; ">
3
</td>
<td style="text-align:left;width: 1.5in; ">
Difference in population proportions
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(p_1 - p_2\)</span>
</td>
<td style="text-align:left;width: 1.6in; ">
Difference in sample proportions
</td>
<td style="text-align:left;width: 0.65in; ">
<span class="math inline">\(\widehat{p}_1 - \widehat{p}_2\)</span>
</td>
</tr>
</tbody>
</table>
<p>This is known as a <em>two-sample</em> inference situation since we have two separate samples. Based on their two-samples of size <span class="math inline">\(n_{seed}\)</span> = 34 and <span class="math inline">\(n_{control}\)</span> = 16, the point estimate is</p>
<p><span class="math display">\[
\widehat{p}_{seed} - \widehat{p}_{control} = \frac{24}{34} - \frac{12}{16} = 0.04411765 \approx 4.4\%
\]</span></p>
<p>However, say the <em>Mythbusters</em> repeated this experiment. In other words, say they recruited 50 new participants and exposed 34 of them to yawning and 16 not. Would they find the exact same estimated difference of 4.4%? Probably not, again, because of <em>sampling variation</em>.</p>
<p>How does this sampling variation affect their estimate of 4.4%? In other words, what would be a plausible range of values for this difference that accounts for this sampling variation? We can answer this question with confidence intervals! Furthermore, since the <em>Mythbusters</em> only have a single two-sample of 50 participants, they would have to construct a 95% confidence interval for <span class="math inline">\(p_{seed} - p_{control}\)</span> using <em>bootstrap resampling with replacement</em>.</p>
<p>Let’s make a couple of important notes. First, for the comparison between the <code>"seed"</code> and <code>"control"</code> groups to make sense, however, both groups need to be <em>independent</em> from each other. Otherwise, they could influence each other’s results. This means that a participant being selected for the <code>"seed"</code> or <code>"control"</code> group has no influence on another participant being assigned to one of the two groups. As an example, if there were a mother and her child as participants in the study, they wouldn’t necessarily be in the same group. They would each be assigned randomly to one of the two groups of the explanatory variable.</p>
<p>Second, the order of the subtraction in the difference doesn’t matter so long as you are consistent and tailor your interpretations accordingly. In other words, using a point estimate of <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span> or <span class="math inline">\(\widehat{p}_{control} - \widehat{p}_{seed}\)</span> does not make a material difference, you just need to stay consistent and interpret your results accordingly.</p>
</div>
<div id="ci-build" class="section level3 hasAnchor" number="36.3.3">
<h3><span class="header-section-number">36.3.3</span> Constructing the confidence interval<a href="confidence-intervals.html#ci-build" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As we did in Subsection <a href="confidence-intervals.html#infer-workflow">36.2.3</a>, let’s first construct the bootstrap distribution for <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span> and then use this to construct 95% confidence intervals for <span class="math inline">\(p_{seed} - p_{control}\)</span>. We’ll do this using the <code>infer</code> workflow again. However, since the difference in proportions is a new scenario for inference, we’ll need to use some new arguments in the <code>infer</code> functions along the way.</p>
<div id="specify-variables-1" class="section level4 unnumbered hasAnchor">
<h4>1. <code>specify</code> variables<a href="confidence-intervals.html#specify-variables-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s take our <code>mythbusters_yawn</code> data frame and <code>specify()</code> which variables are of interest using the <code>y ~ x</code> formula interface where:</p>
<ul>
<li>Our response variable is <code>yawn</code>: whether or not a participant yawned. It has levels <code>"yes"</code> and <code>"no"</code>.</li>
<li>The explanatory variable is <code>group</code>. It has levels <code>"seed"</code> (exposed to yawning) and <code>"control"</code> (not exposed to yawning).</li>
</ul>
<div class="sourceCode" id="cb388"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb388-1"><a href="confidence-intervals.html#cb388-1" tabindex="-1"></a>mythbusters_yawn <span class="sc">|&gt;</span> </span>
<span id="cb388-2"><a href="confidence-intervals.html#cb388-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">formula =</span> yawn <span class="sc">~</span> group)</span></code></pre></div>
<pre><code>Error: A level of the response variable `yawn` needs to be specified for the 
`success` argument in `specify()`.</code></pre>
<p>Alas, we got an error message that <code>infer</code> is telling us that one of the levels of the categorical variable <code>yawn</code> needs to be defined as the <code>success</code>. Recall that we define <code>success</code> to be the event of interest we are trying to count and compute proportions of. Are we interested in those participants who <code>"yes"</code> yawned or those who <code>"no"</code> didn’t yawn? This isn’t clear to R or someone just picking up the code and results for the first time, so we need to set the <code>success</code> argument to <code>"yes"</code> as follows to improve the transparency of the code:</p>
<div class="sourceCode" id="cb390"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb390-1"><a href="confidence-intervals.html#cb390-1" tabindex="-1"></a>mythbusters_yawn <span class="sc">|&gt;</span> </span>
<span id="cb390-2"><a href="confidence-intervals.html#cb390-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">formula =</span> yawn <span class="sc">~</span> group, <span class="at">success =</span> <span class="st">&quot;yes&quot;</span>)</span></code></pre></div>
<pre><code>Response: yawn (factor)
Explanatory: group (factor)
# A tibble: 50 × 2
   yawn  group  
   &lt;fct&gt; &lt;fct&gt;  
 1 yes   seed   
 2 yes   control
 3 no    seed   
 4 yes   seed   
 5 no    seed   
 6 no    control
 7 yes   seed   
 8 no    control
 9 no    control
10 no    seed   
# ℹ 40 more rows</code></pre>
</div>
<div id="generate-replicates-1" class="section level4 unnumbered hasAnchor">
<h4>2. <code>generate</code> replicates<a href="confidence-intervals.html#generate-replicates-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Our next step is to perform <em>bootstrap resampling with replacement</em> like we did with the almonds in the activity in Section <a href="confidence-intervals.html#revisit-almond-bootstrap">36.2.1</a>. We saw how it works with both a single variable in computing bootstrap means in Section <a href="confidence-intervals.html#bootstrap-process">36.2.2</a>, but we haven’t yet worked with bootstrapping involving multiple variables.</p>
<p>In the <code>infer</code> package, bootstrapping with multiple variables means that each <em>row</em> is potentially resampled. Let’s investigate this by focusing only on the first six rows of <code>mythbusters_yawn</code>:</p>
<div class="sourceCode" id="cb392"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb392-1"><a href="confidence-intervals.html#cb392-1" tabindex="-1"></a>first_six_rows <span class="ot">&lt;-</span> <span class="fu">head</span>(mythbusters_yawn)</span>
<span id="cb392-2"><a href="confidence-intervals.html#cb392-2" tabindex="-1"></a>first_six_rows</span></code></pre></div>
<pre><code># A tibble: 6 × 3
   subj group   yawn 
  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
1     1 seed    yes  
2     2 control yes  
3     3 seed    no   
4     4 seed    yes  
5     5 seed    no   
6     6 control no   </code></pre>
<p>When we bootstrap this data, we are potentially pulling the subject’s readings multiple times. Thus, we could see the entries of <code>"seed"</code> for <code>group</code> and <code>"no"</code> for <code>yawn</code> together in a new row in a bootstrap sample. This is further seen by exploring the <code>sample_n()</code> function in <code>dplyr</code> on this smaller 6-row data frame comprised of <code>head(mythbusters_yawn)</code>. The <code>sample_n()</code> function can perform this bootstrapping procedure and is similar to the <code>rep_sample_n()</code> function in <code>infer</code>, except that it is not repeated, but rather only performs one sample with or without replacement.</p>
<div class="sourceCode" id="cb394"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb394-1"><a href="confidence-intervals.html#cb394-1" tabindex="-1"></a>first_six_rows <span class="sc">|&gt;</span> </span>
<span id="cb394-2"><a href="confidence-intervals.html#cb394-2" tabindex="-1"></a>  <span class="fu">sample_n</span>(<span class="at">size =</span> <span class="dv">6</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code># A tibble: 6 × 3
   subj group   yawn 
  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;
1     6 control no   
2     1 seed    yes  
3     2 control yes  
4     6 control no   
5     4 seed    yes  
6     4 seed    yes  </code></pre>
<p>We can see that in this bootstrap sample generated from the first six rows of <code>mythbusters_yawn</code>, we have some rows repeated. The same is true when we perform the <code>generate()</code> step in <code>infer</code> as done in what follows. Using this fact, we <code>generate</code> 1000 replicates, or, in other words, we bootstrap resample the 50 participants with replacement 1000 times.</p>
<div class="sourceCode" id="cb396"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb396-1"><a href="confidence-intervals.html#cb396-1" tabindex="-1"></a>mythbusters_yawn <span class="sc">|&gt;</span> </span>
<span id="cb396-2"><a href="confidence-intervals.html#cb396-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">formula =</span> yawn <span class="sc">~</span> group, <span class="at">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb396-3"><a href="confidence-intervals.html#cb396-3" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>, <span class="at">type =</span> <span class="st">&quot;bootstrap&quot;</span>)</span></code></pre></div>
<pre><code>Response: yawn (factor)
Explanatory: group (factor)
# A tibble: 50,000 × 3
# Groups:   replicate [1,000]
   replicate yawn  group  
       &lt;int&gt; &lt;fct&gt; &lt;fct&gt;  
 1         1 yes   seed   
 2         1 yes   control
 3         1 no    control
 4         1 no    control
 5         1 yes   seed   
 6         1 yes   seed   
 7         1 yes   seed   
 8         1 yes   seed   
 9         1 no    seed   
10         1 yes   seed   
# ℹ 49,990 more rows</code></pre>
<p>Observe that the resulting data frame has 50,000 rows. This is because we performed resampling of 50 participants with replacement 1000 times and 50,000 = 1000 <span class="math inline">\(\cdot\)</span> 50. The variable <code>replicate</code> indicates which resample each row belongs to. So it has the value <code>1</code> 50 times, the value <code>2</code> 50 times, all the way through to the value <code>1000</code> 50 times.</p>
</div>
<div id="calculate-summary-statistics-1" class="section level4 unnumbered hasAnchor">
<h4>3. <code>calculate</code> summary statistics<a href="confidence-intervals.html#calculate-summary-statistics-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>After we <code>generate()</code> many replicates of bootstrap resampling with replacement, we next want to summarize the bootstrap resamples of size 50 with a single summary statistic, the difference in proportions. We do this by setting the <code>stat</code> argument to <code>"diff in props"</code>:</p>
<div class="sourceCode" id="cb398"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb398-1"><a href="confidence-intervals.html#cb398-1" tabindex="-1"></a>mythbusters_yawn <span class="sc">|&gt;</span> </span>
<span id="cb398-2"><a href="confidence-intervals.html#cb398-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">formula =</span> yawn <span class="sc">~</span> group, <span class="at">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb398-3"><a href="confidence-intervals.html#cb398-3" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>, <span class="at">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb398-4"><a href="confidence-intervals.html#cb398-4" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;diff in props&quot;</span>)</span></code></pre></div>
<pre><code>Warning message:
The statistic is based on a difference or ratio; by default, for 
difference-based statistics, the explanatory variable is subtracted in the 
order &quot;control&quot; - &quot;seed&quot;, or divided in the order &quot;control&quot; / &quot;seed&quot; for 
ratio-based statistics. To specify this order yourself, supply 
`order = c(&quot;control&quot;, &quot;seed&quot;)` to the calculate() function. </code></pre>
<p>We see another warning here. We need to specify the order of the subtraction. Is it <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span> or <span class="math inline">\(\widehat{p}_{control} - \widehat{p}_{seed}\)</span>. We specify it to be <span class="math inline">\(\widehat{p}_{seed} - \widehat{p}_{control}\)</span> by setting <code>order = c("seed", "control")</code>. Note that you could’ve also set <code>order = c("control", "seed")</code>. As we stated earlier, the order of the subtraction does not matter, so long as you stay consistent throughout your analysis and tailor your interpretations accordingly.</p>
<p>Let’s save the output in a data frame <code>bootstrap_distribution_yawning</code>:</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="confidence-intervals.html#cb400-1" tabindex="-1"></a>bootstrap_distribution_yawning <span class="ot">&lt;-</span> mythbusters_yawn <span class="sc">|&gt;</span> </span>
<span id="cb400-2"><a href="confidence-intervals.html#cb400-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">formula =</span> yawn <span class="sc">~</span> group, <span class="at">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb400-3"><a href="confidence-intervals.html#cb400-3" tabindex="-1"></a>  <span class="fu">generate</span>(<span class="at">reps =</span> <span class="dv">1000</span>, <span class="at">type =</span> <span class="st">&quot;bootstrap&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb400-4"><a href="confidence-intervals.html#cb400-4" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="at">order =</span> <span class="fu">c</span>(<span class="st">&quot;seed&quot;</span>, <span class="st">&quot;control&quot;</span>))</span>
<span id="cb400-5"><a href="confidence-intervals.html#cb400-5" tabindex="-1"></a>bootstrap_distribution_yawning</span></code></pre></div>
<pre><code># A tibble: 1,000 × 2
   replicate        stat
       &lt;int&gt;       &lt;dbl&gt;
 1         1  0.0357143 
 2         2  0.229167  
 3         3  0.00952381
 4         4  0.0106952 
 5         5  0.00483092
 6         6  0.00793651
 7         7 -0.0845588 
 8         8 -0.00466200
 9         9  0.164686  
10        10  0.124777  
# ℹ 990 more rows</code></pre>
<p>Observe that the resulting data frame has 1000 rows and 2 columns corresponding to the 1000 <code>replicate</code> ID’s and the 1000 differences in proportions for each bootstrap resample in <code>stat</code>.</p>
</div>
<div id="visualize-the-results-1" class="section level4 unnumbered hasAnchor">
<h4>4. <code>visualize</code> the results<a href="confidence-intervals.html#visualize-the-results-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In Figure <a href="confidence-intervals.html#fig:bootstrap-distribution-mythbusters">36.23</a> we <code>visualize()</code> the resulting bootstrap resampling distribution. Let’s also add a vertical line at 0 by adding a <code>geom_vline()</code> layer.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bootstrap-distribution-mythbusters"></span>
<img src="_main_files/figure-html/bootstrap-distribution-mythbusters-1.png" alt="Bootstrap distribution." width="\textwidth" />
<p class="caption">
Figure 36.23: Bootstrap distribution.
</p>
</div>
<p>First, let’s compute the 95% confidence interval for <span class="math inline">\(p_{seed} - p_{control}\)</span> using the percentile method, in other words, by identifying the 2.5th and 97.5th percentiles which include the middle 95% of values. Recall that this method does not require the bootstrap distribution to be normally shaped.</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="confidence-intervals.html#cb402-1" tabindex="-1"></a>bootstrap_distribution_yawning <span class="sc">|&gt;</span> </span>
<span id="cb402-2"><a href="confidence-intervals.html#cb402-2" tabindex="-1"></a>  <span class="fu">get_confidence_interval</span>(<span class="at">type =</span> <span class="st">&quot;percentile&quot;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code># A tibble: 1 × 2
   lower_ci upper_ci
      &lt;dbl&gt;    &lt;dbl&gt;
1 -0.238276 0.302464</code></pre>
<p>Second, since the bootstrap distribution is roughly bell-shaped, we can construct a confidence interval using the standard error method as well. Recall that to construct a confidence interval using the standard error method, we need to specify the center of the interval using the <code>point_estimate</code> argument. In our case, we need to set it to be the difference in sample proportions of 4.4% that the <em>Mythbusters</em> observed.</p>
<p>We can also use the <code>infer</code> workflow to compute this value by excluding the <code>generate()</code> 1000 bootstrap replicates step. In other words, do not generate replicates, but rather use only the original sample data. We can achieve this by commenting out the <code>generate()</code> line, telling R to ignore it:</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="confidence-intervals.html#cb404-1" tabindex="-1"></a>obs_diff_in_props <span class="ot">&lt;-</span> mythbusters_yawn <span class="sc">|&gt;</span> </span>
<span id="cb404-2"><a href="confidence-intervals.html#cb404-2" tabindex="-1"></a>  <span class="fu">specify</span>(<span class="at">formula =</span> yawn <span class="sc">~</span> group, <span class="at">success =</span> <span class="st">&quot;yes&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb404-3"><a href="confidence-intervals.html#cb404-3" tabindex="-1"></a>  <span class="co"># generate(reps = 1000, type = &quot;bootstrap&quot;) |&gt; </span></span>
<span id="cb404-4"><a href="confidence-intervals.html#cb404-4" tabindex="-1"></a>  <span class="fu">calculate</span>(<span class="at">stat =</span> <span class="st">&quot;diff in props&quot;</span>, <span class="at">order =</span> <span class="fu">c</span>(<span class="st">&quot;seed&quot;</span>, <span class="st">&quot;control&quot;</span>))</span>
<span id="cb404-5"><a href="confidence-intervals.html#cb404-5" tabindex="-1"></a>obs_diff_in_props</span></code></pre></div>
<pre><code>Response: yawn (factor)
Explanatory: group (factor)
# A tibble: 1 × 1
       stat
      &lt;dbl&gt;
1 0.0441176</code></pre>
<p>We thus plug this value in as the <code>point_estimate</code> argument.</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="confidence-intervals.html#cb406-1" tabindex="-1"></a>myth_ci_se <span class="ot">&lt;-</span> bootstrap_distribution_yawning <span class="sc">|&gt;</span> </span>
<span id="cb406-2"><a href="confidence-intervals.html#cb406-2" tabindex="-1"></a>  <span class="fu">get_confidence_interval</span>(<span class="at">type =</span> <span class="st">&quot;se&quot;</span>, <span class="at">point_estimate =</span> obs_diff_in_props,</span>
<span id="cb406-3"><a href="confidence-intervals.html#cb406-3" tabindex="-1"></a>                          <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb406-4"><a href="confidence-intervals.html#cb406-4" tabindex="-1"></a>myth_ci_se</span></code></pre></div>
<pre><code># A tibble: 1 × 2
   lower_ci upper_ci
      &lt;dbl&gt;    &lt;dbl&gt;
1 -0.227291 0.315526</code></pre>
<p>Let’s visualize both confidence intervals in Figure <a href="confidence-intervals.html#fig:bootstrap-distribution-mythbusters-CI">36.24</a>, with the percentile method interval marked with black lines and the standard-error method marked with grey lines. Observe that they are both similar to each other.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bootstrap-distribution-mythbusters-CI"></span>
<img src="_main_files/figure-html/bootstrap-distribution-mythbusters-CI-1.png" alt="Two 95\% confidence intervals: percentile method (black) and standard error method (grey)." width="\textwidth" />
<p class="caption">
Figure 36.24: Two 95% confidence intervals: percentile method (black) and standard error method (grey).
</p>
</div>
</div>
</div>
<div id="interpreting-the-confidence-interval" class="section level3 hasAnchor" number="36.3.4">
<h3><span class="header-section-number">36.3.4</span> Interpreting the confidence interval<a href="confidence-intervals.html#interpreting-the-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Given that both confidence intervals are quite similar, let’s focus our interpretation to only the percentile method confidence interval of (-0.238, 0.302). The precise statistical interpretation of a 95% confidence interval is: if this construction procedure is repeated 100 times, then we expect about 95 of the confidence intervals to capture the true value of <span class="math inline">\(p_{seed} - p_{control}\)</span>. In other words, if we gathered 100 samples of <span class="math inline">\(n\)</span> = 50 participants from a similar pool of people and constructed 100 confidence intervals each based on each of the 100 samples, about 95 of them will contain the true value of <span class="math inline">\(p_{seed} - p_{control}\)</span> while about five won’t. Given that this is a little long winded, we use the shorthand interpretation: we’re 95% “confident” that the true difference in proportions <span class="math inline">\(p_{seed} - p_{control}\)</span> is between (-0.238, 0.302).</p>
<p>There is one value of particular interest that this 95% confidence interval contains: zero. If <span class="math inline">\(p_{seed} - p_{control}\)</span> were equal to 0, then there would be no difference in proportion yawning between the two groups. This would suggest that there is no associated effect of being exposed to a yawning recruiter on whether you yawn yourself.</p>
<p>In our case, since the 95% confidence interval includes 0, we cannot conclusively say if either proportion is larger. Of our 1000 bootstrap resamples with replacement, sometimes <span class="math inline">\(\widehat{p}_{seed}\)</span> was higher and thus those exposed to yawning yawned themselves more often. At other times, the reverse happened.</p>
<p>Say, on the other hand, the 95% confidence interval was entirely above zero. This would suggest that <span class="math inline">\(p_{seed} - p_{control} &gt; 0\)</span>, or, in other words <span class="math inline">\(p_{seed} &gt; p_{control}\)</span>, and thus we’d have evidence suggesting those exposed to yawning do yawn more often.</p>
</div>
</div>
<div id="summary-CI" class="section level2 hasAnchor" number="36.4">
<h2><span class="header-section-number">36.4</span> Summary and final remarks<a href="confidence-intervals.html#summary-CI" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="additional-resources-2" class="section level3 hasAnchor" number="36.4.1">
<h3><span class="header-section-number">36.4.1</span> Additional resources<a href="confidence-intervals.html#additional-resources-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you want more examples of the <code>infer</code> workflow to construct confidence intervals, we suggest you check out the <code>infer</code> package homepage, in particular, a series of example analyses available at <a href="https://infer.netlify.app/articles/" class="uri">https://infer.netlify.app/articles/</a>.</p>
</div>
<div id="whats-to-come-1" class="section level3 hasAnchor" number="36.4.2">
<h3><span class="header-section-number">36.4.2</span> What’s to come?<a href="confidence-intervals.html#whats-to-come-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Now that we’ve equipped ourselves with confidence intervals, we’ll cover the other common tool for statistical inference: hypothesis testing. Just like confidence intervals, hypothesis tests are used to infer about a population using a sample. However, we’ll see that the framework for making such inferences is slightly different.</p>

</div>
</div>
</div>
<script src="https://hypothes.is/embed.js" async></script>
            </section>

          </div>
        </div>
      </div>
<a href="m12u-confident-about-what.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="m12c-explore-confidence-intervals-with-your-own-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
