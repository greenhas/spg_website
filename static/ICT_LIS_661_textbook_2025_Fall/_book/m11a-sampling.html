<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>33 M11A: Sampling | Introduction to Data Science</title>
  <meta name="description" content="33 M11A: Sampling | Introduction to Data Science" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="33 M11A: Sampling | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="33 M11A: Sampling | Introduction to Data Science" />
  
  
  

<meta name="author" content="Spencer P. Greenhalgh, PhD" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="m11u-samples-and-populations.html"/>
<link rel="next" href="m11c-explore-sampling-with-your-own-data.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Home Page</a></li>
<li class="chapter" data-level="2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html"><i class="fa fa-check"></i><b>2</b> M1U: Course Syllabus</a>
<ul>
<li class="chapter" data-level="2.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#overview"><i class="fa fa-check"></i><b>2.1</b> Overview</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course"><i class="fa fa-check"></i><b>2.1.1</b> Course</a></li>
<li class="chapter" data-level="2.1.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#instructor"><i class="fa fa-check"></i><b>2.1.2</b> Instructor</a></li>
<li class="chapter" data-level="2.1.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#contact-information"><i class="fa fa-check"></i><b>2.1.3</b> Contact Information</a></li>
<li class="chapter" data-level="2.1.4" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#response-time"><i class="fa fa-check"></i><b>2.1.4</b> Response Time</a></li>
<li class="chapter" data-level="2.1.5" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#office-hours"><i class="fa fa-check"></i><b>2.1.5</b> Office Hours</a></li>
<li class="chapter" data-level="2.1.6" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#meeting-schedule"><i class="fa fa-check"></i><b>2.1.6</b> Meeting Schedule</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#required-materials"><i class="fa fa-check"></i><b>2.2</b> Required Materials</a></li>
<li class="chapter" data-level="2.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#life-is-difficult-statement-inspired-by-dr.-andrew-heiss"><i class="fa fa-check"></i><b>2.3</b> “Life is Difficult” Statement [inspired by [Dr. Andrew Heiss]</a></li>
<li class="chapter" data-level="2.4" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#basic-needs-statement-inspired-by-dr.-sara-goldrick-rab"><i class="fa fa-check"></i><b>2.4</b> Basic Needs Statement [inspired by Dr. Sara Goldrick-Rab]</a></li>
<li class="chapter" data-level="2.5" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-information"><i class="fa fa-check"></i><b>2.5</b> Course Information</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-description"><i class="fa fa-check"></i><b>2.5.1</b> Course Description</a></li>
<li class="chapter" data-level="2.5.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-objectivesi-can-statements"><i class="fa fa-check"></i><b>2.5.2</b> Course Objectives—“I Can Statements”</a></li>
<li class="chapter" data-level="2.5.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-assessment"><i class="fa fa-check"></i><b>2.5.3</b> Course Assessment</a></li>
<li class="chapter" data-level="2.5.4" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#late-work-policy"><i class="fa fa-check"></i><b>2.5.4</b> Late Work Policy</a></li>
<li class="chapter" data-level="2.5.5" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#prep-week"><i class="fa fa-check"></i><b>2.5.5</b> Prep Week</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-policies"><i class="fa fa-check"></i><b>2.6</b> Course Policies</a></li>
<li class="chapter" data-level="2.7" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#plagiarism-cheating-and-generative-ai"><i class="fa fa-check"></i><b>2.7</b> Plagiarism, Cheating, and Generative AI</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#plagiarism-source"><i class="fa fa-check"></i><b>2.7.1</b> Plagiarism [source]</a></li>
<li class="chapter" data-level="2.7.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#cheating-source"><i class="fa fa-check"></i><b>2.7.2</b> Cheating [source]</a></li>
<li class="chapter" data-level="2.7.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#code-plagiarism-and-generative-ai"><i class="fa fa-check"></i><b>2.7.3</b> Code, Plagiarism, and Generative AI</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#course-schedule"><i class="fa fa-check"></i><b>2.8</b> Course Schedule</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-1-course-introduction-25-aug---31-aug"><i class="fa fa-check"></i><b>2.8.1</b> Module 1: Course Introduction (25 Aug - 31 Aug)</a></li>
<li class="chapter" data-level="2.8.2" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-2-data-science-1-sep---7-sep"><i class="fa fa-check"></i><b>2.8.2</b> Module 2: Data Science (1 Sep - 7 Sep)</a></li>
<li class="chapter" data-level="2.8.3" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-3-reproducibility-and-paradigms-8-sep-to-14-sep"><i class="fa fa-check"></i><b>2.8.3</b> Module 3: Reproducibility and Paradigms (8 Sep to 14 Sep)</a></li>
<li class="chapter" data-level="2.8.4" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-4-data-sharing-15-sep---21-sep"><i class="fa fa-check"></i><b>2.8.4</b> Module 4: Data Sharing (15 Sep - 21 Sep)</a></li>
<li class="chapter" data-level="2.8.5" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-5-theory-and-ethics-22-sep---28-sep"><i class="fa fa-check"></i><b>2.8.5</b> Module 5: Theory and Ethics (22 Sep - 28 Sep)</a></li>
<li class="chapter" data-level="2.8.6" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-6-data-cleaning-29-sep---5-oct"><i class="fa fa-check"></i><b>2.8.6</b> Module 6: Data Cleaning (29 Sep - 5 Oct)</a></li>
<li class="chapter" data-level="2.8.7" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-7-data-visualization-6-oct---12-oct"><i class="fa fa-check"></i><b>2.8.7</b> Module 7: Data Visualization (6 Oct - 12 Oct)</a></li>
<li class="chapter" data-level="2.8.8" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-8-descriptive-statistics-13-oct---19-oct"><i class="fa fa-check"></i><b>2.8.8</b> Module 8: Descriptive Statistics (13 Oct - 19 Oct)</a></li>
<li class="chapter" data-level="2.8.9" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-9-basic-regression-20-oct---26-oct"><i class="fa fa-check"></i><b>2.8.9</b> Module 9: Basic Regression (20 Oct - 26 Oct)</a></li>
<li class="chapter" data-level="2.8.10" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-10-multiple-regression-27-oct---2-nov"><i class="fa fa-check"></i><b>2.8.10</b> Module 10: Multiple Regression (27 Oct - 2 Nov)</a></li>
<li class="chapter" data-level="2.8.11" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-11-statistical-sampling-3-nov---9-nov"><i class="fa fa-check"></i><b>2.8.11</b> Module 11: Statistical Sampling (3 Nov - 9 Nov)</a></li>
<li class="chapter" data-level="2.8.12" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-12-confidence-intervals-10-nov---16-nov"><i class="fa fa-check"></i><b>2.8.12</b> Module 12: Confidence Intervals (10 Nov - 16 Nov)</a></li>
<li class="chapter" data-level="2.8.13" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-13-hypothesis-testing-17-nov---23-nov"><i class="fa fa-check"></i><b>2.8.13</b> Module 13: Hypothesis Testing (17 Nov - 23 Nov)</a></li>
<li class="chapter" data-level="2.8.14" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-14-inferential-regression-26-nov---30-nov"><i class="fa fa-check"></i><b>2.8.14</b> Module 14: Inferential Regression (26 Nov - 30 Nov)</a></li>
<li class="chapter" data-level="2.8.15" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-15-course-reflection-1-dec---7-dec"><i class="fa fa-check"></i><b>2.8.15</b> Module 15: Course Reflection (1 Dec - 7 Dec)</a></li>
<li class="chapter" data-level="2.8.16" data-path="m1u-course-syllabus.html"><a href="m1u-course-syllabus.html#module-16-final-project-8-dec---10-dec"><i class="fa fa-check"></i><b>2.8.16</b> Module 16: Final Project (8 Dec - 10 Dec)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html"><i class="fa fa-check"></i><b>3</b> M1A: Install R and RStudio</a>
<ul>
<li class="chapter" data-level="3.1" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html#introduction"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html#r"><i class="fa fa-check"></i><b>3.2</b> R</a></li>
<li class="chapter" data-level="3.3" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html#rstudio"><i class="fa fa-check"></i><b>3.3</b> RStudio</a></li>
<li class="chapter" data-level="3.4" data-path="m1a-install-r-and-rstudio.html"><a href="m1a-install-r-and-rstudio.html#references"><i class="fa fa-check"></i><b>3.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="m1c-introduce-yourself-to-the-class.html"><a href="m1c-introduce-yourself-to-the-class.html"><i class="fa fa-check"></i><b>4</b> M1C: Introduce Yourself to the Class</a></li>
<li class="chapter" data-level="5" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html"><i class="fa fa-check"></i><b>5</b> M2U: The New(?) and Shiny(?) Science of Data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#data-data-science-and-big-data"><i class="fa fa-check"></i><b>5.1</b> Data, Data Science, and Big Data</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#what-are-data"><i class="fa fa-check"></i><b>5.1.1</b> What Are Data?</a></li>
<li class="chapter" data-level="5.1.2" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#what-is-data-science"><i class="fa fa-check"></i><b>5.1.2</b> What Is Data Science?</a></li>
<li class="chapter" data-level="5.1.3" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#what-does-big-data-mean"><i class="fa fa-check"></i><b>5.1.3</b> What Does “Big Data” Mean?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#the-many-skills-of-data-science"><i class="fa fa-check"></i><b>5.2</b> The Many Skills of Data Science</a></li>
<li class="chapter" data-level="5.3" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#conclusion"><i class="fa fa-check"></i><b>5.3</b> Conclusion</a></li>
<li class="chapter" data-level="5.4" data-path="m2u-the-new-and-shiny-science-of-data.html"><a href="m2u-the-new-and-shiny-science-of-data.html#references-1"><i class="fa fa-check"></i><b>5.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html"><i class="fa fa-check"></i><b>6</b> M2A: Getting Started with Data in R</a>
<ul>
<li class="chapter" data-level="6.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#r-rstudio"><i class="fa fa-check"></i><b>6.1</b> What are R and RStudio?</a></li>
<li class="chapter" data-level="6.2" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#code"><i class="fa fa-check"></i><b>6.2</b> How do I code in R?</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#programming-concepts"><i class="fa fa-check"></i><b>6.2.1</b> Basic programming concepts and terminology</a></li>
<li class="chapter" data-level="6.2.2" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#messages"><i class="fa fa-check"></i><b>6.2.2</b> Errors, warnings, and messages</a></li>
<li class="chapter" data-level="6.2.3" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#tips-code"><i class="fa fa-check"></i><b>6.2.3</b> Tips on learning to code</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#packages"><i class="fa fa-check"></i><b>6.3</b> What are R packages?</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#package-installation"><i class="fa fa-check"></i><b>6.3.1</b> Package installation</a></li>
<li class="chapter" data-level="6.3.2" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#package-loading"><i class="fa fa-check"></i><b>6.3.2</b> Package loading</a></li>
<li class="chapter" data-level="6.3.3" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#package-use"><i class="fa fa-check"></i><b>6.3.3</b> Package use</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#nycflights"><i class="fa fa-check"></i><b>6.4</b> Explore your first datasets</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#nycflights23-package"><i class="fa fa-check"></i><b>6.4.1</b> <code>nycflights23</code> package</a></li>
<li class="chapter" data-level="6.4.2" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#flights-data-frame"><i class="fa fa-check"></i><b>6.4.2</b> <code>flights</code> data frame</a></li>
<li class="chapter" data-level="6.4.3" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#exploredataframes"><i class="fa fa-check"></i><b>6.4.3</b> Exploring data frames</a></li>
<li class="chapter" data-level="6.4.4" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#identification-vs-measurement-variables"><i class="fa fa-check"></i><b>6.4.4</b> Identification and measurement variables</a></li>
<li class="chapter" data-level="6.4.5" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#help-files"><i class="fa fa-check"></i><b>6.4.5</b> Help files</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#conclusion-1"><i class="fa fa-check"></i><b>6.5</b> Conclusion</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="m2a-getting-started-with-data-in-r.html"><a href="m2a-getting-started-with-data-in-r.html#additional-resources"><i class="fa fa-check"></i><b>6.5.1</b> Additional resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html"><i class="fa fa-check"></i><b>7</b> M2C: Set up GitHub</a>
<ul>
<li class="chapter" data-level="7.1" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#gitand-githubin-data-science"><i class="fa fa-check"></i><b>7.2</b> Git—and GitHub—in Data Science</a></li>
<li class="chapter" data-level="7.3" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#github-in-ictlis-661"><i class="fa fa-check"></i><b>7.3</b> GitHub in ICT/LIS 661</a></li>
<li class="chapter" data-level="7.4" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#setting-up-github"><i class="fa fa-check"></i><b>7.4</b> Setting Up GitHub</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#creating-a-github-account"><i class="fa fa-check"></i><b>7.4.1</b> Creating a GitHub Account</a></li>
<li class="chapter" data-level="7.4.2" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#setting-up-a-github-repository-for-class"><i class="fa fa-check"></i><b>7.4.2</b> Setting up a GitHub Repository for Class</a></li>
<li class="chapter" data-level="7.4.3" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#installing-github-desktop"><i class="fa fa-check"></i><b>7.4.3</b> Installing GitHub Desktop</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="m2c-set-up-github.html"><a href="m2c-set-up-github.html#moving-forward"><i class="fa fa-check"></i><b>7.5</b> Moving Forward</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html"><i class="fa fa-check"></i><b>8</b> M3U: Research Paradigms and Reproducibility</a>
<ul>
<li class="chapter" data-level="8.1" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#introduction-2"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#reproducibility-and-paradigms"><i class="fa fa-check"></i><b>8.2</b> Reproducibility and Paradigms</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#an-example-paradigm"><i class="fa fa-check"></i><b>8.2.1</b> An Example Paradigm</a></li>
<li class="chapter" data-level="8.2.2" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#another-example-paradigm"><i class="fa fa-check"></i><b>8.2.2</b> Another Example Paradigm</a></li>
<li class="chapter" data-level="8.2.3" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#why-do-paradigms-matter"><i class="fa fa-check"></i><b>8.2.3</b> Why Do Paradigms Matter?</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#supporting-reproducibility"><i class="fa fa-check"></i><b>8.3</b> Supporting Reproducibility</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#open-design"><i class="fa fa-check"></i><b>8.3.1</b> Open Design</a></li>
<li class="chapter" data-level="8.3.2" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#open-analysis"><i class="fa fa-check"></i><b>8.3.2</b> Open Analysis</a></li>
<li class="chapter" data-level="8.3.3" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#open-publication"><i class="fa fa-check"></i><b>8.3.3</b> Open Publication</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#conclusion-2"><i class="fa fa-check"></i><b>8.4</b> Conclusion</a></li>
<li class="chapter" data-level="8.5" data-path="m3u-research-paradigms-and-reproducibility.html"><a href="m3u-research-paradigms-and-reproducibility.html#references-2"><i class="fa fa-check"></i><b>8.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html"><i class="fa fa-check"></i><b>9</b> M3A: Using Projects and Scripts in R</a>
<ul>
<li class="chapter" data-level="9.1" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#introduction-3"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#more-about-r-and-rstudio"><i class="fa fa-check"></i><b>9.2</b> More About R and RStudio</a></li>
<li class="chapter" data-level="9.3" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#the-console-and-the-workspace"><i class="fa fa-check"></i><b>9.3</b> The Console and the Workspace</a></li>
<li class="chapter" data-level="9.4" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#holding-onto-code"><i class="fa fa-check"></i><b>9.4</b> Holding Onto Code</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#rstudio-projects"><i class="fa fa-check"></i><b>9.4.1</b> RStudio Projects</a></li>
<li class="chapter" data-level="9.4.2" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#using-scripts"><i class="fa fa-check"></i><b>9.4.2</b> Using Scripts</a></li>
<li class="chapter" data-level="9.4.3" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#backing-up-your-project-folder"><i class="fa fa-check"></i><b>9.4.3</b> Backing Up Your Project Folder</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="m3a-using-projects-and-scripts-in-r.html"><a href="m3a-using-projects-and-scripts-in-r.html#conclusion-3"><i class="fa fa-check"></i><b>9.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html"><i class="fa fa-check"></i><b>10</b> M3C: Writing in R Markdown</a>
<ul>
<li class="chapter" data-level="10.1" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#introduction-4"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#markdown-syntax"><i class="fa fa-check"></i><b>10.2</b> Markdown syntax</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#inline-formatting"><i class="fa fa-check"></i><b>10.2.1</b> Inline formatting</a></li>
<li class="chapter" data-level="10.2.2" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#block-level-elements"><i class="fa fa-check"></i><b>10.2.2</b> Block-level elements</a></li>
<li class="chapter" data-level="10.2.3" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#r-code-chunks"><i class="fa fa-check"></i><b>10.2.3</b> R code chunks</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="m3c-writing-in-r-markdown.html"><a href="m3c-writing-in-r-markdown.html#trying-out-r-markdown"><i class="fa fa-check"></i><b>10.3</b> Trying out R Markdown</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html"><i class="fa fa-check"></i><b>11</b> M4U: The Value of Open Data</a>
<ul>
<li class="chapter" data-level="11.1" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#introduction-5"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#positivism-and-the-need-for-data"><i class="fa fa-check"></i><b>11.2</b> Positivism and the Need for Data</a></li>
<li class="chapter" data-level="11.3" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#sharing-data"><i class="fa fa-check"></i><b>11.3</b> Sharing Data</a></li>
<li class="chapter" data-level="11.4" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#sharing-data-and-privacy"><i class="fa fa-check"></i><b>11.4</b> Sharing Data and Privacy</a></li>
<li class="chapter" data-level="11.5" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#how-to-share-data"><i class="fa fa-check"></i><b>11.5</b> How to Share Data</a></li>
<li class="chapter" data-level="11.6" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#benefits-of-sharing-data"><i class="fa fa-check"></i><b>11.6</b> Benefits of Sharing Data</a></li>
<li class="chapter" data-level="11.7" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#downsides-of-sharing-data"><i class="fa fa-check"></i><b>11.7</b> Downsides of Sharing Data</a></li>
<li class="chapter" data-level="11.8" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#incentives-for-sharing-data"><i class="fa fa-check"></i><b>11.8</b> Incentives for Sharing Data</a></li>
<li class="chapter" data-level="11.9" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#conclusion-4"><i class="fa fa-check"></i><b>11.9</b> Conclusion</a></li>
<li class="chapter" data-level="11.10" data-path="m4u-the-value-of-open-data.html"><a href="m4u-the-value-of-open-data.html#references-3"><i class="fa fa-check"></i><b>11.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html"><i class="fa fa-check"></i><b>12</b> M4A: Find a Dataset Relevant To You</a>
<ul>
<li class="chapter" data-level="12.1" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html#introduction-6"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html#signs-of-a-good-dataset"><i class="fa fa-check"></i><b>12.2</b> Signs of a Good Dataset</a></li>
<li class="chapter" data-level="12.3" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html#finding-a-good-dataset"><i class="fa fa-check"></i><b>12.3</b> Finding a Good Dataset</a></li>
<li class="chapter" data-level="12.4" data-path="m4a-find-a-dataset-relevant-to-you.html"><a href="m4a-find-a-dataset-relevant-to-you.html#loading-dataset"><i class="fa fa-check"></i><b>12.4</b> Loading Your Dataset</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html"><i class="fa fa-check"></i><b>13</b> M4C: Show Your Work</a>
<ul>
<li class="chapter" data-level="13.1" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#introduction-7"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#invisible-labor"><i class="fa fa-check"></i><b>13.2</b> Invisible Labor</a></li>
<li class="chapter" data-level="13.3" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#the-invisible-labor-of-data-science"><i class="fa fa-check"></i><b>13.3</b> The Invisible Labor of Data Science</a></li>
<li class="chapter" data-level="13.4" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#time-and-money"><i class="fa fa-check"></i><b>13.4</b> Time and Money</a></li>
<li class="chapter" data-level="13.5" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#crediting-data-work"><i class="fa fa-check"></i><b>13.5</b> Crediting Data Work</a></li>
<li class="chapter" data-level="13.6" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#crediting-emotional-labor-and-care-work"><i class="fa fa-check"></i><b>13.6</b> Crediting Emotional Labor and Care Work</a></li>
<li class="chapter" data-level="13.7" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#show-your-work"><i class="fa fa-check"></i><b>13.7</b> Show Your Work</a></li>
<li class="chapter" data-level="13.8" data-path="m4c-show-your-work.html"><a href="m4c-show-your-work.html#references-4"><i class="fa fa-check"></i><b>13.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html"><i class="fa fa-check"></i><b>14</b> M5U: Numbers Don’t Speak for Themselves</a>
<ul>
<li class="chapter" data-level="14.1" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#introduction-8"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#bigger-is-not-always-better"><i class="fa fa-check"></i><b>14.2</b> Bigger is not Always Better</a></li>
<li class="chapter" data-level="14.3" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#theory"><i class="fa fa-check"></i><b>14.3</b> Theory</a></li>
<li class="chapter" data-level="14.4" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#the-importance-of-theory"><i class="fa fa-check"></i><b>14.4</b> The Importance of Theory</a></li>
<li class="chapter" data-level="14.5" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#research-isnt-just-empirical"><i class="fa fa-check"></i><b>14.5</b> Research isn’t Just Empirical</a></li>
<li class="chapter" data-level="14.6" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#the-importance-of-context"><i class="fa fa-check"></i><b>14.6</b> The Importance of Context</a></li>
<li class="chapter" data-level="14.7" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#conclusion-5"><i class="fa fa-check"></i><b>14.7</b> Conclusion</a></li>
<li class="chapter" data-level="14.8" data-path="m5u-numbers-dont-speak-for-themselves.html"><a href="m5u-numbers-dont-speak-for-themselves.html#references-5"><i class="fa fa-check"></i><b>14.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html"><i class="fa fa-check"></i><b>15</b> M5A: Are Ethics Enough in Data Science?</a>
<ul>
<li class="chapter" data-level="15.1" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#a-note-on-sources"><i class="fa fa-check"></i><b>15.1</b> A Note on Sources</a></li>
<li class="chapter" data-level="15.2" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#introduction-9"><i class="fa fa-check"></i><b>15.2</b> Introduction</a></li>
<li class="chapter" data-level="15.3" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#ethics-vs.-politics"><i class="fa fa-check"></i><b>15.3</b> Ethics vs. Politics</a></li>
<li class="chapter" data-level="15.4" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#why-politics"><i class="fa fa-check"></i><b>15.4</b> Why Politics?</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#argument-1-i-am-just-an-engineer"><i class="fa fa-check"></i><b>15.4.1</b> Argument 1: “I am Just an Engineer”</a></li>
<li class="chapter" data-level="15.4.2" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#argument-2-we-shouldnt-take-political-stances"><i class="fa fa-check"></i><b>15.4.2</b> Argument 2: “We Shouldn’t Take Political Stances”</a></li>
<li class="chapter" data-level="15.4.3" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#argument-3-dont-let-the-perfect-be-the-enemy-of-the-good"><i class="fa fa-check"></i><b>15.4.3</b> Argument 3: “Don’t Let the Perfect Be the Enemy of the Good”</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#conclusion-6"><i class="fa fa-check"></i><b>15.5</b> Conclusion</a></li>
<li class="chapter" data-level="15.6" data-path="m5a-are-ethics-enough-in-data-science.html"><a href="m5a-are-ethics-enough-in-data-science.html#references-6"><i class="fa fa-check"></i><b>15.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="m5c-reflect-on-theoretical-and-philosophical-constraints.html"><a href="m5c-reflect-on-theoretical-and-philosophical-constraints.html"><i class="fa fa-check"></i><b>16</b> M5C: Reflect on Theoretical and Philosophical Constraints</a></li>
<li class="chapter" data-level="17" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html"><i class="fa fa-check"></i><b>17</b> M6U: Unicorns, Janitors, and Rock Stars</a>
<ul>
<li class="chapter" data-level="17.1" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#introduction-10"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#intentionally-challenging-data-visualization"><i class="fa fa-check"></i><b>17.2</b> Intentionally Challenging Data Visualization</a></li>
<li class="chapter" data-level="17.3" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#sexy-scientists-and-drab-janitors"><i class="fa fa-check"></i><b>17.3</b> Sexy Scientists and… Drab Janitors?</a></li>
<li class="chapter" data-level="17.4" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#strangers-in-the-dataset"><i class="fa fa-check"></i><b>17.4</b> Strangers in the Dataset</a></li>
<li class="chapter" data-level="17.5" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#sharing-work-and-sharing-credit"><i class="fa fa-check"></i><b>17.5</b> Sharing Work and Sharing Credit</a></li>
<li class="chapter" data-level="17.6" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#conclusion-7"><i class="fa fa-check"></i><b>17.6</b> Conclusion</a></li>
<li class="chapter" data-level="17.7" data-path="m6u-unicorns-janitors-and-rock-stars.html"><a href="m6u-unicorns-janitors-and-rock-stars.html#references-7"><i class="fa fa-check"></i><b>17.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html"><i class="fa fa-check"></i><b>18</b> M6A: Wrangling and Tidying Data</a>
<ul>
<li class="chapter" data-level="18.1" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#introduction-11"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#wrangling"><i class="fa fa-check"></i><b>18.2</b> Wrangling</a>
<ul>
<li class="chapter" data-level="" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#wrangling-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="18.2.1" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#piping"><i class="fa fa-check"></i><b>18.2.1</b> The pipe operator: <code>|&gt;</code></a></li>
<li class="chapter" data-level="18.2.2" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#filter"><i class="fa fa-check"></i><b>18.2.2</b> <code>filter</code> rows</a></li>
<li class="chapter" data-level="18.2.3" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#mutate"><i class="fa fa-check"></i><b>18.2.3</b> <code>mutate</code> existing variables</a></li>
<li class="chapter" data-level="18.2.4" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#arrange"><i class="fa fa-check"></i><b>18.2.4</b> <code>arrange</code> and sort rows</a></li>
<li class="chapter" data-level="18.2.5" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#joins"><i class="fa fa-check"></i><b>18.2.5</b> <code>join</code> data frames</a></li>
<li class="chapter" data-level="18.2.6" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#normal-forms"><i class="fa fa-check"></i><b>18.2.6</b> Normal forms</a></li>
<li class="chapter" data-level="18.2.7" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#other-verbs"><i class="fa fa-check"></i><b>18.2.7</b> Other verbs</a></li>
<li class="chapter" data-level="18.2.8" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#top_n-values-of-a-variable"><i class="fa fa-check"></i><b>18.2.8</b> <code>top_n</code> values of a variable</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidying-data"><i class="fa fa-check"></i><b>18.3</b> Tidying Data</a>
<ul>
<li class="chapter" data-level="" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidy-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="18.3.1" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#csv"><i class="fa fa-check"></i><b>18.3.1</b> Importing data</a></li>
<li class="chapter" data-level="18.3.2" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidy-data-ex"><i class="fa fa-check"></i><b>18.3.2</b> “Tidy” data</a></li>
<li class="chapter" data-level="18.3.3" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidy-definition"><i class="fa fa-check"></i><b>18.3.3</b> Definition of “tidy” data</a></li>
<li class="chapter" data-level="18.3.4" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#converting-to-tidy-data"><i class="fa fa-check"></i><b>18.3.4</b> Converting to “tidy” data</a></li>
<li class="chapter" data-level="18.3.5" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#case-study-tidy"><i class="fa fa-check"></i><b>18.3.5</b> Case study: Democracy in Guatemala</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#tidyverse-package"><i class="fa fa-check"></i><b>18.4</b> <code>tidyverse</code> package</a></li>
<li class="chapter" data-level="18.5" data-path="m6a-wrangling-and-tidying-data.html"><a href="m6a-wrangling-and-tidying-data.html#references-8"><i class="fa fa-check"></i><b>18.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="m6c-practice-wrangling-and-tidying-your-own-data.html"><a href="m6c-practice-wrangling-and-tidying-your-own-data.html"><i class="fa fa-check"></i><b>19</b> M6C: Practice Wrangling and Tidying Your Own Data</a></li>
<li class="chapter" data-level="20" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html"><i class="fa fa-check"></i><b>20</b> M7U: Subjectivity in Data Visualization</a>
<ul>
<li class="chapter" data-level="20.1" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#introduction-12"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#persuasion-and-the-god-trick"><i class="fa fa-check"></i><b>20.2</b> Persuasion and the God Trick</a></li>
<li class="chapter" data-level="20.3" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#visualization-as-rhetoric"><i class="fa fa-check"></i><b>20.3</b> Visualization as Rhetoric</a></li>
<li class="chapter" data-level="20.4" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#editorial-choices-in-visualization"><i class="fa fa-check"></i><b>20.4</b> Editorial Choices in Visualization</a></li>
<li class="chapter" data-level="20.5" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#visualization-as-ideological-work"><i class="fa fa-check"></i><b>20.5</b> Visualization as Ideological Work</a></li>
<li class="chapter" data-level="20.6" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#feminist-objectivity"><i class="fa fa-check"></i><b>20.6</b> Feminist Objectivity</a></li>
<li class="chapter" data-level="20.7" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#data-visceralization"><i class="fa fa-check"></i><b>20.7</b> Data Visceralization</a></li>
<li class="chapter" data-level="20.8" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#conclusion-8"><i class="fa fa-check"></i><b>20.8</b> Conclusion</a></li>
<li class="chapter" data-level="20.9" data-path="m7u-subjectivity-in-data-visualization.html"><a href="m7u-subjectivity-in-data-visualization.html#references-9"><i class="fa fa-check"></i><b>20.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html"><i class="fa fa-check"></i><b>21</b> M7A: Data Visualization</a>
<ul>
<li class="chapter" data-level="21.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#introduction-13"><i class="fa fa-check"></i><b>21.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#needed-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#grammarofgraphics"><i class="fa fa-check"></i><b>21.2</b> The grammar of graphics</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#components-of-the-grammar"><i class="fa fa-check"></i><b>21.2.1</b> Components of the grammar</a></li>
<li class="chapter" data-level="21.2.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#gapminder"><i class="fa fa-check"></i><b>21.2.2</b> Gapminder data</a></li>
<li class="chapter" data-level="21.2.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#other-components"><i class="fa fa-check"></i><b>21.2.3</b> Other components</a></li>
<li class="chapter" data-level="21.2.4" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#ggplot2-package"><i class="fa fa-check"></i><b>21.2.4</b> ggplot2 package</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#FiveNG"><i class="fa fa-check"></i><b>21.3</b> Five named graphs - the 5NG</a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geompoint"><i class="fa fa-check"></i><b>21.3.1</b> Scatterplots via <code>geom_point</code></a></li>
<li class="chapter" data-level="21.3.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#overplotting"><i class="fa fa-check"></i><b>21.3.2</b> Overplotting</a></li>
<li class="chapter" data-level="21.3.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary"><i class="fa fa-check"></i><b>21.3.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#linegraphs"><i class="fa fa-check"></i><b>21.4</b> 5NG#2: Linegraphs</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geomline"><i class="fa fa-check"></i><b>21.4.1</b> Linegraphs via <code>geom_line</code></a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#histograms"><i class="fa fa-check"></i><b>21.5</b> 5NG#3: Histograms</a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geomhistogram"><i class="fa fa-check"></i><b>21.5.1</b> Histograms via <code>geom_histogram</code></a></li>
<li class="chapter" data-level="21.5.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#adjustbins"><i class="fa fa-check"></i><b>21.5.2</b> Adjusting the bins</a></li>
<li class="chapter" data-level="21.5.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary-1"><i class="fa fa-check"></i><b>21.5.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#facets"><i class="fa fa-check"></i><b>21.6</b> Facets</a></li>
<li class="chapter" data-level="21.7" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#boxplots"><i class="fa fa-check"></i><b>21.7</b> 5NG#4: Boxplots</a>
<ul>
<li class="chapter" data-level="21.7.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geomboxplot"><i class="fa fa-check"></i><b>21.7.1</b> Boxplots via <code>geom_boxplot</code></a></li>
<li class="chapter" data-level="21.7.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary-2"><i class="fa fa-check"></i><b>21.7.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="21.8" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#geombar"><i class="fa fa-check"></i><b>21.8</b> 5NG#5: Barplots</a>
<ul>
<li class="chapter" data-level="21.8.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#barplots-via-geom_bar-or-geom_col"><i class="fa fa-check"></i><b>21.8.1</b> Barplots via <code>geom_bar</code> or <code>geom_col</code></a></li>
<li class="chapter" data-level="21.8.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#avoid-pie-charts"><i class="fa fa-check"></i><b>21.8.2</b> Avoid pie charts!</a></li>
<li class="chapter" data-level="21.8.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#two-categ-barplot"><i class="fa fa-check"></i><b>21.8.3</b> Two categorical variables</a></li>
<li class="chapter" data-level="21.8.4" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary-3"><i class="fa fa-check"></i><b>21.8.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="21.9" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#data-vis-conclusion"><i class="fa fa-check"></i><b>21.9</b> Conclusion</a>
<ul>
<li class="chapter" data-level="21.9.1" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#summary-table"><i class="fa fa-check"></i><b>21.9.1</b> Summary table</a></li>
<li class="chapter" data-level="21.9.2" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#function-argument-specification"><i class="fa fa-check"></i><b>21.9.2</b> Function argument specification</a></li>
<li class="chapter" data-level="21.9.3" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#additional-resources-1"><i class="fa fa-check"></i><b>21.9.3</b> Additional resources</a></li>
</ul></li>
<li class="chapter" data-level="21.10" data-path="m7a-data-visualization.html"><a href="m7a-data-visualization.html#references-10"><i class="fa fa-check"></i><b>21.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="m7c-practice-visualizing-your-own-data.html"><a href="m7c-practice-visualizing-your-own-data.html"><i class="fa fa-check"></i><b>22</b> M7C: Practice Visualizing Your Own Data</a></li>
<li class="chapter" data-level="23" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html"><i class="fa fa-check"></i><b>23</b> M8U: Statistics and Scientific Racism</a>
<ul>
<li class="chapter" data-level="23.1" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#introduction-14"><i class="fa fa-check"></i><b>23.1</b> Introduction</a></li>
<li class="chapter" data-level="23.2" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#the-origins-of-statistics"><i class="fa fa-check"></i><b>23.2</b> The Origins of Statistics</a></li>
<li class="chapter" data-level="23.3" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#the-importance-of-statistical-humility"><i class="fa fa-check"></i><b>23.3</b> The Importance of Statistical Humility</a></li>
<li class="chapter" data-level="23.4" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#eugenics-a-failure-of-statistical-humility"><i class="fa fa-check"></i><b>23.4</b> Eugenics: A Failure of Statistical Humility</a></li>
<li class="chapter" data-level="23.5" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#the-continuing-legacy-of-eugenics-and-scientific-racism"><i class="fa fa-check"></i><b>23.5</b> The Continuing Legacy of Eugenics and Scientific Racism</a></li>
<li class="chapter" data-level="23.6" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#conclusion-9"><i class="fa fa-check"></i><b>23.6</b> Conclusion</a></li>
<li class="chapter" data-level="23.7" data-path="m8u-statistics-and-scientific-racism.html"><a href="m8u-statistics-and-scientific-racism.html#references-11"><i class="fa fa-check"></i><b>23.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html"><i class="fa fa-check"></i><b>24</b> M8A: Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="24.1" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#introduction-15"><i class="fa fa-check"></i><b>24.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#wrangling-packages-2"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="24.2" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#summarize"><i class="fa fa-check"></i><b>24.2</b> <code>summarize</code> variables</a>
<ul>
<li class="chapter" data-level="24.2.1" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#mean"><i class="fa fa-check"></i><b>24.2.1</b> Mean</a></li>
<li class="chapter" data-level="24.2.2" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#standard-deviation"><i class="fa fa-check"></i><b>24.2.2</b> Standard Deviation</a></li>
<li class="chapter" data-level="24.2.3" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#calculating-mean-with-mean-and-standard-deviation-with-sd"><i class="fa fa-check"></i><b>24.2.3</b> Calculating Mean with <code>mean()</code> and Standard Deviation with <code>sd()</code></a></li>
<li class="chapter" data-level="24.2.4" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#percentiles-quartiles-and-iqr"><i class="fa fa-check"></i><b>24.2.4</b> Percentiles, Quartiles and <code>IQR()</code></a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#groupby"><i class="fa fa-check"></i><b>24.3</b> <code>group_by</code> rows</a></li>
<li class="chapter" data-level="24.4" data-path="m8a-descriptive-statistics.html"><a href="m8a-descriptive-statistics.html#conclusion-10"><i class="fa fa-check"></i><b>24.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="m8c-calculate-descriptive-statistics-for-your-own-data.html"><a href="m8c-calculate-descriptive-statistics-for-your-own-data.html"><i class="fa fa-check"></i><b>25</b> M8C: Calculate Descriptive Statistics for Your Own Data</a></li>
<li class="chapter" data-level="26" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html"><i class="fa fa-check"></i><b>26</b> M9U: Linear Regression</a>
<ul>
<li class="chapter" data-level="26.1" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#introduction-16"><i class="fa fa-check"></i><b>26.1</b> Introduction</a></li>
<li class="chapter" data-level="26.2" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#linear-equations"><i class="fa fa-check"></i><b>26.2</b> Linear Equations</a></li>
<li class="chapter" data-level="26.3" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#linear-relationships-and-scatterplots"><i class="fa fa-check"></i><b>26.3</b> Linear Relationships and Scatterplots</a></li>
<li class="chapter" data-level="26.4" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#the-regression-equation"><i class="fa fa-check"></i><b>26.4</b> The Regression Equation</a></li>
<li class="chapter" data-level="26.5" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#least-squares-criteria-for-best-fit"><i class="fa fa-check"></i><b>26.5</b> Least Squares Criteria for Best Fit</a></li>
<li class="chapter" data-level="26.6" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#correlation-coefficients"><i class="fa fa-check"></i><b>26.6</b> Correlation Coefficients</a></li>
<li class="chapter" data-level="26.7" data-path="m9u-linear-regression.html"><a href="m9u-linear-regression.html#conclusion-11"><i class="fa fa-check"></i><b>26.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html"><i class="fa fa-check"></i><b>27</b> M9A: Basic Regression</a>
<ul>
<li class="chapter" data-level="27.1" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#introduction-17"><i class="fa fa-check"></i><b>27.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#reg-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="27.2" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model1"><i class="fa fa-check"></i><b>27.2</b> One numerical explanatory variable</a>
<ul>
<li class="chapter" data-level="27.2.1" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model1EDA"><i class="fa fa-check"></i><b>27.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="27.2.2" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model1table"><i class="fa fa-check"></i><b>27.2.2</b> Simple linear regression</a></li>
<li class="chapter" data-level="27.2.3" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model1points"><i class="fa fa-check"></i><b>27.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model2"><i class="fa fa-check"></i><b>27.3</b> One categorical explanatory variable</a>
<ul>
<li class="chapter" data-level="27.3.1" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model2EDA"><i class="fa fa-check"></i><b>27.3.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="27.3.2" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model2table"><i class="fa fa-check"></i><b>27.3.2</b> Linear regression</a></li>
<li class="chapter" data-level="27.3.3" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#model2points"><i class="fa fa-check"></i><b>27.3.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="27.4" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#reg-related-topics"><i class="fa fa-check"></i><b>27.4</b> Related topics</a>
<ul>
<li class="chapter" data-level="27.4.1" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#correlation-is-not-causation"><i class="fa fa-check"></i><b>27.4.1</b> Correlation is not necessarily causation</a></li>
<li class="chapter" data-level="27.4.2" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#leastsquares"><i class="fa fa-check"></i><b>27.4.2</b> Best-fitting line</a></li>
<li class="chapter" data-level="27.4.3" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#underthehood"><i class="fa fa-check"></i><b>27.4.3</b> get_regression_x() functions</a></li>
</ul></li>
<li class="chapter" data-level="27.5" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#reg-conclusion"><i class="fa fa-check"></i><b>27.5</b> Conclusion</a></li>
<li class="chapter" data-level="27.6" data-path="m9a-basic-regression.html"><a href="m9a-basic-regression.html#references-12"><i class="fa fa-check"></i><b>27.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="m9c-perform-a-basic-regression-with-your-own-data.html"><a href="m9c-perform-a-basic-regression-with-your-own-data.html"><i class="fa fa-check"></i><b>28</b> M9C: Perform a Basic Regression With Your Own Data</a></li>
<li class="chapter" data-level="29" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html"><i class="fa fa-check"></i><b>29</b> M10U: Consequences of Failed Predictions</a>
<ul>
<li class="chapter" data-level="29.1" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#introduction-18"><i class="fa fa-check"></i><b>29.1</b> Introduction</a></li>
<li class="chapter" data-level="29.2" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#regression-and-automated-content-moderation"><i class="fa fa-check"></i><b>29.2</b> Regression and Automated Content Moderation</a></li>
<li class="chapter" data-level="29.3" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#the-problem-with-automated-content-moderation"><i class="fa fa-check"></i><b>29.3</b> The Problem with Automated Content Moderation</a></li>
<li class="chapter" data-level="29.4" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#an-example-from-instagram"><i class="fa fa-check"></i><b>29.4</b> An Example from Instagram</a></li>
<li class="chapter" data-level="29.5" data-path="m10u-consequences-of-failed-predictions.html"><a href="m10u-consequences-of-failed-predictions.html#conclusion-12"><i class="fa fa-check"></i><b>29.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html"><i class="fa fa-check"></i><b>30</b> M10A: Multiple Regression</a>
<ul>
<li class="chapter" data-level="" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#mult-reg-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="30.1" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4"><i class="fa fa-check"></i><b>30.1</b> One numerical and one categorical explanatory variable</a>
<ul>
<li class="chapter" data-level="30.1.1" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4EDA"><i class="fa fa-check"></i><b>30.1.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="30.1.2" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4interactiontable"><i class="fa fa-check"></i><b>30.1.2</b> Model with interactions</a></li>
<li class="chapter" data-level="30.1.3" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4table"><i class="fa fa-check"></i><b>30.1.3</b> Model without interactions</a></li>
<li class="chapter" data-level="30.1.4" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model4points"><i class="fa fa-check"></i><b>30.1.4</b> Observed responses, fitted values, and residuals</a></li>
</ul></li>
<li class="chapter" data-level="30.2" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model3"><i class="fa fa-check"></i><b>30.2</b> Two numerical explanatory variables</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model3EDA"><i class="fa fa-check"></i><b>30.2.1</b> Exploratory data analysis</a></li>
<li class="chapter" data-level="30.2.2" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model3table"><i class="fa fa-check"></i><b>30.2.2</b> Multiple regression with two numerical regressors</a></li>
<li class="chapter" data-level="30.2.3" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#model3points"><i class="fa fa-check"></i><b>30.2.3</b> Observed/fitted values and residuals</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#mult-reg-conclusion"><i class="fa fa-check"></i><b>30.3</b> Conclusion</a></li>
<li class="chapter" data-level="30.4" data-path="m10a-multiple-regression.html"><a href="m10a-multiple-regression.html#references-13"><i class="fa fa-check"></i><b>30.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="m10c-perform-a-multiple-regression-with-your-own-data.html"><a href="m10c-perform-a-multiple-regression-with-your-own-data.html"><i class="fa fa-check"></i><b>31</b> M10C: Perform a Multiple Regression With Your Own Data</a></li>
<li class="chapter" data-level="32" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html"><i class="fa fa-check"></i><b>32</b> M11U: Samples and Populations</a>
<ul>
<li class="chapter" data-level="32.1" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#introduction-19"><i class="fa fa-check"></i><b>32.1</b> Introduction</a></li>
<li class="chapter" data-level="32.2" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#samples"><i class="fa fa-check"></i><b>32.2</b> Samples</a>
<ul>
<li class="chapter" data-level="32.2.1" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#variation-in-samples"><i class="fa fa-check"></i><b>32.2.1</b> Variation in Samples</a></li>
<li class="chapter" data-level="32.2.2" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#sample-sizes"><i class="fa fa-check"></i><b>32.2.2</b> Sample Sizes</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#probability"><i class="fa fa-check"></i><b>32.3</b> Probability</a></li>
<li class="chapter" data-level="32.4" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#expected-values-and-the-law-of-large-numbers"><i class="fa fa-check"></i><b>32.4</b> Expected Values and the Law of Large Numbers</a></li>
<li class="chapter" data-level="32.5" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#probability-and-sampling"><i class="fa fa-check"></i><b>32.5</b> Probability and Sampling</a></li>
<li class="chapter" data-level="32.6" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#probability-and-the-normal-distribution"><i class="fa fa-check"></i><b>32.6</b> Probability and the Normal Distribution</a></li>
<li class="chapter" data-level="32.7" data-path="m11u-samples-and-populations.html"><a href="m11u-samples-and-populations.html#conclusion-13"><i class="fa fa-check"></i><b>32.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="m11a-sampling.html"><a href="m11a-sampling.html"><i class="fa fa-check"></i><b>33</b> M11A: Sampling</a>
<ul>
<li class="chapter" data-level="" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-packages"><i class="fa fa-check"></i>Needed packages</a></li>
<li class="chapter" data-level="33.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-activity"><i class="fa fa-check"></i><b>33.1</b> First activity: red balls</a>
<ul>
<li class="chapter" data-level="33.1.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#population-proportion"><i class="fa fa-check"></i><b>33.1.1</b> The proportion of red balls in the bowl</a></li>
<li class="chapter" data-level="33.1.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-manual"><i class="fa fa-check"></i><b>33.1.2</b> Manual sampling</a></li>
<li class="chapter" data-level="33.1.3" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-simulation"><i class="fa fa-check"></i><b>33.1.3</b> Virtual sampling</a></li>
</ul></li>
<li class="chapter" data-level="33.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-framework"><i class="fa fa-check"></i><b>33.2</b> Sampling framework</a>
<ul>
<li class="chapter" data-level="33.2.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#terminology-and-notation"><i class="fa fa-check"></i><b>33.2.1</b> Population, sample, and the sampling distribution</a></li>
</ul></li>
<li class="chapter" data-level="33.3" data-path="m11a-sampling.html"><a href="m11a-sampling.html#central-limit-theorem"><i class="fa fa-check"></i><b>33.3</b> The Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#random-variables"><i class="fa fa-check"></i><b>33.3.1</b> Random variables</a></li>
<li class="chapter" data-level="33.3.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#the-sampling-distribution-using-random-variables"><i class="fa fa-check"></i><b>33.3.2</b> The sampling distribution using random variables</a></li>
<li class="chapter" data-level="33.3.3" data-path="m11a-sampling.html"><a href="m11a-sampling.html#the-center-of-the-distribution-the-expected-value"><i class="fa fa-check"></i><b>33.3.3</b> The center of the distribution: the expected value</a></li>
<li class="chapter" data-level="33.3.4" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-variation"><i class="fa fa-check"></i><b>33.3.4</b> Sampling variation: standard deviation and standard error</a></li>
<li class="chapter" data-level="33.3.5" data-path="m11a-sampling.html"><a href="m11a-sampling.html#summary-4"><i class="fa fa-check"></i><b>33.3.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-activity-mean"><i class="fa fa-check"></i><b>33.4</b> Second activity: chocolate-covered almonds</a>
<ul>
<li class="chapter" data-level="33.4.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#population-mean"><i class="fa fa-check"></i><b>33.4.1</b> The population mean weight of almonds in the bowl</a></li>
<li class="chapter" data-level="33.4.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#resampling-tactile-bowl"><i class="fa fa-check"></i><b>33.4.2</b> Manual sampling and sample means</a></li>
<li class="chapter" data-level="33.4.3" data-path="m11a-sampling.html"><a href="m11a-sampling.html#virtual-samples-mean-bowl"><i class="fa fa-check"></i><b>33.4.3</b> Virtual sampling</a></li>
<li class="chapter" data-level="33.4.4" data-path="m11a-sampling.html"><a href="m11a-sampling.html#the-sampling-distribution-of-the-sample-mean"><i class="fa fa-check"></i><b>33.4.4</b> The sampling distribution of the sample mean</a></li>
<li class="chapter" data-level="33.4.5" data-path="m11a-sampling.html"><a href="m11a-sampling.html#random-variable-sample-mean"><i class="fa fa-check"></i><b>33.4.5</b> Random variables</a></li>
<li class="chapter" data-level="33.4.6" data-path="m11a-sampling.html"><a href="m11a-sampling.html#CLT-mean"><i class="fa fa-check"></i><b>33.4.6</b> The Central Limit Theorem revisited</a></li>
</ul></li>
<li class="chapter" data-level="33.5" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-other-scenarios"><i class="fa fa-check"></i><b>33.5</b> The sampling distribution in other scenarios</a>
<ul>
<li class="chapter" data-level="33.5.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-distribution-for-two-samples"><i class="fa fa-check"></i><b>33.5.1</b> Sampling distribution for two samples</a></li>
</ul></li>
<li class="chapter" data-level="33.6" data-path="m11a-sampling.html"><a href="m11a-sampling.html#sampling-final-remarks"><i class="fa fa-check"></i><b>33.6</b> Summary and final remarks</a>
<ul>
<li class="chapter" data-level="33.6.1" data-path="m11a-sampling.html"><a href="m11a-sampling.html#summary-of-scenarios"><i class="fa fa-check"></i><b>33.6.1</b> Summary of scenarios</a></li>
<li class="chapter" data-level="33.6.2" data-path="m11a-sampling.html"><a href="m11a-sampling.html#whats-to-come"><i class="fa fa-check"></i><b>33.6.2</b> What’s to come?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="34" data-path="m11c-explore-sampling-with-your-own-data.html"><a href="m11c-explore-sampling-with-your-own-data.html"><i class="fa fa-check"></i><b>34</b> M11C: Explore Sampling With Your Own Data</a></li>
<li class="chapter" data-level="35" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html"><i class="fa fa-check"></i><b>35</b> M12U: Confident About What?</a>
<ul>
<li class="chapter" data-level="35.1" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html#introduction-20"><i class="fa fa-check"></i><b>35.1</b> Introduction</a></li>
<li class="chapter" data-level="35.2" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html#travelingwhiletrans"><i class="fa fa-check"></i><b>35.2</b> #TravelingWhileTrans</a></li>
<li class="chapter" data-level="35.3" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html#conclusion-14"><i class="fa fa-check"></i><b>35.3</b> Conclusion</a></li>
<li class="chapter" data-level="35.4" data-path="m12u-confident-about-what.html"><a href="m12u-confident-about-what.html#references-14"><i class="fa fa-check"></i><b>35.4</b> References</a></li>
</ul></li>
<li class="chapter" data-level="36" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>36</b> M12A: Confidence Intervals</a>
<ul>
<li class="chapter" data-level="36.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#introduction-21"><i class="fa fa-check"></i><b>36.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="confidence-intervals.html"><a href="confidence-intervals.html#CI-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#resampling-tactile"><i class="fa fa-check"></i><b>36.2</b> Pennies activity</a>
<ul>
<li class="chapter" data-level="36.2.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#what-is-the-average-year-on-us-pennies-in-2019"><i class="fa fa-check"></i><b>36.2.1</b> What is the average year on US pennies in 2019?</a></li>
<li class="chapter" data-level="36.2.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#resampling-once"><i class="fa fa-check"></i><b>36.2.2</b> Resampling once</a></li>
<li class="chapter" data-level="36.2.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#student-resamples"><i class="fa fa-check"></i><b>36.2.3</b> Resampling 35 times</a></li>
<li class="chapter" data-level="36.2.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ci-what-did-we-just-do"><i class="fa fa-check"></i><b>36.2.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="36.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#resampling-simulation"><i class="fa fa-check"></i><b>36.3</b> Computer simulation of resampling</a>
<ul>
<li class="chapter" data-level="36.3.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#virtually-resampling-once"><i class="fa fa-check"></i><b>36.3.1</b> Virtually resampling once</a></li>
<li class="chapter" data-level="36.3.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#bootstrap-35-replicates"><i class="fa fa-check"></i><b>36.3.2</b> Virtually resampling 35 times</a></li>
<li class="chapter" data-level="36.3.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#bootstrap-1000-replicates"><i class="fa fa-check"></i><b>36.3.3</b> Virtually resampling 1000 times</a></li>
</ul></li>
<li class="chapter" data-level="36.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ci-build-up"><i class="fa fa-check"></i><b>36.4</b> Understanding confidence intervals</a>
<ul>
<li class="chapter" data-level="36.4.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#percentile-method"><i class="fa fa-check"></i><b>36.4.1</b> Percentile method</a></li>
<li class="chapter" data-level="36.4.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#se-method"><i class="fa fa-check"></i><b>36.4.2</b> Standard error method</a></li>
</ul></li>
<li class="chapter" data-level="36.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#bootstrap-process"><i class="fa fa-check"></i><b>36.5</b> Constructing confidence intervals</a>
<ul>
<li class="chapter" data-level="36.5.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#original-workflow"><i class="fa fa-check"></i><b>36.5.1</b> Original workflow</a></li>
<li class="chapter" data-level="36.5.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#infer-workflow"><i class="fa fa-check"></i><b>36.5.2</b> <code>infer</code> package workflow</a></li>
<li class="chapter" data-level="36.5.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#percentile-method-infer"><i class="fa fa-check"></i><b>36.5.3</b> Percentile method with <code>infer</code></a></li>
<li class="chapter" data-level="36.5.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#infer-se"><i class="fa fa-check"></i><b>36.5.4</b> Standard error method with <code>infer</code></a></li>
</ul></li>
<li class="chapter" data-level="36.6" data-path="confidence-intervals.html"><a href="confidence-intervals.html#one-prop-ci"><i class="fa fa-check"></i><b>36.6</b> Interpreting confidence intervals</a>
<ul>
<li class="chapter" data-level="36.6.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ilyas-yohan"><i class="fa fa-check"></i><b>36.6.1</b> Did the net capture the fish?</a></li>
<li class="chapter" data-level="36.6.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#shorthand"><i class="fa fa-check"></i><b>36.6.2</b> Precise and shorthand interpretation</a></li>
<li class="chapter" data-level="36.6.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ci-width"><i class="fa fa-check"></i><b>36.6.3</b> Width of confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="36.7" data-path="confidence-intervals.html"><a href="confidence-intervals.html#case-study-two-prop-ci"><i class="fa fa-check"></i><b>36.7</b> Case study: Is yawning contagious?</a>
<ul>
<li class="chapter" data-level="36.7.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#mythbusters-study-data"><i class="fa fa-check"></i><b>36.7.1</b> <em>Mythbusters</em> study data</a></li>
<li class="chapter" data-level="36.7.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#sampling-scenario"><i class="fa fa-check"></i><b>36.7.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="36.7.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ci-build"><i class="fa fa-check"></i><b>36.7.3</b> Constructing the confidence interval</a></li>
<li class="chapter" data-level="36.7.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#interpreting-the-confidence-interval"><i class="fa fa-check"></i><b>36.7.4</b> Interpreting the confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="36.8" data-path="confidence-intervals.html"><a href="confidence-intervals.html#ci-conclusion"><i class="fa fa-check"></i><b>36.8</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="37" data-path="m12c-explore-confidence-intervals-with-your-own-data.html"><a href="m12c-explore-confidence-intervals-with-your-own-data.html"><i class="fa fa-check"></i><b>37</b> M12C: Explore Confidence Intervals With Your Own Data</a></li>
<li class="chapter" data-level="38" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html"><i class="fa fa-check"></i><b>38</b> M13U: The Dangers of False Positives</a>
<ul>
<li class="chapter" data-level="38.1" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#introduction-22"><i class="fa fa-check"></i><b>38.1</b> Introduction</a></li>
<li class="chapter" data-level="38.2" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#the-dartmouth-cheating-scandal"><i class="fa fa-check"></i><b>38.2</b> The Dartmouth Cheating Scandal</a></li>
<li class="chapter" data-level="38.3" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#what-was-wrong-with-dartmouths-investigation"><i class="fa fa-check"></i><b>38.3</b> What Was Wrong With Dartmouth’s Investigation</a></li>
<li class="chapter" data-level="38.4" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#investigations-of-students-must-start-with-concrete-evidence"><i class="fa fa-check"></i><b>38.4</b> Investigations of Students Must Start With Concrete Evidence</a></li>
<li class="chapter" data-level="38.5" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#a-problem-with-companies-and-transparency"><i class="fa fa-check"></i><b>38.5</b> A Problem with Companies and Transparency</a></li>
<li class="chapter" data-level="38.6" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#not-just-dartmouth"><i class="fa fa-check"></i><b>38.6</b> Not Just Dartmouth</a></li>
<li class="chapter" data-level="38.7" data-path="m13u-the-dangers-of-false-positives.html"><a href="m13u-the-dangers-of-false-positives.html#conclusion-15"><i class="fa fa-check"></i><b>38.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html"><i class="fa fa-check"></i><b>39</b> M13: Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="39.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#introduction-23"><i class="fa fa-check"></i><b>39.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#nhst-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="39.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-activity"><i class="fa fa-check"></i><b>39.2</b> Promotions activity</a>
<ul>
<li class="chapter" data-level="39.2.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#does-gender-affect-promotions-at-a-bank"><i class="fa fa-check"></i><b>39.2.1</b> Does gender affect promotions at a bank?</a></li>
<li class="chapter" data-level="39.2.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#shuffling-once"><i class="fa fa-check"></i><b>39.2.2</b> Shuffling once</a></li>
<li class="chapter" data-level="39.2.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#shuffling-16-times"><i class="fa fa-check"></i><b>39.2.3</b> Shuffling 16 times</a></li>
<li class="chapter" data-level="39.2.4" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-what-did-we-just-do"><i class="fa fa-check"></i><b>39.2.4</b> What did we just do?</a></li>
</ul></li>
<li class="chapter" data-level="39.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#understanding-ht"><i class="fa fa-check"></i><b>39.3</b> Understanding hypothesis tests</a></li>
<li class="chapter" data-level="39.4" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-infer"><i class="fa fa-check"></i><b>39.4</b> Conducting hypothesis tests</a>
<ul>
<li class="chapter" data-level="39.4.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#infer-workflow-ht"><i class="fa fa-check"></i><b>39.4.1</b> <code>infer</code> package workflow</a></li>
<li class="chapter" data-level="39.4.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#comparing-infer-workflows"><i class="fa fa-check"></i><b>39.4.2</b> Comparison with confidence intervals</a></li>
<li class="chapter" data-level="39.4.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#only-one-test"><i class="fa fa-check"></i><b>39.4.3</b> “There is only one test”</a></li>
</ul></li>
<li class="chapter" data-level="39.5" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-interpretation"><i class="fa fa-check"></i><b>39.5</b> Interpreting hypothesis tests</a>
<ul>
<li class="chapter" data-level="39.5.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#trial"><i class="fa fa-check"></i><b>39.5.1</b> Two possible outcomes</a></li>
<li class="chapter" data-level="39.5.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#types-of-errors"><i class="fa fa-check"></i><b>39.5.2</b> Types of errors</a></li>
<li class="chapter" data-level="39.5.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#choosing-alpha"><i class="fa fa-check"></i><b>39.5.3</b> How do we choose alpha?</a></li>
</ul></li>
<li class="chapter" data-level="39.6" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#ht-case-study"><i class="fa fa-check"></i><b>39.6</b> Case study: Are action or romance movies rated higher?</a>
<ul>
<li class="chapter" data-level="39.6.1" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#imdb-data"><i class="fa fa-check"></i><b>39.6.1</b> IMDb ratings data</a></li>
<li class="chapter" data-level="39.6.2" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#sampling-scenario-1"><i class="fa fa-check"></i><b>39.6.2</b> Sampling scenario</a></li>
<li class="chapter" data-level="39.6.3" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#conducting-the-hypothesis-test"><i class="fa fa-check"></i><b>39.6.3</b> Conducting the hypothesis test</a></li>
</ul></li>
<li class="chapter" data-level="39.7" data-path="m13-hypothesis-testing.html"><a href="m13-hypothesis-testing.html#nhst-conclusion"><i class="fa fa-check"></i><b>39.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="m13c-explore-hypothesis-testing-with-your-own-data.html"><a href="m13c-explore-hypothesis-testing-with-your-own-data.html"><i class="fa fa-check"></i><b>40</b> M13C: Explore Hypothesis Testing With Your Own Data</a></li>
<li class="chapter" data-level="41" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html"><i class="fa fa-check"></i><b>41</b> M14U: Small Stories vs. Big Data</a>
<ul>
<li class="chapter" data-level="41.1" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#introduction-24"><i class="fa fa-check"></i><b>41.1</b> Introduction</a></li>
<li class="chapter" data-level="41.2" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#the-origins-of-autoethnography"><i class="fa fa-check"></i><b>41.2</b> The Origins of Autoethnography</a></li>
<li class="chapter" data-level="41.3" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#what-does-autoethnography-look-like"><i class="fa fa-check"></i><b>41.3</b> What does Autoethnography Look Like?</a></li>
<li class="chapter" data-level="41.4" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#how-do-autoethnographers-measure-quality"><i class="fa fa-check"></i><b>41.4</b> How do Autoethnographers Measure Quality?</a></li>
<li class="chapter" data-level="41.5" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#conclusion-16"><i class="fa fa-check"></i><b>41.5</b> Conclusion</a></li>
<li class="chapter" data-level="41.6" data-path="m14u-small-stories-vs.-big-data.html"><a href="m14u-small-stories-vs.-big-data.html#references-15"><i class="fa fa-check"></i><b>41.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="42" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html"><i class="fa fa-check"></i><b>42</b> M14A: Inferential Regression</a>
<ul>
<li class="chapter" data-level="42.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#introduction-25"><i class="fa fa-check"></i><b>42.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#inf-packages"><i class="fa fa-check"></i>Needed packages</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-refresher"><i class="fa fa-check"></i><b>42.2</b> Regression refresher</a>
<ul>
<li class="chapter" data-level="42.2.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#teaching-evaluations-analysis"><i class="fa fa-check"></i><b>42.2.1</b> Teaching evaluations analysis</a></li>
<li class="chapter" data-level="42.2.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#sampling-scenario-2"><i class="fa fa-check"></i><b>42.2.2</b> Sampling scenario</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-interp"><i class="fa fa-check"></i><b>42.3</b> Interpreting regression tables</a>
<ul>
<li class="chapter" data-level="42.3.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-se"><i class="fa fa-check"></i><b>42.3.1</b> Standard error</a></li>
<li class="chapter" data-level="42.3.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-test-statistic"><i class="fa fa-check"></i><b>42.3.2</b> Test statistic</a></li>
<li class="chapter" data-level="42.3.3" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#p-value"><i class="fa fa-check"></i><b>42.3.3</b> p-value</a></li>
<li class="chapter" data-level="42.3.4" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#confidence-interval"><i class="fa fa-check"></i><b>42.3.4</b> Confidence interval</a></li>
<li class="chapter" data-level="42.3.5" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-table-computation"><i class="fa fa-check"></i><b>42.3.5</b> How does R compute the table?</a></li>
</ul></li>
<li class="chapter" data-level="42.4" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#regression-conditions"><i class="fa fa-check"></i><b>42.4</b> Conditions for inference for regression</a>
<ul>
<li class="chapter" data-level="42.4.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#residuals-refresher"><i class="fa fa-check"></i><b>42.4.1</b> Residuals refresher</a></li>
<li class="chapter" data-level="42.4.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#linearity-of-relationship"><i class="fa fa-check"></i><b>42.4.2</b> Linearity of relationship</a></li>
<li class="chapter" data-level="42.4.3" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#independence-of-residuals"><i class="fa fa-check"></i><b>42.4.3</b> Independence of residuals</a></li>
<li class="chapter" data-level="42.4.4" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#normality-of-residuals"><i class="fa fa-check"></i><b>42.4.4</b> Normality of residuals</a></li>
<li class="chapter" data-level="42.4.5" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#equality-of-variance"><i class="fa fa-check"></i><b>42.4.5</b> Equality of variance</a></li>
<li class="chapter" data-level="42.4.6" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#what-is-the-conclusion"><i class="fa fa-check"></i><b>42.4.6</b> What’s the conclusion?</a></li>
</ul></li>
<li class="chapter" data-level="42.5" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#infer-regression"><i class="fa fa-check"></i><b>42.5</b> Simulation-based inference for regression</a>
<ul>
<li class="chapter" data-level="42.5.1" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#confidence-interval-for-slope"><i class="fa fa-check"></i><b>42.5.1</b> Confidence interval for slope</a></li>
<li class="chapter" data-level="42.5.2" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#hypothesis-test-for-slope"><i class="fa fa-check"></i><b>42.5.2</b> Hypothesis test for slope</a></li>
</ul></li>
<li class="chapter" data-level="42.6" data-path="m14a-inferential-regression.html"><a href="m14a-inferential-regression.html#inference-conclusion"><i class="fa fa-check"></i><b>42.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="43" data-path="m14c-perform-an-inferential-regression-with-your-own-data.html"><a href="m14c-perform-an-inferential-regression-with-your-own-data.html"><i class="fa fa-check"></i><b>43</b> M14C: Perform an Inferential Regression With Your Own Data</a></li>
<li class="chapter" data-level="44" data-path="m15u-reflect-on-your-understanding-of-data-science.html"><a href="m15u-reflect-on-your-understanding-of-data-science.html"><i class="fa fa-check"></i><b>44</b> M15U: Reflect on Your Understanding of Data Science</a></li>
<li class="chapter" data-level="45" data-path="m15a-reflect-on-your-application-of-data-science.html"><a href="m15a-reflect-on-your-application-of-data-science.html"><i class="fa fa-check"></i><b>45</b> M15A: Reflect on Your Application of Data Science</a></li>
<li class="chapter" data-level="46" data-path="m15c-reflect-on-your-connection-of-data-science.html"><a href="m15c-reflect-on-your-connection-of-data-science.html"><i class="fa fa-check"></i><b>46</b> M15C: Reflect on Your Connection of Data Science</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="m11a-sampling" class="section level1 hasAnchor" number="33">
<h1><span class="header-section-number">33</span> M11A: Sampling<a href="m11a-sampling.html#m11a-sampling" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>This content draws on material from <em><a href="https://moderndive.com/v2">Statistical Inference via Data Science: A ModernDive into R and the Tidyverse [Second Edition]</a></em> by <a href="https://chester.rbind.io/">Chester Ismay</a>, <a href="https://rudeboybert.rbind.io/">Albert Y. Kim</a>, and <a href="https://avaldivi6.github.io/">Arturo Valdivia</a> licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p>
<p>Changes to the source material include addition of new material; light editing; rearranging, removing, and combining original material; adding and changing links; and adding first-person language from current author.</p>
<p>The resulting content is licensed under <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a></p>
<div id="sampling-packages" class="section level2 unnumbered hasAnchor">
<h2>Needed packages<a href="m11a-sampling.html#sampling-packages" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If needed, read Section <a href="m2a-getting-started-with-data-in-r.html#packages">6.3</a> for information on how to install and load R packages.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="m11a-sampling.html#cb226-1" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb226-2"><a href="m11a-sampling.html#cb226-2" tabindex="-1"></a><span class="fu">library</span>(moderndive)</span>
<span id="cb226-3"><a href="m11a-sampling.html#cb226-3" tabindex="-1"></a><span class="fu">library</span>(infer)</span></code></pre></div>
<p>Recall that loading the <code>tidyverse</code> package loads many packages that we have encountered earlier. For details refer to Section <a href="m6a-wrangling-and-tidying-data.html#tidyverse-package">18.4</a>. The packages <code>moderndive</code> and <code>infer</code> contain functions and data frames that will be used in this chapter.</p>
</div>
<div id="sampling-activity" class="section level2 hasAnchor" number="33.1">
<h2><span class="header-section-number">33.1</span> First activity: red balls<a href="m11a-sampling.html#sampling-activity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Take a look at the bowl in Figure <a href="m11a-sampling.html#fig:sampling-exercise-1">33.1</a>. It has red and white balls of equal size. The balls have been mixed beforehand, and there does not seem to be any particular pattern for the location of red and white balls inside the bowl.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling-exercise-1"></span>
<img src="images/sampling/balls/sampling_bowl_1.jpg" alt="A bowl with red and white balls." width="95%" />
<p class="caption">
Figure 33.1: A bowl with red and white balls.
</p>
</div>
<div id="population-proportion" class="section level3 hasAnchor" number="33.1.1">
<h3><span class="header-section-number">33.1.1</span> The proportion of red balls in the bowl<a href="m11a-sampling.html#population-proportion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s say that we’re interested in finding the proportion of red balls in the bowl. To find this proportion, we could count the number of red balls and divide this number by the total number of balls. The bowl seen in Figure <a href="m11a-sampling.html#fig:sampling-exercise-1">33.1</a> is represented virtually by the data frame <code>bowl</code> included in the <code>moderndive</code> package. The first ten rows are shown here for illustration purposes:</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="m11a-sampling.html#cb227-1" tabindex="-1"></a>bowl</span></code></pre></div>
<pre><code># A tibble: 2,400 × 2
   ball_ID color
     &lt;int&gt; &lt;chr&gt;
 1       1 white
 2       2 white
 3       3 white
 4       4 red  
 5       5 white
 6       6 white
 7       7 red  
 8       8 white
 9       9 red  
10      10 white
# ℹ 2,390 more rows</code></pre>
<p>The <code>bowl</code> has 2400 rows representing the 2400 balls in the bowl shown in Figure <a href="m11a-sampling.html#fig:sampling-exercise-1">33.1</a>. You can view and scroll through the entire contents of the <code>bowl</code> in RStudio’s data viewer by running <code>View(bowl)</code>. The first variable <code>ball_ID</code> is used as an <em>identification variable</em> as discussed in Subsection <a href="m2a-getting-started-with-data-in-r.html#identification-vs-measurement-variables">6.4.4</a>; none of the balls in the actual bowl are marked with numbers.</p>
<p>The second variable <code>color</code> indicates whether a particular virtual ball is red or white. We can compute the proportion of red balls in the bowl using the <code>dplyr</code> data-wrangling verbs presented in Chapter <a href="m6a-wrangling-and-tidying-data.html#wrangling">18.2</a>. A few steps are needed in order to determine this proportion. Let’s look at these these steps separately to remind you how they work but later introduce all the steps together and simplify some of the code. First, for each of the balls, we identify if it is red or not using a test for equality with the logical operator <code>==</code>. We do this by using the <code>mutate()</code> function from Section <a href="m6a-wrangling-and-tidying-data.html#mutate">18.2.3</a> that allows us to create a new Boolean variable called <code>is_red</code>.</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="m11a-sampling.html#cb229-1" tabindex="-1"></a>bowl <span class="sc">|&gt;</span> </span>
<span id="cb229-2"><a href="m11a-sampling.html#cb229-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">is_red =</span> (color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>))</span></code></pre></div>
<pre><code># A tibble: 2,400 × 3
   ball_ID color is_red
     &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; 
 1       1 white FALSE 
 2       2 white FALSE 
 3       3 white FALSE 
 4       4 red   TRUE  
 5       5 white FALSE 
 6       6 white FALSE 
 7       7 red   TRUE  
 8       8 white FALSE 
 9       9 red   TRUE  
10      10 white FALSE 
# ℹ 2,390 more rows</code></pre>
<p>The variable <code>is_red</code> returns the Boolean (that is, logical) value <code>TRUE</code> for each row where <code>color == "red"</code> and <code>FALSE</code> for every row where <code>color</code> is not equal to <code>"red"</code>. Since R treats <code>TRUE</code> like the number <code>1</code> and <code>FALSE</code> like the number <code>0</code>, accounting for <code>TRUE</code>s and <code>FALSE</code>s is equivalent to working with <code>1</code>’s and <code>0</code>’s. In particular, adding all the <code>1</code>’s and <code>0</code>’s is equivalent to counting how many red balls are in the bowl.</p>
<p>Let’s compute this using the <code>sum()</code> function inside the <code>summarize()</code> function. Recall from Section <a href="m8a-descriptive-statistics.html#summarize">24.2</a> that <code>summarize()</code> takes a data frame with many rows and returns a data frame with a single row containing summary statistics such as the <code>sum()</code>:</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="m11a-sampling.html#cb231-1" tabindex="-1"></a>bowl <span class="sc">|&gt;</span> </span>
<span id="cb231-2"><a href="m11a-sampling.html#cb231-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">is_red =</span> (color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb231-3"><a href="m11a-sampling.html#cb231-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">num_red =</span> <span class="fu">sum</span>(is_red))</span></code></pre></div>
<pre><code># A tibble: 1 × 1
  num_red
    &lt;int&gt;
1     900</code></pre>
<p>The <code>sum()</code> has added all the <code>1</code>’s and <code>0</code>’s and has effectively counted the number of red balls. There are 900 red balls in the bowl. Since the bowl contains 2400 balls, the proportion of red balls is 900/2400 = 0.375. We could ask R to find the proportion directly by replacing <code>sum()</code> with the <code>mean()</code> function inside <code>summarize()</code>. The average of <code>1</code>’s and <code>0</code>’s is precisely the proportion of red balls in the bowl:</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="m11a-sampling.html#cb233-1" tabindex="-1"></a>bowl <span class="sc">|&gt;</span> </span>
<span id="cb233-2"><a href="m11a-sampling.html#cb233-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">is_red =</span> (color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>)) <span class="sc">|&gt;</span> </span>
<span id="cb233-3"><a href="m11a-sampling.html#cb233-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(is_red))</span></code></pre></div>
<pre><code># A tibble: 1 × 1
  prop_red
     &lt;dbl&gt;
1    0.375</code></pre>
<p>This code works well but can be simplified once more. Instead of creating a new Boolean variable <code>is_red</code> before finding the proportion, we could write both steps simultaneously in a single line of code:</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="m11a-sampling.html#cb235-1" tabindex="-1"></a>bowl <span class="sc">|&gt;</span> </span>
<span id="cb235-2"><a href="m11a-sampling.html#cb235-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>))</span></code></pre></div>
<pre><code># A tibble: 1 × 1
  prop_red
     &lt;dbl&gt;
1    0.375</code></pre>
<p>In the rest of this chapter, we’ll be using this kind of calculation frequently. subsections.</p>
</div>
<div id="sampling-manual" class="section level3 hasAnchor" number="33.1.2">
<h3><span class="header-section-number">33.1.2</span> Manual sampling<a href="m11a-sampling.html#sampling-manual" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the previous subsection, we were able to find the proportion of red balls in the bowl using R only because we had the information of the entire bowl as a data frame. Otherwise, we would have to retrieve this manually. If the bowl contained a large number of balls, this could be a long and tedious process. How long do you think it would take to do this manually if the bowl had tens of thousands of balls? Or millions? Or even more?</p>
<p>In real-life situations, we are often interested in finding the proportion of a very large number of objects (or subjects), and performing an exhaustive count could be tedious, costly, impractical, or even impossible. Because of these limitations, we typically do not perform exhaustive counts. Rather, for this balls example, we randomly select a sample of balls from the bowl, find the proportion of red balls in this sample, and use this proportion to (hopefully) learn more about the proportion of red balls in the entire bowl.</p>
<div id="one-sample" class="section level4 unnumbered hasAnchor">
<h4>One sample<a href="m11a-sampling.html#one-sample" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We could do this by inserting a shovel into the bowl as seen in Figure <a href="m11a-sampling.html#fig:sampling-exercise-2">33.2</a> and collecting <span class="math inline">\(5 \cdot 10 = 50\)</span> balls as shown in Figure <a href="m11a-sampling.html#fig:sampling-exercise-3">33.3</a>. The set of balls retrieved is called a <em>sample</em>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling-exercise-2"></span>
<img src="images/sampling/balls/sampling_bowl_2.jpg" alt="Inserting a shovel into the bowl." width="100%" />
<p class="caption">
Figure 33.2: Inserting a shovel into the bowl.
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling-exercise-3"></span>
<img src="images/sampling/balls/sampling_bowl_3_cropped.jpg" alt="Taking a sample of 50 balls from the bowl." width="80%" />
<p class="caption">
Figure 33.3: Taking a sample of 50 balls from the bowl.
</p>
</div>
<p>Since 17 of the balls are red, the proportion of red balls in the sample is 17/50 = 0.34 or 34%. Compare this to the proportion of red balls in the entire bowl, 0.375, that we found in Subsection <a href="m11a-sampling.html#population-proportion">33.1.1</a>. The proportion from the sample seems actually pretty good, and it did not take much time or energy to get. But, was this approximate proportion just a lucky outcome? Could we be this lucky the next time we take a sample from the bowl? Let’s imagine that we take more samples from the bowl and calculate the proportions of red balls in those samples.</p>
</div>
<div id="thirty-three-samples" class="section level4 unnumbered hasAnchor">
<h4>Thirty-three samples<a href="m11a-sampling.html#thirty-three-samples" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Each time we take another sample, we do the following:</p>
<ul>
<li>return the 50 balls used earlier back into the bowl and mix the contents of the bowl to ensure that each new sample is not influenced by the previous sample; then,</li>
<li>take a new sample with the shovel and determine a new proportion of red balls.</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling-exercise-3b"></span>
<img src="images/sampling/balls/tactile_2_a.jpg" alt="Repeating sampling activity." width="25%" /><img src="images/sampling/balls/tactile_2_b.jpg" alt="Repeating sampling activity." width="25%" /><img src="images/sampling/balls/tactile_2_c.jpg" alt="Repeating sampling activity." width="25%" />
<p class="caption">
Figure 33.4: Repeating sampling activity.
</p>
</div>
<p>If we did this many times, we would observe that different samples may produce different proportions of red balls. A proportion of red balls from a sample is called a <em>sample proportion</em>. A group of 33 students performed this activity previously and drew a histogram using blocks to represent sample proportions of red balls. Figure <a href="m11a-sampling.html#fig:sampling-exercise-4">33.5</a> shows students working on the histogram with two blocks drawn already representing the first two sample proportions found and the third about to be added.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling-exercise-4"></span>
<img src="images/sampling/balls/tactile_3_a.jpg" alt="Students drawing a histogram of sample proportions." width="60%" />
<p class="caption">
Figure 33.5: Students drawing a histogram of sample proportions.
</p>
</div>
<p>Recall from Section <a href="m7a-data-visualization.html#histograms">21.5</a> that histograms help us visualize the <em>distribution</em> of a numerical variable. In particular, where the center of the values falls and how the values vary. A histogram of the first 10 sample proportions can be seen in Figure <a href="m11a-sampling.html#fig:sampling-exercise-5">33.6</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling-exercise-5"></span>
<img src="images/sampling/balls/tactile_3_c-2e.png" alt="Hand-drawn histogram of 10 sample proportions." width="\textwidth" height="30%" />
<p class="caption">
Figure 33.6: Hand-drawn histogram of 10 sample proportions.
</p>
</div>
<p>By looking at the histogram, we can see that the lowest proportion of red balls was between 0.20 and 0.25 while the highest was between 0.45 and 0.5. More importantly, the most frequently occurring proportions were between 0.30 and 0.35.</p>
<p>This real-life version of the activity has results stored in the <code>tactile_prop_red</code> data frame included in the <code>moderndive</code> package. Here are the first 10 rows:</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="m11a-sampling.html#cb237-1" tabindex="-1"></a>tactile_prop_red</span></code></pre></div>
<pre><code># A tibble: 33 × 4
   group            replicate red_balls prop_red
   &lt;chr&gt;                &lt;int&gt;     &lt;int&gt;    &lt;dbl&gt;
 1 Ilyas, Yohan             1        21     0.42
 2 Morgan, Terrance         2        17     0.34
 3 Martin, Thomas           3        21     0.42
 4 Clark, Frank             4        21     0.42
 5 Riddhi, Karina           5        18     0.36
 6 Andrew, Tyler            6        19     0.38
 7 Julia                    7        19     0.38
 8 Rachel, Lauren           8        11     0.22
 9 Daniel, Caroline         9        15     0.3 
10 Josh, Maeve             10        17     0.34
# ℹ 23 more rows</code></pre>
<p>Notice that for each student <code>group</code>, the data frame provides their names, the number of <code>red_balls</code> observed in the sample, and the calculated proportion of red balls in the sample, <code>prop_red</code>. We also have a <code>replicate</code> variable counting off each of the 33 groups. The name <code>replicate</code> indicates that each row can be viewed as one instance of a replicated (in other words “repeated”) activity.</p>
<p>Using the R data visualization techniques introduced earlier in the semester, we can construct the histogram for all 33 sample proportions as shown in Figure <a href="m11a-sampling.html#fig:samplingdistribution-tactile">33.7</a>. Recall that each student has a sample of 50 balls using the same procedure and has calculated the proportion of red balls in each sample. The histogram is built using only those sample proportions. We do not need the individual information of each student or the number of red balls found. We constructed the histogram using <code>ggplot()</code> with <code>geom_histogram()</code>. To align the bins in the computerized histogram version so it matches the hand-drawn histogram shown in Figure <a href="m11a-sampling.html#fig:sampling-exercise-5">33.6</a>, this code uses the arguments <code>boundary = 0.4</code> and <code>binwidth = 0.05</code>. The former indicates that we want a binning scheme, so that one of the bins’ boundaries is at 0.4; the latter fixes the width of the bin to 0.05 units.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="m11a-sampling.html#cb239-1" tabindex="-1"></a><span class="fu">ggplot</span>(tactile_prop_red, <span class="fu">aes</span>(<span class="at">x =</span> prop_red)) <span class="sc">+</span></span>
<span id="cb239-2"><a href="m11a-sampling.html#cb239-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.05</span>, <span class="at">boundary =</span> <span class="fl">0.4</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb239-3"><a href="m11a-sampling.html#cb239-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Proportion of red balls in each sample&quot;</span>, </span>
<span id="cb239-4"><a href="m11a-sampling.html#cb239-4" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;Histogram of 33 proportions&quot;</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:samplingdistribution-tactile"></span>
<img src="_main_files/figure-html/samplingdistribution-tactile-1.png" alt="The distribution of sample proportions based on 33 random samples of size 50." width="\textwidth" />
<p class="caption">
Figure 33.7: The distribution of sample proportions based on 33 random samples of size 50.
</p>
</div>
<p>When studying the histogram, we can see that some proportions are lower than 25% and others are greater than 45%, but most of the sample proportions are between 30% and 45%.</p>
<p>We can also use this activity to introduce some statistical terminology. The process of taking repeated <em>samples</em> of 50 balls and finding the corresponding <em>sample proportions</em> is called <em>sampling</em>. Since we returned the observed balls to the bowl before getting another sample, we say that we performed <em>sampling with replacement</em> and because we mixed the balls before taking a new sample, the samples were <em>randomly drawn</em> and are called <em>random samples</em>.</p>
<p>As shown in Figure <a href="m11a-sampling.html#fig:samplingdistribution-tactile">33.7</a>, different random samples produce different sample proportions. This phenomenon is called <em>sampling variation</em>. Furthermore, the histogram is a graphical representation of the <em>distribution</em> of sample proportions; it describes the sample proportions determined and how often they appear. The distribution of all possible sample proportions that can be found from random samples is called, appropriately, the <em>sampling distribution</em> of the sample proportion. The sampling distribution is central to the ideas we develop in this chapter.</p>
</div>
</div>
<div id="sampling-simulation" class="section level3 hasAnchor" number="33.1.3">
<h3><span class="header-section-number">33.1.3</span> Virtual sampling<a href="m11a-sampling.html#sampling-simulation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the previous Subsection <a href="m11a-sampling.html#sampling-manual">33.1.2</a>, we imagined a <em>tactile</em> sampling activity: students took physical samples using a real shovel from a bowl with white and red balls by hand. Let’s now extend the entire process using simulations on a computer, a sort of <em>virtual</em> sampling activity.</p>
<p>The use of simulations permits us to study not only 33 random samples but thousands, tens of thousands, or even more samples. When a large number of random samples is retrieved, we can gain a better understanding of the <em>sampling distribution</em> and the <em>sampling variation</em> of sample proportions. In addition, we are not limited by samples of 50 balls, as we can simulate sampling with any desired sample size. We’ll go through all of this in this subsection, beginning by reproducing our manual activity.</p>
<div id="one-virtual-sample" class="section level4 unnumbered hasAnchor">
<h4>One virtual sample<a href="m11a-sampling.html#one-virtual-sample" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Recall that the bowl seen in Figure <a href="m11a-sampling.html#fig:sampling-exercise-1">33.1</a> is represented by the data frame <code>bowl</code> included in the <code>moderndive</code> package. The virtual analog to the 50-ball shovel seen in Figure <a href="m11a-sampling.html#fig:sampling-exercise-2">33.2</a> can be achieved using the <code>rep_slice_sample()</code> function included in the <code>moderndive</code> package. This function allows us to take <code>rep</code>eated (or <code>rep</code>licated) random <code>samples</code> of size <code>n</code>.</p>
<p>Let’s start by taking a single sample of 50 balls. Before running the code, though, remember that sampling is a random, variable process. As you run the <em>code</em> in the book, you may get different <em>results</em> than the book. In most cases, that won’t be an issue, though you should use your critical thinking and statistical reasoning to look out for potential problems!</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="m11a-sampling.html#cb240-1" tabindex="-1"></a>virtual_shovel <span class="ot">&lt;-</span> bowl <span class="sc">|&gt;</span> </span>
<span id="cb240-2"><a href="m11a-sampling.html#cb240-2" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">50</span>)</span>
<span id="cb240-3"><a href="m11a-sampling.html#cb240-3" tabindex="-1"></a>virtual_shovel</span></code></pre></div>
<pre><code># A tibble: 50 × 3
# Groups:   replicate [1]
   replicate ball_ID color
       &lt;int&gt;   &lt;int&gt; &lt;chr&gt;
 1         1    1970 white
 2         1     842 red  
 3         1    2287 white
 4         1     599 white
 5         1     108 white
 6         1     846 red  
 7         1     390 red  
 8         1     344 white
 9         1     910 white
10         1    1485 white
# ℹ 40 more rows</code></pre>
<p>Notice that <code>virtual_shovel</code> has 50, rows corresponding to our virtual sample of size 50. The <code>ball_ID</code> variable identifies which of the 2400 balls from <code>bowl</code> are included in our sample of 50 balls while <code>color</code> denotes whether its white or red. The <code>replicate</code> variable is equal to 1 for all 50 rows because we have decided to take only one sample right now. Later on, we take more samples, and <code>replicate</code> will take more values.</p>
<p>Let’s compute the proportion of red balls in our virtual sample. The code we use is similar to the one used for finding the proportion of red balls in the entire bowl in Subsection <a href="m11a-sampling.html#population-proportion">33.1.1</a>:</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="m11a-sampling.html#cb242-1" tabindex="-1"></a>virtual_shovel <span class="sc">|&gt;</span> </span>
<span id="cb242-2"><a href="m11a-sampling.html#cb242-2" tabindex="-1"></a> <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  replicate prop_red
      &lt;int&gt;    &lt;dbl&gt;
1         1     0.24</code></pre>
<p>Based on this random sample, 24% of the <code>virtual_shovel</code>’s 50 balls were red! Remember, though, that because sampling is random, you may well get a different result. Let’s proceed finding the sample proportion for more random samples.</p>
</div>
<div id="thirty-three-virtual-samples" class="section level4 unnumbered hasAnchor">
<h4>Thirty-three virtual samples<a href="m11a-sampling.html#thirty-three-virtual-samples" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In Section <a href="m11a-sampling.html#sampling-activity">33.1</a>, students got 33 samples and sample proportions. They repeated/replicated the sampling process 33 times. Let’s do this virtually by again using the function <code>rep_slice_sample()</code> and this time adding the <code>reps = 33</code> argument as we want to retrieve 33 random samples. We’ll save these samples in the data frame <code>virtual_samples</code>, as shown, and then provide a preview of its first 10 rows. If you want to inspect the entire <code>virtual_samples</code> data frame, use RStudio’s data viewer by running <code>View(virtual_samples)</code>.</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="m11a-sampling.html#cb244-1" tabindex="-1"></a>virtual_samples <span class="ot">&lt;-</span> bowl <span class="sc">|&gt;</span> </span>
<span id="cb244-2"><a href="m11a-sampling.html#cb244-2" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">50</span>, <span class="at">reps =</span> <span class="dv">33</span>)</span>
<span id="cb244-3"><a href="m11a-sampling.html#cb244-3" tabindex="-1"></a>virtual_samples</span></code></pre></div>
<pre><code># A tibble: 1,650 × 3
# Groups:   replicate [33]
   replicate ball_ID color
       &lt;int&gt;   &lt;int&gt; &lt;chr&gt;
 1         1    1970 white
 2         1     842 red  
 3         1    2287 white
 4         1     599 white
 5         1     108 white
 6         1     846 red  
 7         1     390 red  
 8         1     344 white
 9         1     910 white
10         1    1485 white
# ℹ 1,640 more rows</code></pre>
<p>Observe in the data viewer that the first 50 rows of <code>replicate</code> are equal to <code>1</code>, the next 50 rows of <code>replicate</code> are equal to <code>2</code>, and so on. The first 50 rows correspond to the first sample of 50 balls while the next 50 rows correspond to the second sample of 50 balls. This pattern continues for all <code>reps = 33</code> replicates, and thus <code>virtual_samples</code> has 33 <span class="math inline">\(\cdot\)</span> 50 = 1650 rows.</p>
<p>Using <code>virtual_samples</code>, we can find the proportion of red balls for each replicate. Let’s use the same <code>dplyr</code> verbs as before. In particular, we add <code>group_by()</code> of the <code>replicate</code> variable. Recall from Section <a href="m8a-descriptive-statistics.html#groupby">24.3</a> that by assigning the grouping variable “meta-data” before <code>summarize()</code>, we perform the calculations needed for each replicate separately. The other line of code, as explained in the case of one sample, calculates the sample proportion of red balls. Here’s a preview of my first 10 rows:</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="m11a-sampling.html#cb246-1" tabindex="-1"></a>virtual_prop_red <span class="ot">&lt;-</span> virtual_samples <span class="sc">|&gt;</span> </span>
<span id="cb246-2"><a href="m11a-sampling.html#cb246-2" tabindex="-1"></a>  <span class="fu">group_by</span>(replicate) <span class="sc">|&gt;</span> </span>
<span id="cb246-3"><a href="m11a-sampling.html#cb246-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>)) </span>
<span id="cb246-4"><a href="m11a-sampling.html#cb246-4" tabindex="-1"></a>virtual_prop_red</span></code></pre></div>
<pre><code># A tibble: 33 × 2
   replicate prop_red
       &lt;int&gt;    &lt;dbl&gt;
 1         1     0.24
 2         2     0.46
 3         3     0.38
 4         4     0.36
 5         5     0.38
 6         6     0.3 
 7         7     0.42
 8         8     0.42
 9         9     0.32
10        10     0.48
# ℹ 23 more rows</code></pre>
<p>Technically, the function <code>rep_slice_sample()</code> already groups the data by replicate, so it is not 100% necessary to include <code>group_by()</code> in the code. Moreover, using <code>dplyr</code> pipes in R we could simplify the work and write everything at once:</p>
<ul>
<li>using <code>rep_slice_sample()</code>, we have 33 replicates (each being a random sample of 50 balls) and<br />
</li>
<li>using <code>summarize()</code> with <code>mean()</code> on the Boolean values, we determine the proportion of red balls for each sample.</li>
</ul>
<p>Let’s store these proportions in the data frame <code>virtual_prop_red</code>. I’ll print my first 10 sample proportions (for the first 10 samples) as an illustration:</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="m11a-sampling.html#cb248-1" tabindex="-1"></a>virtual_prop_red <span class="ot">&lt;-</span> bowl <span class="sc">|&gt;</span> </span>
<span id="cb248-2"><a href="m11a-sampling.html#cb248-2" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">50</span>, <span class="at">reps =</span> <span class="dv">33</span>) <span class="sc">|&gt;</span></span>
<span id="cb248-3"><a href="m11a-sampling.html#cb248-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>))</span>
<span id="cb248-4"><a href="m11a-sampling.html#cb248-4" tabindex="-1"></a>virtual_prop_red</span></code></pre></div>
<pre><code># A tibble: 33 × 2
   replicate prop_red
       &lt;int&gt;    &lt;dbl&gt;
 1         1     0.24
 2         2     0.46
 3         3     0.38
 4         4     0.36
 5         5     0.38
 6         6     0.3 
 7         7     0.42
 8         8     0.42
 9         9     0.32
10        10     0.48
# ℹ 23 more rows</code></pre>
<p>As was the case in the tactile activity, there is sampling variation in the resulting 33 proportions from the virtual samples. (In fact, you should see differences between my variation and your variation!) Let’s construct a histogram with these sample proportions as shown in Figure <a href="m11a-sampling.html#fig:samplingdistribution-virtual">33.8</a>. The histogram helps us visualize the sampling distribution of the sample proportion. Observe again the histogram was constructed using <code>ggplot()</code>, <code>geom_histogram()</code>, and including the arguments <code>binwidth = 0.05</code> and <code>boundary = 0.4</code>.</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="m11a-sampling.html#cb250-1" tabindex="-1"></a><span class="fu">ggplot</span>(virtual_prop_red, <span class="fu">aes</span>(<span class="at">x =</span> prop_red)) <span class="sc">+</span></span>
<span id="cb250-2"><a href="m11a-sampling.html#cb250-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.05</span>, <span class="at">boundary =</span> <span class="fl">0.4</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb250-3"><a href="m11a-sampling.html#cb250-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sample proportion&quot;</span>, </span>
<span id="cb250-4"><a href="m11a-sampling.html#cb250-4" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;Histogram of 33 sample proportions&quot;</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:samplingdistribution-virtual"></span>
<img src="_main_files/figure-html/samplingdistribution-virtual-1.png" alt="The distribution of 33 proportions based on 33 virtual samples of size 50." width="\textwidth" />
<p class="caption">
Figure 33.8: The distribution of 33 proportions based on 33 virtual samples of size 50.
</p>
</div>
<p>When observing the histogram, we can see that some proportions are lower than 25% and others are greater than 45%. Also, the sample proportions observed more frequently are between 35% and 40% (for 11 out of 33 samples). We found similar results when sampling was done by hand in Subsection <a href="m11a-sampling.html#sampling-manual">33.1.2</a>, and that histogram was presented in Figure <a href="m11a-sampling.html#fig:samplingdistribution-tactile">33.7</a>. You can see both histograms side by side in Figure <a href="m11a-sampling.html#fig:tactile-vs-virtual">33.9</a> for an easy comparison. Note that they are somewhat similar in their center and variation, although not identical. The differences are also due to <em>sampling variation</em>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tactile-vs-virtual"></span>
<img src="_main_files/figure-html/tactile-vs-virtual-1.png" alt="The sampling distribution of the sample proportion and sampling variation:  showing a histogram for virtual sample proportions (left) and another histogram for tactile sample proportions (right)." width="\textwidth" />
<p class="caption">
Figure 33.9: The sampling distribution of the sample proportion and sampling variation: showing a histogram for virtual sample proportions (left) and another histogram for tactile sample proportions (right).
</p>
</div>
</div>
<div id="one-thousand-virtual-samples" class="section level4 unnumbered hasAnchor">
<h4>One thousand virtual samples<a href="m11a-sampling.html#one-thousand-virtual-samples" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>It was helpful to observe how sampling variation affects sample proportions in 33 samples. It was also interesting to note that while the 33 virtual samples provide different sample proportions than the 33 physical samples, the overall patterns were fairly similar. Because the samples were taken at random in both cases, any other set of 33 samples, virtual or physical, would provide a different set of sample proportions due to sampling variation, but the overall patterns would still be similar. Still, 33 samples are not enough to fully understand these patterns.</p>
<p>This is why we’re now going to study the sampling distribution and the effects of sampling variation with 1000 random samples. Trying to do this manually could be impractical, but getting virtual samples can be done quickly and efficiently. Additionally, we have already developed the tools for this. We’ll repeat the steps performed earlier using the <code>rep_slice_sample()</code> function with a sample <code>size</code> set to be 50. This time, however, let’s set the number of replicates (<code>reps</code>) to <code>1000</code>, and use <code>summarize()</code> and <code>mean()</code> again on the Boolean values to calculate the sample proportions. We’ll compute <code>virtual_prop_red</code> with the count of red balls and the corresponding sample proportion for all 1000 random samples. The proportions for my first 10 samples are shown:</p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="m11a-sampling.html#cb251-1" tabindex="-1"></a>virtual_prop_red <span class="ot">&lt;-</span> bowl <span class="sc">|&gt;</span> </span>
<span id="cb251-2"><a href="m11a-sampling.html#cb251-2" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">50</span>, <span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb251-3"><a href="m11a-sampling.html#cb251-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>))</span>
<span id="cb251-4"><a href="m11a-sampling.html#cb251-4" tabindex="-1"></a>virtual_prop_red</span></code></pre></div>
<pre><code># A tibble: 1,000 × 2
   replicate prop_red
       &lt;int&gt;    &lt;dbl&gt;
 1         1     0.24
 2         2     0.46
 3         3     0.38
 4         4     0.36
 5         5     0.38
 6         6     0.3 
 7         7     0.42
 8         8     0.42
 9         9     0.32
10        10     0.48
# ℹ 990 more rows</code></pre>
<p>As done previously, a histogram for these 1000 sample proportions is given in Figure <a href="m11a-sampling.html#fig:samplingdistribution-virtual-1000">33.10</a>.</p>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="m11a-sampling.html#cb253-1" tabindex="-1"></a><span class="fu">ggplot</span>(virtual_prop_red, <span class="fu">aes</span>(<span class="at">x =</span> prop_red)) <span class="sc">+</span></span>
<span id="cb253-2"><a href="m11a-sampling.html#cb253-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.04</span>, <span class="at">boundary =</span> <span class="fl">0.4</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb253-3"><a href="m11a-sampling.html#cb253-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sample proportion&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Histogram of 1000 sample proportions&quot;</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:samplingdistribution-virtual-1000"></span>
<img src="_main_files/figure-html/samplingdistribution-virtual-1000-1.png" alt="The distribution of 1000 proportions based on 1000 random samples of size 50." width="\textwidth" />
<p class="caption">
Figure 33.10: The distribution of 1000 proportions based on 1000 random samples of size 50.
</p>
</div>
<p>The sample proportions represented by the histogram could be as low as 15% or as high as 60%, but those extreme proportions are rare. The most frequent proportions determined are those between 35% and 40%.</p>
<p>Please read the “Normal distribution” section of (<a href="https://moderndive.com/v2/appendixa">Appendix A online</a>) for a brief discussion of this distribution and its properties.</p>
</div>
<div id="different-sample-sizes" class="section level4 unnumbered hasAnchor">
<h4>Different sample sizes<a href="m11a-sampling.html#different-sample-sizes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Another advantage of using simulations is that we can also study how the sampling distribution of the sample proportion changes if we find the sample proportions from samples smaller than or larger than 50 balls. We do need to be careful to not mix results, though: we build the sampling distribution using sample proportions from samples of the <strong>same</strong> size, but the size chosen does not have to be 50 balls.</p>
<p>We must first decide the sample size we want to use, and then take samples using that size. As an illustration, we can perform the sampling activity three times, for each activity using a different sample size, think of having three shovels of sizes 25, 50, and 100 as shown in Figure <a href="m11a-sampling.html#fig:three-shovels">33.11</a>. Of course, we do this virtually: with each shovel size we gather many random samples, calculate the corresponding sample proportions, and plot those proportions in a histogram. Therefore we create three histograms, each one describing the sampling distribution for sample proportions from samples of size 25, 50, and 100, respectively. As we show later in this subsection, the size of the sample has a direct effect on the sampling distribution and the magnitude of its sampling variation.</p>
<!--
A shovel with 25 slots          |  A shovel with 50 slots  | A shovel with 100 slots
:-------------------------:|:-------------------------:|:-------------------------:
![](images/sampling/balls/shovel_025.jpg){ width=1.6in }  |  ![](images/sampling/balls/shovel_050.jpg){ width=1.6in } | ![](images/sampling/balls/shovel_100.jpg){ width=1.6in } 
-->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:three-shovels"></span>
<img src="images/sampling/balls/three_shovels.png" alt="Three shovels to extract three different sample sizes." width="100%" />
<p class="caption">
Figure 33.11: Three shovels to extract three different sample sizes.
</p>
</div>
<p>We follow the same process performed previously: we generate 1000 samples, find the sample proportions, and use them to draw a histogram. We follow this process three different times, setting the <code>size</code> argument in the code equal to <code>25</code>, <code>50</code>, and <code>100</code>, respectively. We run each of the following code segments individually and then compare the resulting histograms.</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="m11a-sampling.html#cb254-1" tabindex="-1"></a><span class="co"># Segment 1: sample size = 25 ------------------------------</span></span>
<span id="cb254-2"><a href="m11a-sampling.html#cb254-2" tabindex="-1"></a><span class="co"># 1.a) Compute sample proportions for 1000 samples, each sample of size 25</span></span>
<span id="cb254-3"><a href="m11a-sampling.html#cb254-3" tabindex="-1"></a>virtual_prop_red_25 <span class="ot">&lt;-</span> bowl <span class="sc">|&gt;</span> </span>
<span id="cb254-4"><a href="m11a-sampling.html#cb254-4" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">25</span>, <span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb254-5"><a href="m11a-sampling.html#cb254-5" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>))</span>
<span id="cb254-6"><a href="m11a-sampling.html#cb254-6" tabindex="-1"></a></span>
<span id="cb254-7"><a href="m11a-sampling.html#cb254-7" tabindex="-1"></a><span class="co"># 1.b) Plot a histogram to represent the distribution of the sample proportions</span></span>
<span id="cb254-8"><a href="m11a-sampling.html#cb254-8" tabindex="-1"></a><span class="fu">ggplot</span>(virtual_prop_red_25, <span class="fu">aes</span>(<span class="at">x =</span> prop_red)) <span class="sc">+</span></span>
<span id="cb254-9"><a href="m11a-sampling.html#cb254-9" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.05</span>, <span class="at">boundary =</span> <span class="fl">0.4</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb254-10"><a href="m11a-sampling.html#cb254-10" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Proportion of 25 balls that were red&quot;</span>, <span class="at">title =</span> <span class="st">&quot;25&quot;</span>) </span>
<span id="cb254-11"><a href="m11a-sampling.html#cb254-11" tabindex="-1"></a></span>
<span id="cb254-12"><a href="m11a-sampling.html#cb254-12" tabindex="-1"></a></span>
<span id="cb254-13"><a href="m11a-sampling.html#cb254-13" tabindex="-1"></a><span class="co"># Segment 2: sample size = 50 ------------------------------</span></span>
<span id="cb254-14"><a href="m11a-sampling.html#cb254-14" tabindex="-1"></a><span class="co"># 2.a) Compute sample proportions for 1000 samples, each sample of size 50</span></span>
<span id="cb254-15"><a href="m11a-sampling.html#cb254-15" tabindex="-1"></a>virtual_prop_red_50 <span class="ot">&lt;-</span> bowl <span class="sc">|&gt;</span> </span>
<span id="cb254-16"><a href="m11a-sampling.html#cb254-16" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">50</span>, <span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb254-17"><a href="m11a-sampling.html#cb254-17" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>))</span>
<span id="cb254-18"><a href="m11a-sampling.html#cb254-18" tabindex="-1"></a></span>
<span id="cb254-19"><a href="m11a-sampling.html#cb254-19" tabindex="-1"></a><span class="co"># 2.b) Plot a histogram to represent the distribution of the sample proportions</span></span>
<span id="cb254-20"><a href="m11a-sampling.html#cb254-20" tabindex="-1"></a><span class="fu">ggplot</span>(virtual_prop_red_50, <span class="fu">aes</span>(<span class="at">x =</span> prop_red)) <span class="sc">+</span></span>
<span id="cb254-21"><a href="m11a-sampling.html#cb254-21" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.05</span>, <span class="at">boundary =</span> <span class="fl">0.4</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb254-22"><a href="m11a-sampling.html#cb254-22" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Proportion of 50 balls that were red&quot;</span>, <span class="at">title =</span> <span class="st">&quot;50&quot;</span>)  </span>
<span id="cb254-23"><a href="m11a-sampling.html#cb254-23" tabindex="-1"></a></span>
<span id="cb254-24"><a href="m11a-sampling.html#cb254-24" tabindex="-1"></a></span>
<span id="cb254-25"><a href="m11a-sampling.html#cb254-25" tabindex="-1"></a><span class="co"># Segment 3: sample size = 100 ------------------------------</span></span>
<span id="cb254-26"><a href="m11a-sampling.html#cb254-26" tabindex="-1"></a><span class="co"># 2.a) Compute sample proportions for 1000 samples, each sample of size 100</span></span>
<span id="cb254-27"><a href="m11a-sampling.html#cb254-27" tabindex="-1"></a>virtual_prop_red_100 <span class="ot">&lt;-</span> bowl <span class="sc">|&gt;</span> </span>
<span id="cb254-28"><a href="m11a-sampling.html#cb254-28" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb254-29"><a href="m11a-sampling.html#cb254-29" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>))</span>
<span id="cb254-30"><a href="m11a-sampling.html#cb254-30" tabindex="-1"></a></span>
<span id="cb254-31"><a href="m11a-sampling.html#cb254-31" tabindex="-1"></a><span class="co"># 3.b) Plot a histogram to represent the distribution of the sample proportions</span></span>
<span id="cb254-32"><a href="m11a-sampling.html#cb254-32" tabindex="-1"></a><span class="fu">ggplot</span>(virtual_prop_red_100, <span class="fu">aes</span>(<span class="at">x =</span> prop_red)) <span class="sc">+</span></span>
<span id="cb254-33"><a href="m11a-sampling.html#cb254-33" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.05</span>, <span class="at">boundary =</span> <span class="fl">0.4</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb254-34"><a href="m11a-sampling.html#cb254-34" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Proportion of 100 balls that were red&quot;</span>, <span class="at">title =</span> <span class="st">&quot;100&quot;</span>) </span></code></pre></div>
<p>For easy comparison, we can present the three resulting histograms in a single row with matching <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> axes in Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions">33.12</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:comparing-sampling-distributions"></span>
<img src="_main_files/figure-html/comparing-sampling-distributions-1.png" alt="Histograms of sample proportions for different sample sizes." width="\textwidth" />
<p class="caption">
Figure 33.12: Histograms of sample proportions for different sample sizes.
</p>
</div>
<p>Observe that all three histograms:</p>
<ul>
<li>are centered around the same middle value, which appears to be a value slightly below 0.4,</li>
<li>are somewhat bell-shaped, and</li>
<li>exhibit <em>sampling variation</em> that is different for each sample size. In particular, as the sample size increases from 25 to 50 to 100, the sample proportions do not vary as much and they seem to get closer to the middle value.</li>
</ul>
<p>These are important characteristics of the <em>sampling distribution</em> of the sample proportion: The first observation relates to the shape of the distribution, the second to the center of the distribution, and the last one to the <em>sampling variation</em> and how it is affected by the sample size. These results are not coincidental or isolated to the example of sample proportions of red balls in a bowl. In the next subsection, a theoretical framework is introduced that helps explain with precise mathematical equations the behavior of sample proportions coming from random samples.</p>
</div>
</div>
</div>
<div id="sampling-framework" class="section level2 hasAnchor" number="33.2">
<h2><span class="header-section-number">33.2</span> Sampling framework<a href="m11a-sampling.html#sampling-framework" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Section <a href="m11a-sampling.html#sampling-activity">33.1</a>, we gained some intuition about sampling and its characteristics. In this section, we’ll cover some statistical definitions and terminology related to sampling. We’ll conclude by introducing key characteristics that will be formally studied in the rest of the chapter.</p>
<div id="terminology-and-notation" class="section level3 hasAnchor" number="33.2.1">
<h3><span class="header-section-number">33.2.1</span> Population, sample, and the sampling distribution<a href="m11a-sampling.html#terminology-and-notation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <strong>population</strong> or <strong>study population</strong> is a collection of all individuals or observations of interest. In the bowl activities the <strong>population</strong> is the collection of all the balls in the bowl. A <strong>sample</strong> is a subset of the population. <strong>Sampling</strong> is the act of collecting samples from the population. <strong>Simple random sampling</strong> is <em>sampling</em> where each member of the population has the same chance of being selected, for example, by using a shovel to select balls from a bowl. A <strong>random sample</strong> is a sample found using simple random sampling. In the bowl activities, physical and virtual, we use simple random sampling to get random samples from the bowl.</p>
<p>A <strong>population parameter</strong> (or simply a <strong>parameter</strong>) is a numerical summary (a number) that represents some characteristic of the population. A <strong>sample statistic</strong> (or simply a <strong>statistic</strong>) is a numerical summary computed from a sample. In the bowl activities the parameter of interest was the population proportion <span class="math inline">\(p=\)</span> 0.375. Similarly, previously a sample of 50 balls was taken and 17 were red. A statistic is the <em>sample proportion</em> which in this example was equal to <span class="math inline">\(\widehat{p}= 0.34\)</span>. Observe how we use <span class="math inline">\(p\)</span> to represent the population proportion (parameter) and <span class="math inline">\(\widehat{p}\)</span> for the sample proportion (statistic).</p>
<p>The <strong>distribution</strong> of a list of numbers is the set of the possible values in the list and how often they occur. The <strong>sampling distribution of the sample proportion</strong> is the <strong>distribution</strong> of sample proportions from <strong>each possible</strong> random samples of a given size. To illustrate this concept, recall that in Subsection <a href="m11a-sampling.html#sampling-simulation">33.1.3</a> we drew three histograms shown in Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions">33.12</a>. The histogram on the left, for example, was constructed from taking 1000 random samples of size <span class="math inline">\(n=25\)</span>, then finding the sample proportion for each sample and using these proportions to draw the histogram. This histogram is a good visual approximation of the <strong>sampling distribution</strong> of the sample proportion.</p>
<p>The <em>sampling distribution</em> can be a difficult concept to grasp right away:</p>
<ul>
<li>The <em>sampling distribution of the sample proportion</em> is the distribution of <em>sample proportions</em>; it is constructed using exclusively <em>sample proportions</em>.</li>
<li>People learning this terminology sometimes confuse the term <em>sampling distribution</em> with a <em>sample’s distribution</em>—the latter can be understood as the distribution of the values in a given sample.</li>
<li>A histogram from a simulation of sample proportions is only a visual approximation of the sampling distribution. It is not the exact distribution. Still, when the simulations produce a large number of sample proportions, the resulting histogram provides a good approximation of the sampling distribution. This was the case in Subsection <a href="m11a-sampling.html#sampling-simulation">33.1.3</a> and the three histograms shown in Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions">33.12</a>.</li>
</ul>
<p>The lessons we learned by performing the activities in Section <a href="m11a-sampling.html#sampling-activity">33.1</a> contribute to gaining insights about key characteristics of the <em>sampling distribution</em> of the <em>sample proportion</em>, namely:</p>
<ol style="list-style-type: decimal">
<li>The center of the <em>sampling distribution</em></li>
<li>The effect of <em>sampling variation</em> on the <em>sampling distribution</em> and the effect of the sample size on this <em>sampling variation</em></li>
<li>The shape of the <em>sampling distribution</em></li>
</ol>
<p>The first two points relate to measures of central tendency and dispersion, respectively. The last one provides a connection to one of the most important theorems in statistics: the Central Limit Theorem. In the next section, we formally study these characteristics.</p>
</div>
</div>
<div id="central-limit-theorem" class="section level2 hasAnchor" number="33.3">
<h2><span class="header-section-number">33.3</span> The Central Limit Theorem<a href="m11a-sampling.html#central-limit-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A fascinating result in statistics is that when retrieving random samples from any population, the corresponding sample means follow a typical behavior: their histogram is bell-shaped and has very unique features. This is true regardless of the distribution of the population values and forms the basis of what we know as the Central Limit Theorem. Before fully describing it, let’s look at a theoretical framework to construct this and other characteristics related to sampling.</p>
<div id="random-variables" class="section level3 hasAnchor" number="33.3.1">
<h3><span class="header-section-number">33.3.1</span> Random variables<a href="m11a-sampling.html#random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A simple theoretical framework can help us formalize important properties of the sampling distribution of the sample proportion. To do this, let’s modify the bowl activity slightly. Instead of using a shovel to select all 25 balls at once, we randomly select one ball at a time, 25 times. If the ball is red we call it a success and record a 1 (one); if it is not red we call it a failure and record a 0 (zero). Then, we return the ball to the bowl so the proportion of red balls in the bowl doesn’t change.</p>
<p>This process is called a trial or a Bernoulli trial in honor of Jacob Bernoulli, a 17th-century mathematician who is among the first ones to work with these trials. Getting a sample of 25 balls is running 25 trials and getting 25 numbers, ones or zeros, representing whether or not we have observed red balls on each trial, respectively. The average of these 25 numbers (zeros or ones) represents precisely the proportion or red balls in a sample of 25 balls.</p>
<p>It is useful to represent a trial as a random variable. We use the uppercase letter <span class="math inline">\(X\)</span> and the subscript <span class="math inline">\(1\)</span> as <span class="math inline">\(X_1\)</span> to denote the random variable for the first trial. After the first trial is completed, so the color of the first ball is observed, the value of <span class="math inline">\(X_1\)</span> is realized as 1 if the ball is red or 0 if the ball is white. For example, if the first ball is red, we write <span class="math inline">\(X_1 = 1\)</span>. Similarly, we use <span class="math inline">\(X_2\)</span> to represent the second trial. For example, if the second ball is white, <span class="math inline">\(X_2\)</span> is realized as <span class="math inline">\(X_2=0\)</span>, and so on. <span class="math inline">\(X_1\)</span>, <span class="math inline">\(X_2\)</span>, <span class="math inline">\(\dots\)</span> are random variables only before the trials have been performed. After the trials, they are just the <em>ones</em> or <em>zeros</em> representing red or white balls, respectively.</p>
<p>Moreover, since our experiment is to perform 25 trials and then find the average of them, this average or mean, before the trials are carried out, can also be expressed as a random variable:</p>
<p><span class="math display">\[\overline X = \frac{X_1+X_2+\dots+X_{25}}{25}.\]</span></p>
<p>Here <span class="math inline">\(\overline X\)</span> is the random variable that represents the average, or mean, of these 25 trials. This is why we call <span class="math inline">\(\overline X\)</span> the <strong>sample mean</strong>. Again, <span class="math inline">\(\overline X\)</span> is a random variable before the 25 trials have been performed. After the trials, <span class="math inline">\(\overline X\)</span> is realized as the average of 25 zeros and ones.
For example, if the results of the trials are</p>
<p><span class="math display">\[\{0,0,0,1,0,1,0,1,0,0,1,0,1,1,0,0,0,1,1,0,1,0,0,0,1 \},\]</span></p>
<p>the observed value of <span class="math inline">\(\overline X\)</span> will be</p>
<p><span class="math display">\[\overline X = \frac{0+0+0+1+0+1+\dots+1+0+0+0+1}{25} = \frac{10}{25}=0.4.\]</span></p>
<p>So, for this particular example, the sample mean is <span class="math inline">\(\overline X = 0.4\)</span>, which happens to be the sample proportion of red balls in this sample of 25 balls. In the context of Bernoulli trials, because we are finding averages of zeros and ones, these <strong>sample means</strong> are <strong>sample proportions</strong>! Connecting with the notation used earlier, observe that after the trials have been completed, <span class="math inline">\(\overline X = \widehat{p}\)</span>.</p>
</div>
<div id="the-sampling-distribution-using-random-variables" class="section level3 hasAnchor" number="33.3.2">
<h3><span class="header-section-number">33.3.2</span> The sampling distribution using random variables<a href="m11a-sampling.html#the-sampling-distribution-using-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that we want to calculate the sample proportion for another random sample of 25 balls. In terms of the random variable <span class="math inline">\(\overline X\)</span>, this is performing 25 trials and finding another 25 values, ones and zeros, for <span class="math inline">\(X_1\)</span>, $X_2, <span class="math inline">\(\dots\)</span>, <span class="math inline">\(X_{25}\)</span> and finding their average. For example we might get:</p>
<p><span class="math display">\[\{1,0,0,1,0,0,0,1,0,0,1,0,1,0,1,1,0,0,0,1,0,1,0,0,0,0\}\]</span></p>
<p>Then, the realization of <span class="math inline">\(\overline X\)</span> will be <span class="math inline">\(\overline X = 9/25 = 0.36\)</span>. This sample proportion was different than the one found earlier, 0.4. The possible values of <span class="math inline">\(\overline X\)</span> are the possible proportions of red balls for a sample of 25 balls. In other words, the value that <span class="math inline">\(\overline X\)</span> takes after the trials have been completed is the sample proportion for the observed sample of red and white balls.</p>
<p>Moreover, while any given trial can result in choosing a red ball or not (1 or 0), the chances or getting a red ball are influenced by the proportion of red balls in the bowl. For example, if a bowl has more red balls than white, the chances of getting a red ball on any given trial are higher than getting a white ball. Because 1 is the realization of a trial when a red ball is observed, the sample proportion also would tend to be higher.</p>
<p>Sampling variation produces different sample proportions for different random samples, but they are influenced by the proportion of red and white balls in the bowl. This is why understanding the sampling distribution of the sample proportion is learning which sample proportions are possible and which proportions are more or less likely to be observed. Since the realization of <span class="math inline">\(\overline X\)</span> is the observed sample proportion, the sampling distribution of the sample proportion is precisely the distribution of <span class="math inline">\(\overline X\)</span>. In the rest of this section, we use both expressions interchangeably. Recall the key characteristics of the <em>sampling distribution</em> of the sample proportion, now given in terms of <span class="math inline">\(\overline X\)</span>:</p>
<ol style="list-style-type: decimal">
<li>The center of the <em>distribution</em> of <span class="math inline">\(\overline X\)</span></li>
<li>The effect of <em>sampling variation</em> on the <em>distribution</em> of <span class="math inline">\(\overline X\)</span> and the effect of the sample size on <em>sampling variation</em></li>
<li>The shape of the <em>distribution</em> of <span class="math inline">\(\overline X\)</span></li>
</ol>
<p>To address these points, we use simulations. Simulations seldom provide the exact structure of the distribution, because an infinite number of samples may be needed for this. A large number of replications often produces a really good approximation of the distribution, though, and can be used to understand well the distribution’s characteristics. Let’s use the output found in Subsection <a href="m11a-sampling.html#sampling-simulation">33.1.3</a>; namely, the sample proportions for samples of size 25, 50, and 100. If we focus on size 25, think of each sample proportion from samples of size 25 as a possible value of <span class="math inline">\(\overline X\)</span>. We now use these sample proportions to illustrate properties of the distribution of <span class="math inline">\(\overline X\)</span>, the sampling distribution of the sample proportion.</p>
</div>
<div id="the-center-of-the-distribution-the-expected-value" class="section level3 hasAnchor" number="33.3.3">
<h3><span class="header-section-number">33.3.3</span> The center of the distribution: the expected value<a href="m11a-sampling.html#the-center-of-the-distribution-the-expected-value" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Since the distribution of <span class="math inline">\(\overline X\)</span> is composed of all the sample proportions that can be calculated for a given sample size, the center of this distribution can be understood as the average of all these proportions. This is the value we would <em>expect</em> to get, on average, from all these sample proportions. This is why the center value of the sampling distribution is called the <strong>expected value</strong> of the sample proportion, and we write <span class="math inline">\(E(\overline X)\)</span>. Based on probability theory, the mean of <span class="math inline">\(\overline X\)</span> happens to be equal to the population proportion of red balls in the bowl. In Subsection <a href="m11a-sampling.html#population-proportion">33.1.1</a> we determined that the population proportion was 900/2400 = 0.375, therefore</p>
<p><span class="math display">\[E(\overline X) = p = 0.375.\]</span></p>
<p>As an illustration, we noted in Subsection <a href="m11a-sampling.html#sampling-simulation">33.1.3</a> when looking at the histograms in Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions">33.12</a> that all three histograms were centered at some value between 0.35 and 0.4 (or between 35% and 40%). As we have established now, they are centered exactly at the expected value of <span class="math inline">\(\overline X\)</span>, which is the population proportion. Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions-3">33.13</a> displays these histograms again, but this time adds a vertical red line on each of them at the location of the population proportion value, <span class="math inline">\(p\)</span> = 0.375.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:comparing-sampling-distributions-3"></span>
<img src="_main_files/figure-html/comparing-sampling-distributions-3-1.png" alt="Three sampling distributions with population proportion $p$ marked by vertical line." width="\textwidth" />
<p class="caption">
Figure 33.13: Three sampling distributions with population proportion <span class="math inline">\(p\)</span> marked by vertical line.
</p>
</div>
<p>The results shown seem to agree with the theory. We can further check, using the simulation results, by finding the average of the 1000 sample proportions. We start with the histogram on the left:</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="m11a-sampling.html#cb255-1" tabindex="-1"></a>virtual_prop_red_25</span></code></pre></div>
<pre><code># A tibble: 1,000 × 3
   replicate prop_red     n
       &lt;int&gt;    &lt;dbl&gt; &lt;int&gt;
 1         1     0.28    25
 2         2     0.6     25
 3         3     0.36    25
 4         4     0.36    25
 5         5     0.2     25
 6         6     0.44    25
 7         7     0.24    25
 8         8     0.08    25
 9         9     0.28    25
10        10     0.4     25
# ℹ 990 more rows</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="m11a-sampling.html#cb257-1" tabindex="-1"></a>virtual_prop_red_25 <span class="sc">|&gt;</span> </span>
<span id="cb257-2"><a href="m11a-sampling.html#cb257-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">E_Xbar_25 =</span> <span class="fu">mean</span>(prop_red))</span></code></pre></div>
<pre><code># A tibble: 1 × 1
  E_Xbar_25
      &lt;dbl&gt;
1     0.372</code></pre>
<p>The variable <code>prop_red</code> in data frame <code>virtual_prop_red_25</code> contains the sample proportions for each of the 1000 samples taken. The average of these sample proportions is presented as object <code>E_Xbar_25</code> which represents the estimated expected value of <span class="math inline">\(\overline X\)</span>, by using the average of the 1000 sample proportions. Each of the sample proportions is calculated from random samples of 25 balls from the bowl. This average happens to be precisely the same as the population proportion.</p>
<p>It is worth spending a moment understanding this result. If we take one random sample of a given size, we know that the sample proportion from this sample would be somewhat different than the population proportion due to sampling variation; however, if we take many random samples of the same size, the average of the sample proportions are expected to be about the same as the population proportion.</p>
<p>We present the equivalent results with samples of size 50 and 100:</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="m11a-sampling.html#cb259-1" tabindex="-1"></a>virtual_prop_red_50 <span class="sc">|&gt;</span> </span>
<span id="cb259-2"><a href="m11a-sampling.html#cb259-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">E_Xbar_50 =</span> <span class="fu">mean</span>(prop_red))</span>
<span id="cb259-3"><a href="m11a-sampling.html#cb259-3" tabindex="-1"></a>virtual_prop_red_100 <span class="sc">|&gt;</span> </span>
<span id="cb259-4"><a href="m11a-sampling.html#cb259-4" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">E_Xbar_100 =</span> <span class="fu">mean</span>(prop_red))</span></code></pre></div>
<pre><code># A tibble: 1 × 1
  E_Xbar_50
      &lt;dbl&gt;
1     0.376</code></pre>
<pre><code># A tibble: 1 × 1
  E_Xbar_100
       &lt;dbl&gt;
1      0.376</code></pre>
<p>Indeed, the results are about the same as the population proportion. Note that the average of 1000 sample proportions for samples of size 50 was actually 0.376, close to 0.375. This happens because the simulations only approximate the sampling distribution and the expected value. When using simulations we do not expect to achieve the exact theoretical results, rather values that are close enough to support our understanding of the theoretical results.</p>
</div>
<div id="sampling-variation" class="section level3 hasAnchor" number="33.3.4">
<h3><span class="header-section-number">33.3.4</span> Sampling variation: standard deviation and standard error<a href="m11a-sampling.html#sampling-variation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Another relevant characteristic observed in Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions-3">33.13</a> is how the amount of dispersion or <em>sampling variation</em> changes when the sample size changes. While all the histograms have a similar bell-shaped configuration and are centered at the same value, observe that when…</p>
<ul>
<li>the sample size is <span class="math inline">\(n=25\)</span> (left histogram) the observed sample proportions are about as low as 0.1 and as high as 0.65.</li>
<li>the sample size is <span class="math inline">\(n=50\)</span> (middle histogram) the observed sample proportions are about as low as 0.15 and as high as 0.55.</li>
<li>the sample size is <span class="math inline">\(n=100\)</span> (right histogram) the observed sample proportions are about as low as 0.20 and as high as 0.5.</li>
</ul>
<p>As the sample size <span class="math inline">\(n\)</span> increases from 25 to 50 to 100, the variation of the sampling distribution decreases. Thus, the values are clustered more and more tightly around the center of the distribution. In other words, the histogram on the left of Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions-3">33.13</a> is more spread out than the one in the middle, which in turn is more spread out than the one on the right.</p>
<p>We know that the center of the distribution is the expected value of <span class="math inline">\(\overline X\)</span>, which is the population proportion. From this, we can quantify this variation by calculating how far the sample proportions are, on average, from the population proportion. A well-known statistical measurement to quantify dispersion is the <em>standard deviation</em>. We discuss how it works before we continue with the sampling variation problem.</p>
<div id="the-standard-deviation" class="section level4 unnumbered hasAnchor">
<h4>The standard deviation<a href="m11a-sampling.html#the-standard-deviation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Let’s start with an example and introduce some special notation. As an illustration, given four values <span class="math inline">\(y_1=3\)</span>, <span class="math inline">\(y_2=-1\)</span>, <span class="math inline">\(y_3=5\)</span>, and <span class="math inline">\(y_4= 9\)</span>, their average is given by</p>
<p><span class="math display">\[\bar y = \frac14\sum_{i=1}^4y_i =\frac14 (y_1 + y_2 + y_3 + y_4)=  \frac{3-1+5+9}{4}= 2.\]</span></p>
<p>The capital Greek letter <span class="math inline">\(\Sigma\)</span> represents the summation of values, and it is useful when a large number of values need to be added. The letter <span class="math inline">\(i\)</span> underneath <span class="math inline">\(\Sigma\)</span> is the index of summation. It starts at <span class="math inline">\(i=1\)</span>, so the first value we are adding is <span class="math inline">\(y_{\bf 1} = 3\)</span>. Afterwards <span class="math inline">\(i=2\)</span>, so we add <span class="math inline">\(y_{\bf 2}=-1\)</span> to our previous result, an so on, as shown in the equation above. The summation symbol can be very useful when adding many numbers or making more complicated operations, such as defining the standard deviation.</p>
<p>To construct the standard deviation of a list of values, we</p>
<ul>
<li>find the deviations of each value from their average,</li>
<li>square those deviations,</li>
<li>find the average of the squared deviations, and</li>
<li>take the square root of this average to finish.</li>
</ul>
<p>In our example, the standard deviation is given by</p>
<p><span class="math display">\[\begin{aligned}
SD &amp;= \sqrt{\frac14\sum_{i=1}^4(y_i - \bar y)^2} = \sqrt{\frac{(3-2)^2+(-1-2)^2+(5-2)^2+(9-2)^2}{4}} \\
   &amp;= \sqrt{\frac{1+9+9+49}{4}}=\sqrt{17} = 4.12
\end{aligned}\]</span></p>
<p>Let’s look at another example, this time using R. Let’s again use our bowl activity with red and white balls in the bowl. We’ll create a Boolean variable <code>is_red</code> that corresponds to <code>TRUE</code>s or <code>1</code>s for red balls and <code>FALSE</code>s or <code>0</code>s for white balls and using these numbers, we’ll compute the proportion (average of <code>1</code>s and <code>0</code>s) using the <code>mean()</code> function and the standard deviation using the <code>sd()</code> function<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> inside <code>summarize()</code>:</p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="m11a-sampling.html#cb262-1" tabindex="-1"></a>bowl <span class="sc">|&gt;</span> </span>
<span id="cb262-2"><a href="m11a-sampling.html#cb262-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">is_red =</span> color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>) <span class="sc">|&gt;</span> </span>
<span id="cb262-3"><a href="m11a-sampling.html#cb262-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">p =</span> <span class="fu">mean</span>(is_red), <span class="at">st_dev =</span> <span class="fu">sd</span>(is_red))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
      p st_dev
  &lt;dbl&gt;  &lt;dbl&gt;
1 0.375  0.484</code></pre>
<p>So, the proportion of red balls is 0.375 with a standard deviation of 0.484. The intuition behind the standard deviation can be expressed as follows: if you were to select many balls, with replacement, from the bowl, we would expect the proportion of red balls to be about 0.375, give or take 0.484.</p>
<p>In addition, when dealing with proportions, the formula for the standard deviation can be expressed directly in terms of the population proportion, <span class="math inline">\(p\)</span>, using the formula:</p>
<p><span class="math display">\[SD = \sqrt{p(1-p)}.\]</span></p>
<p>Here is the value of the standard deviation using this alternative formula in R:</p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="m11a-sampling.html#cb264-1" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.375</span></span>
<span id="cb264-2"><a href="m11a-sampling.html#cb264-2" tabindex="-1"></a><span class="fu">sqrt</span>(p <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p))</span></code></pre></div>
<pre><code>[1] 0.484</code></pre>
<p>The value is the same as using the general formula. Now that we have gained a better understanding of the standard deviation, we can discuss the standard deviation in the context of sampling variation for the sample proportion.</p>
</div>
<div id="the-standard-error" class="section level4 unnumbered hasAnchor">
<h4>The standard error<a href="m11a-sampling.html#the-standard-error" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Recall that we want to measure the magnitude of the sampling variation for the distribution of <span class="math inline">\(\overline X\)</span> (the sampling distribution of the sample proportion) and want to use the standard deviation for this purpose. We saw earlier that the center of the distribution of <span class="math inline">\(\overline X\)</span> is the expected value of <span class="math inline">\(\overline X\)</span>. In our case, this is the population proportion <span class="math inline">\(p = 0.375\)</span>. The standard deviation will then indicate how far, on average, each possible sample proportion roughly is from the population proportion. If we were to consider using a sample proportion as an estimate of the population proportion, this deviation could be considered the error in estimation. Because of this particular relationship, the standard deviation of the sampling distribution receives a special name: the <strong>standard error</strong>. Note that all <em>standard errors</em> are standard deviations but not all standard deviations are standard errors.</p>
<p>Let’s work again with simulations and the bowl of red and white balls. We’ll take 10,000 random samples of size <span class="math inline">\(n=100\)</span>, find the sample proportion for each sample, and calculate the average and standard deviation for these sample proportions. This simulation produces a histogram similar to the one presented on the right in Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions-3">33.13</a>. To produce this data, we’ll again use the <code>rep_slice_sample()</code> function and <code>mean()</code> and <code>sd()</code> function inside <code>summarize()</code> to produce the desired results:</p>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="m11a-sampling.html#cb266-1" tabindex="-1"></a>bowl <span class="sc">|&gt;</span></span>
<span id="cb266-2"><a href="m11a-sampling.html#cb266-2" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">reps =</span> <span class="dv">10000</span>) <span class="sc">|&gt;</span></span>
<span id="cb266-3"><a href="m11a-sampling.html#cb266-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>)) <span class="sc">|&gt;</span></span>
<span id="cb266-4"><a href="m11a-sampling.html#cb266-4" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">p =</span> <span class="fu">mean</span>(prop_red), <span class="at">SE_Xbar =</span> <span class="fu">sd</span>(prop_red))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
      p SE_Xbar
  &lt;dbl&gt;   &lt;dbl&gt;
1 0.375  0.0479</code></pre>
<p>Observe that <code>p</code> is the estimated expected value and <code>SE_Xbar</code> is the estimated standard error based on the simulation of taking sample proportions for random samples of size <span class="math inline">\(n=100\)</span>. Compare this value with the standard deviation for the entire bowl, discovered earlier. It is one-tenth the size! This is not a coincidence: the standard error of <span class="math inline">\(\overline X\)</span> is equal to the standard deviation of the population (the bowl) divided by the square root of the sample size. In the case of sample proportions, the standard error of <span class="math inline">\(\overline X\)</span> can also be determined using the formula:</p>
<p><span class="math display">\[SE(\overline X) = \sqrt{\frac{p(1-p)}{n}}\]</span>
where <span class="math inline">\(p\)</span> is the population proportion and <span class="math inline">\(n\)</span> is the size of our sample. This formula shows that the standard error is inversely proportional to the square root of the sample size: as the sample size increases, the standard error decreases. In our example, the standard error is</p>
<p><span class="math display">\[SE(\overline X) = \sqrt{\frac{0.375\cdot(1-0.375)}{100}} = 0.0484\]</span></p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="m11a-sampling.html#cb268-1" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.375</span></span>
<span id="cb268-2"><a href="m11a-sampling.html#cb268-2" tabindex="-1"></a><span class="fu">sqrt</span>(p <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p) <span class="sc">/</span> <span class="dv">100</span>)</span></code></pre></div>
<pre><code>[1] 0.0484</code></pre>
<p>This value is nearly identical to the result found on the simulation above. We’ll repeat this exercise, this time finding the estimated standard error of <span class="math inline">\(\overline X\)</span> from the simulations done earlier. These simulations are stored in data frames <code>virtual_prop_red_25</code> and <code>virtual_prop_red_50</code>, when the sample sizes used are <span class="math inline">\(n=25\)</span> and <span class="math inline">\(n=50\)</span>, respectively:</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="m11a-sampling.html#cb270-1" tabindex="-1"></a>virtual_prop_red_25 <span class="sc">|&gt;</span> </span>
<span id="cb270-2"><a href="m11a-sampling.html#cb270-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">SE_Xbar_50 =</span> <span class="fu">sd</span>(prop_red))</span></code></pre></div>
<pre><code># A tibble: 1 × 1
  SE_Xbar_50
       &lt;dbl&gt;
1     0.0954</code></pre>
<div class="sourceCode" id="cb272"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb272-1"><a href="m11a-sampling.html#cb272-1" tabindex="-1"></a>virtual_prop_red_50 <span class="sc">|&gt;</span> </span>
<span id="cb272-2"><a href="m11a-sampling.html#cb272-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">SE_Xbar_100 =</span> <span class="fu">sd</span>(prop_red))</span></code></pre></div>
<pre><code># A tibble: 1 × 1
  SE_Xbar_100
        &lt;dbl&gt;
1      0.0687</code></pre>
<p>The standard errors for these examples, based on the proportion of red balls in the bowl and the sample sizes, are here:</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="m11a-sampling.html#cb274-1" tabindex="-1"></a><span class="fu">sqrt</span>(p <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p) <span class="sc">/</span> <span class="dv">25</span>)</span></code></pre></div>
<pre><code>[1] 0.0968</code></pre>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="m11a-sampling.html#cb276-1" tabindex="-1"></a><span class="fu">sqrt</span>(p <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p) <span class="sc">/</span> <span class="dv">50</span>)</span></code></pre></div>
<pre><code>[1] 0.0685</code></pre>
<p>The simulations support the standard errors derived using mathematical formulas. The simulations are used to check that in fact the results achieved agree with the theory. Observe also that the theoretical results are constructed based on the knowledge of the population proportion, <span class="math inline">\(p\)</span>; by contrast, the simulations produce samples based on the population of interest but produce results only based on information found from samples and sample proportions.</p>
<p>The formula for the standard error of the sample proportion given here can actually be derived using facts in probability theory, but its development goes beyond the scope of this book. To learn more about it, please consult more advanced treatments in probability and statistics such as <a href="http://onlinestatbook.com/2/sampling_distributions/samp_dist_p.html">this one</a>.</p>
</div>
<div id="the-sampling-distribution-of-the-sample-proportion" class="section level4 unnumbered hasAnchor">
<h4>The sampling distribution of the sample proportion<a href="m11a-sampling.html#the-sampling-distribution-of-the-sample-proportion" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>So far, we have looked at some of the properties of the sampling distribution for the sampling proportion; namely, the expected value and standard error of <span class="math inline">\(\overline X\)</span>. Let’s now turn our attention to the shape of the sampling distribution.</p>
<p>As mentioned before, histograms (such as those seen earlier) provide a good approximation of the sampling distribution of the sample proportion, the distribution of <span class="math inline">\(\overline X\)</span>. Since we are interested in the shape of the distribution, let’s redraw again the histograms using sample proportions from random samples of size <span class="math inline">\(n=25\)</span>, <span class="math inline">\(n=50\)</span>, and <span class="math inline">\(n=100\)</span>, but this time we’ll add a smooth curve that appears to connect the top parts of each bar in the histogram. These histograms are presented in Figures <a href="m11a-sampling.html#fig:sample-proportion-25-with-normal-pdf">33.14</a>, <a href="m11a-sampling.html#fig:sample-proportion-50-with-normal-pdf">33.15</a>, and <a href="m11a-sampling.html#fig:sample-proportion-100-with-normal-pdf">33.16</a>. The figures represent density histograms where the area of each bar represents the percentage or proportion of observations for the corresponding bin and the total area of each histogram is 1 (or 100%). The ranges for the <span class="math inline">\(x-\)</span> and <span class="math inline">\(y-\)</span>axis on all these plots have been kept constant for appropriate comparisons among them.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sample-proportion-25-with-normal-pdf"></span>
<img src="_main_files/figure-html/sample-proportion-25-with-normal-pdf-1.png" alt="Histogram of the distribution of the sample proportion and the normal curve (n=25)." width="\textwidth" />
<p class="caption">
Figure 33.14: Histogram of the distribution of the sample proportion and the normal curve (n=25).
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sample-proportion-50-with-normal-pdf"></span>
<img src="_main_files/figure-html/sample-proportion-50-with-normal-pdf-1.png" alt="Histogram of the distribution of the sample proportion and the normal curve (n=50)." width="\textwidth" />
<p class="caption">
Figure 33.15: Histogram of the distribution of the sample proportion and the normal curve (n=50).
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sample-proportion-100-with-normal-pdf"></span>
<img src="_main_files/figure-html/sample-proportion-100-with-normal-pdf-1.png" alt="Histogram of the sampling distribution of the sample proportion and the normal curve (n=100)." width="\textwidth" />
<p class="caption">
Figure 33.16: Histogram of the sampling distribution of the sample proportion and the normal curve (n=100).
</p>
</div>
<p>The curves in red seem to be a fairly good representation of the top bars of the histograms. However, we have not used the simulated data to draw these curves; these bell-shaped curves were extracted from the normal distribution with mean equal to <span class="math inline">\(p=0.375\)</span> and standard deviation equal to <span class="math inline">\(\sqrt{{p(1-p)/n}}\)</span> where <span class="math inline">\(n\)</span> changes for each histogram. This is a fascinating result due to an application of one of the most important results in statistics: the Central Limit Theorem (CLT).</p>
<p>The CLT states that as the sample size, <span class="math inline">\(n\)</span>, approaches infinity, the distribution of <span class="math inline">\(\overline X\)</span> approaches the normal distribution (with the appropriate mean and standard deviation). Moreover, it does not depend on the population distribution; the population can be a bowl with red and white balls or anything else.</p>
<p>The observant reader might have noticed that, in practice, we cannot take samples of size equal to infinity. What makes the CLT even more relevant for practical purposes is that the distribution of <span class="math inline">\(\overline X\)</span> approximates normality even when the sample size used is fairly small. As you can see in Figure <a href="m11a-sampling.html#fig:sample-proportion-25-with-normal-pdf">33.14</a>, even when random samples of size <span class="math inline">\(n=25\)</span> are used, the distribution of <span class="math inline">\(\overline X\)</span> already seems to follow a normal distribution.</p>
<p>Observe also that all the curves follow the bell-shaped form of the normal curve but the spread is greater when a smaller sample size has been used and is consistent with the standard error for <span class="math inline">\(\overline X\)</span> found earlier for each case.</p>
</div>
</div>
<div id="summary-4" class="section level3 hasAnchor" number="33.3.5">
<h3><span class="header-section-number">33.3.5</span> Summary<a href="m11a-sampling.html#summary-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s look at what we have learned about the sampling distribution of the sample proportion:</p>
<ol style="list-style-type: decimal">
<li>The mean of all the sample proportions will be exactly the same as the population proportion.</li>
<li>The standard deviation of the sample proportions, also called the standard error, is inversely proportional to the square root of the sample size: the larger the sample size used to calculate sample proportions, the closer those sample proportions will be from the population proportion, on average.</li>
<li>As long as the random samples used are large enough, the sampling distribution of the sample proportion (or simply the distribution of <span class="math inline">\(\overline X\)</span>) will approximate the normal distribution. This is true for sample proportions regardless of the structure of the underlying population distribution; that is, regardless of how many red and white balls are in the bowl, or whether you are performing any other experiment that deals with sample proportions.</li>
</ol>
<p>In case you want to reinforce these ideas a little more, Shuyi Chiou, Casey Dunn, and Pathikrit Bhattacharyya created a 3-minute and 38-second video at <a href="https://youtu.be/jvoxEYmQHNM" class="uri">https://youtu.be/jvoxEYmQHNM</a> explaining this crucial statistical theorem using the average weight of wild bunny rabbits and the average wingspan of dragons as examples. Figure <a href="m11a-sampling.html#fig:CLT-video-preview">33.17</a> shows a preview of this video.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:CLT-video-preview"></span>
<img src="images/copyright/CLT_video_preview.png" alt="Preview of Central Limit Theorem video." width="75%" />
<p class="caption">
Figure 33.17: Preview of Central Limit Theorem video.
</p>
</div>
</div>
</div>
<div id="sampling-activity-mean" class="section level2 hasAnchor" number="33.4">
<h2><span class="header-section-number">33.4</span> Second activity: chocolate-covered almonds<a href="m11a-sampling.html#sampling-activity-mean" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s extend the results achieved for the sample proportion to a more general case: the <strong>sample mean</strong>. In this section we show how most of the results for sample proportions extend directly to sample means, but we also highlight important differences when working with the <strong>sampling distribution of the sample mean</strong>.</p>
<p>As we did with sample proportions, we start by illustrating these results with another activity: sampling from a bowl of chocolate-covered almonds, as seen in Figure <a href="m11a-sampling.html#fig:bowl-almond">33.18</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bowl-almond"></span>
<img src="images/sampling/almonds/v2_side_almonds.jpg" alt="A bowl of chocolate-covered almonds." width="40%" />
<p class="caption">
Figure 33.18: A bowl of chocolate-covered almonds.
</p>
</div>
<p>For ease of exposition we refer to each chocolate-covered almond simply as an almond. We are now interested in the average weight in grams of <em>all</em> the almonds in the bowl; this is the <em>population average</em> weight or <em>population mean</em> weight.</p>
<div id="population-mean" class="section level3 hasAnchor" number="33.4.1">
<h3><span class="header-section-number">33.4.1</span> The population mean weight of almonds in the bowl<a href="m11a-sampling.html#population-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The population of interest is all the almonds in the bowl. The bowl is represented virtually by the data frame <code>almonds_bowl</code> included in the <code>moderndive</code> package. The first ten rows are shown here for illustration purposes:</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="m11a-sampling.html#cb278-1" tabindex="-1"></a>almonds_bowl</span></code></pre></div>
<pre><code># A tibble: 5,000 × 2
      ID weight
   &lt;int&gt;  &lt;dbl&gt;
 1     1    3.8
 2     2    4.2
 3     3    3.2
 4     4    3.1
 5     5    4.1
 6     6    3.9
 7     7    3.4
 8     8    4.2
 9     9    3.5
10    10    3.4
# ℹ 4,990 more rows</code></pre>
<p>The first variable <code>ID</code> represents a virtual ID number given to each almond, and the variable <code>weight</code> contains the weight in grams for each almond in the bowl. The <strong>population mean</strong> weight of almonds, a population parameter, can be calculated in R using again the <code>dplyr</code> data-wrangling verbs presented in Chapter <a href="m6a-wrangling-and-tidying-data.html#wrangling">18.2</a>. Observe, in particular, inside the function <code>summarize()</code> the use of the <code>mean()</code>, <code>sd()</code>, and <code>n()</code> functions for the mean weight, the weight’s standard deviation<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>, and the number of almonds in the bowl:</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="m11a-sampling.html#cb280-1" tabindex="-1"></a>almonds_bowl <span class="sc">|&gt;</span> </span>
<span id="cb280-2"><a href="m11a-sampling.html#cb280-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight), </span>
<span id="cb280-3"><a href="m11a-sampling.html#cb280-3" tabindex="-1"></a>            <span class="at">sd_weight =</span> <span class="fu">sd</span>(weight), </span>
<span id="cb280-4"><a href="m11a-sampling.html#cb280-4" tabindex="-1"></a>            <span class="at">length =</span> <span class="fu">n</span>())</span></code></pre></div>
<pre><code># A tibble: 1 × 3
  mean_weight sd_weight length
        &lt;dbl&gt;     &lt;dbl&gt;  &lt;int&gt;
1        3.64     0.392   5000</code></pre>
<p>We have 5,000 almonds in the bowl, the population mean weight is 3.64 grams, and the weight’s standard deviation is 0.392 grams. We used R to compute the mean and standard deviation, but we could have used the formulas instead. If we call <span class="math inline">\(x_1\)</span> the first almond in the bowl, <span class="math inline">\(x_2\)</span> the second, and so on, the mean is given by</p>
<p><span class="math display">\[\mu = \sum_{i=1}^{5000}\frac{x_i}{5000}=3.64.\]</span></p>
<p>and the standard deviation is given by</p>
<p><span class="math display">\[\sigma = \sum_{i=1}^{5000} \frac{(x_i - \mu)^2}{5000}=0.392.\]</span></p>
<p>The Greek letters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are used to represent the population mean and population standard deviation (the parameters of interest). In addition, since we know the information of the entire bowl, we can draw the distribution of weights of the entire population (bowl) using a histogram:</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="m11a-sampling.html#cb282-1" tabindex="-1"></a><span class="fu">ggplot</span>(almonds_bowl, <span class="fu">aes</span>(<span class="at">x =</span> weight)) <span class="sc">+</span></span>
<span id="cb282-2"><a href="m11a-sampling.html#cb282-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.1</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:almonds-bowl-histogram"></span>
<img src="_main_files/figure-html/almonds-bowl-histogram-1.png" alt="Distribution of weights for the entire bowl of almonds." width="\textwidth" />
<p class="caption">
Figure 33.19: Distribution of weights for the entire bowl of almonds.
</p>
</div>
<p>We can see that the weight of almonds ranges from 2.6 to 4.6 grams and the most common weights observed are between 3.6 and 4.0 grams, but the distribution is not symmetric and does not follow any typical pattern.</p>
<p>Now that we have a clear understanding of our population of interest and the parameters of interest, we can continue our exploration of the <strong>sampling distribution of the sample mean</strong> weights of almonds by constructing samples.</p>
</div>
<div id="resampling-tactile-bowl" class="section level3 hasAnchor" number="33.4.2">
<h3><span class="header-section-number">33.4.2</span> Manual sampling and sample means<a href="m11a-sampling.html#resampling-tactile-bowl" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we randomly select one almond from the bowl, we could determine its weight using a scale, as shown in Figure <a href="m11a-sampling.html#fig:one-almond">33.20</a>:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:one-almond"></span>
<img src="images/sampling/almonds/one-almond.png" alt="One almond on a scale." width="40%" />
<p class="caption">
Figure 33.20: One almond on a scale.
</p>
</div>
<p>Let’s now take a random sample of 25 almonds, as shown in Figure <a href="m11a-sampling.html#fig:twenty-five-almonds">33.21</a>, and determine the sample average weight, or <em>sample mean</em> weight, in grams.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:twenty-five-almonds"></span>
<img src="images/sampling/almonds/twenty-five-almonds.png" alt="A random sample of 25 almonds on a scale." width="40%" />
<p class="caption">
Figure 33.21: A random sample of 25 almonds on a scale.
</p>
</div>
<p>Since the total weight is 88.6 grams, as shown in Figure <a href="m11a-sampling.html#fig:twenty-five-almonds">33.21</a>, the sample mean weight will be <span class="math inline">\(88.6/25 = 3.544\)</span>. The <code>moderndive</code> package contains the information of this sample in the <code>almonds_sample</code> data frame. Here, we present the weight of the first 10 almonds in the sample:</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="m11a-sampling.html#cb283-1" tabindex="-1"></a>almonds_sample</span></code></pre></div>
<pre><code># A tibble: 25 × 3
# Groups:   replicate [1]
   replicate    ID weight
       &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;
 1         1  4645    3  
 2         1  3629    3.9
 3         1  4796    4  
 4         1  2669    3.8
 5         1  3488    4.3
 6         1   105    4.1
 7         1  1762    3.6
 8         1  1035    4.2
 9         1  4880    3.2
10         1   398    4  
# ℹ 15 more rows</code></pre>
<p>The <code>almonds_sample</code> data frame in the <code>moderndive</code> package has <span class="math inline">\(n=\)</span> 25 rows corresponding to each almond in the sample shown in Figure <a href="m11a-sampling.html#fig:twenty-five-almonds">33.21</a>. The first variable <code>replicate</code> indicates this is the first and only replicate since it is a single sample. The second variable <code>ID</code> gives an identification to the particular almond. The third column <code>weight</code> gives the corresponding weight for each almond in grams as a numeric variable, also known as a double (<code>dbl</code>). The distribution of the weights of these 25 are shown in the histogram in Figure <a href="m11a-sampling.html#fig:almonds-sample-histogram">33.22</a>.</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="m11a-sampling.html#cb285-1" tabindex="-1"></a><span class="fu">ggplot</span>(almonds_sample, <span class="fu">aes</span>(<span class="at">x =</span> weight)) <span class="sc">+</span></span>
<span id="cb285-2"><a href="m11a-sampling.html#cb285-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.1</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:almonds-sample-histogram"></span>
<img src="_main_files/figure-html/almonds-sample-histogram-1.png" alt="Distribution of weight for a sample of 25 almonds." width="\textwidth" />
<p class="caption">
Figure 33.22: Distribution of weight for a sample of 25 almonds.
</p>
</div>
<p>The weights of almonds in this sample range from 2.9 to 4.4 grams. There is not an obvious pattern in the distribution of this sample. Let’s now compute the sample mean using our data-wrangling tools.</p>
<div class="sourceCode" id="cb286"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb286-1"><a href="m11a-sampling.html#cb286-1" tabindex="-1"></a>almonds_sample <span class="sc">|&gt;</span> <span class="fu">summarize</span>(<span class="at">sample_mean_weight =</span> <span class="fu">mean</span>(weight))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  replicate sample_mean_weight
      &lt;int&gt;              &lt;dbl&gt;
1         1               3.67</code></pre>
<p>The sample mean weight was not too far from the population mean weight of 3.64 grams. The difference between the statistic (sample mean weight) and the parameter (population mean weight) was due to sampling variation.</p>
</div>
<div id="virtual-samples-mean-bowl" class="section level3 hasAnchor" number="33.4.3">
<h3><span class="header-section-number">33.4.3</span> Virtual sampling<a href="m11a-sampling.html#virtual-samples-mean-bowl" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can now perform sampling virtually. The data frame <code>almonds_bowl</code> has 5000 rows, each representing an almond in the bowl. As we did in Section <a href="m11a-sampling.html#sampling-simulation">33.1.3</a> we can use the <code>rep_slice_sample()</code> function to retrieve 1000 random samples with a sample <code>size</code> set to be 25, and with the number of replicates <code>reps</code> set to <code>1000</code>. Be sure to scroll through the contents of <code>virtual_samples</code> in RStudio’s viewer.</p>
<div class="sourceCode" id="cb288"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb288-1"><a href="m11a-sampling.html#cb288-1" tabindex="-1"></a>virtual_samples_almonds <span class="ot">&lt;-</span> almonds_bowl <span class="sc">|&gt;</span> </span>
<span id="cb288-2"><a href="m11a-sampling.html#cb288-2" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">25</span>, <span class="at">reps =</span> <span class="dv">1000</span>)</span>
<span id="cb288-3"><a href="m11a-sampling.html#cb288-3" tabindex="-1"></a>virtual_samples_almonds</span></code></pre></div>
<pre><code># A tibble: 25,000 × 3
# Groups:   replicate [1,000]
   replicate    ID weight
       &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;
 1         1  3467    3.7
 2         1  3784    4.2
 3         1  4653    4.2
 4         1  2216    4.1
 5         1    98    3.5
 6         1  2286    3.6
 7         1  4597    3.6
 8         1  2385    4.3
 9         1  3959    3.7
10         1  1497    3.9
# ℹ 24,990 more rows</code></pre>
<p>Observe that now <code>virtual_samples_almonds</code> has 1000 <span class="math inline">\(\cdot\)</span> 25 = 25,000 rows. Using the appropriate data wrangling code, the <code>virtual_mean_weight</code> data frame produces the sample mean almond weight for each random sample, a total of 1000 sample means.</p>
<div class="sourceCode" id="cb290"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb290-1"><a href="m11a-sampling.html#cb290-1" tabindex="-1"></a>virtual_mean_weight <span class="ot">&lt;-</span> virtual_samples_almonds <span class="sc">|&gt;</span> </span>
<span id="cb290-2"><a href="m11a-sampling.html#cb290-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight))</span>
<span id="cb290-3"><a href="m11a-sampling.html#cb290-3" tabindex="-1"></a>virtual_mean_weight</span></code></pre></div>
<pre><code># A tibble: 1,000 × 2
   replicate mean_weight
       &lt;int&gt;       &lt;dbl&gt;
 1         1        3.79
 2         2        3.45
 3         3        3.67
 4         4        3.5 
 5         5        3.67
 6         6        3.63
 7         7        3.62
 8         8        3.59
 9         9        3.56
10        10        3.78
# ℹ 990 more rows</code></pre>
<p>Figure <a href="m11a-sampling.html#fig:sampling-mean-virtual-1000">33.23</a> presents the histogram for these sample means:</p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="m11a-sampling.html#cb292-1" tabindex="-1"></a><span class="fu">ggplot</span>(virtual_mean_weight, <span class="fu">aes</span>(<span class="at">x =</span> mean_weight)) <span class="sc">+</span></span>
<span id="cb292-2"><a href="m11a-sampling.html#cb292-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.04</span>, <span class="at">boundary =</span> <span class="fl">3.5</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb292-3"><a href="m11a-sampling.html#cb292-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sample mean&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Histogram of 1000 sample means&quot;</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sampling-mean-virtual-1000"></span>
<img src="_main_files/figure-html/sampling-mean-virtual-1000-1.png" alt="The distribution of 1000 means based on 1000 random samples of size 25." width="\textwidth" />
<p class="caption">
Figure 33.23: The distribution of 1000 means based on 1000 random samples of size 25.
</p>
</div>
<p>The sample mean weights observed in the histogram appear to go below 3.4 grams and above 3.85 grams, but those extreme sample means are rare. The most frequent sample means found seem to be those above 3.5 or below 3.8 grams. Furthermore, the histogram is almost symmetric and showing that bell-shaped form, although the left tail of the histogram appears to be slightly longer than the right tail. While we are dealing with sample means now, the conclusions are strikingly similar to those presented in Subsection <a href="m11a-sampling.html#resampling-tactile-bowl">33.4.2</a> when discussing the sampling distribution for the sample proportion.</p>
</div>
<div id="the-sampling-distribution-of-the-sample-mean" class="section level3 hasAnchor" number="33.4.4">
<h3><span class="header-section-number">33.4.4</span> The sampling distribution of the sample mean<a href="m11a-sampling.html#the-sampling-distribution-of-the-sample-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As we did in the case of the sample proportion, we are interested in learning key characteristics of the <strong>sampling distribution of the sample mean</strong>, namely:</p>
<ol style="list-style-type: decimal">
<li>The center of the <em>sampling distribution</em></li>
<li>The effect of <em>sampling variation</em> on the <em>sampling distribution</em> and the effect of the sample size on <em>sampling variation</em></li>
<li>The shape of the <em>sampling distribution</em></li>
</ol>
</div>
<div id="random-variable-sample-mean" class="section level3 hasAnchor" number="33.4.5">
<h3><span class="header-section-number">33.4.5</span> Random variables<a href="m11a-sampling.html#random-variable-sample-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Once again, we can use random variables to formalize our understanding of the sample distribution of the sample mean. Instead of using Bernoulli trials, as we did in the case of sample proportions, our trials will record the almond weights. Let’s again modify the bowl activity slightly. In lieu of selecting a sample of almonds all at once, we randomly select one almond at a time, we record the weight of the almond and return it to the bowl before selecting another almond, so the configuration of weights and the chances of any of the almonds to be selected is the same every time we choose one. Getting a sample of 25 almonds is performing these trials 25 times to get 25 weights. Then, the average of these 25 numbers is the average weight or mean weight of a sample of 25 almonds. This is what we call a sample mean.</p>
<p>Using random variables, we’ll now let uppercase <span class="math inline">\(X_1\)</span> to be the random variable that represents the weight of the first almond before it has been selected, <span class="math inline">\(X_2\)</span> the weight of the second almond, and so on. These are random variables because they can take any possible almond weight value from the bowl. After the first trial is completed, the value of <span class="math inline">\(X_1\)</span> is realized as the weight in grams of the first almond selected. We can represent this value by the lowercase <span class="math inline">\(x_1\)</span> as it is no longer a random variable but a number and we can write <span class="math inline">\(X_1 = x_1\)</span>. After the second trial is completed, <span class="math inline">\(X_2 = x_2\)</span>, where lowercase <span class="math inline">\(x_2\)</span> is the observed almond weight, and so on. Since our experiment is to perform 25 trials and then find the average of them, this average or mean, before the trials are carried out, can also be expressed as a random variable:</p>
<p><span class="math display">\[\overline X = \frac{X_1+X_2+\dots+X_{25}}{25}.\]</span></p>
<p>Observe that <span class="math inline">\(\overline X\)</span> is the average, or mean, of these 25 trials. This is again why <span class="math inline">\(\overline X\)</span> is called the <strong>sample mean</strong>. Recall that when dealing with proportions, the trials are Bernoulli trials, represented only with zeros or ones. In this context, <strong>sample proportions</strong> are a special case of <strong>sample means</strong>. The trials we use now are not restricted to zeros and ones, and the sample means are no longer sample proportions.</p>
<p>For example, let’s focus on the sample of 25 almond weights used earlier and their sample mean:</p>
<div class="sourceCode" id="cb293"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb293-1"><a href="m11a-sampling.html#cb293-1" tabindex="-1"></a>almonds_sample</span></code></pre></div>
<pre><code># A tibble: 25 × 3
# Groups:   replicate [1]
   replicate    ID weight
       &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;
 1         1  4645    3  
 2         1  3629    3.9
 3         1  4796    4  
 4         1  2669    3.8
 5         1  3488    4.3
 6         1   105    4.1
 7         1  1762    3.6
 8         1  1035    4.2
 9         1  4880    3.2
10         1   398    4  
# ℹ 15 more rows</code></pre>
<p>Looking at the weights in the data frame <code>almonds_sample</code>, observe that <span class="math inline">\(X_1 = 3.0\)</span> grams, <span class="math inline">\(X_2 = 3.9\)</span> grams, <span class="math inline">\(X_3 = 4.0\)</span> grams, and so on. If you view the entire data frame, for example running <code>View(almonds_sample)</code> in R, you could check that <span class="math inline">\(X_{23} = 3.3\)</span>, <span class="math inline">\(X_{24} = 4.4\)</span>, and <span class="math inline">\(X_{25} = 3.6\)</span>, so the sample mean would be</p>
<p><span class="math display">\[\overline X = \frac{3.0+3.9+4.0+\dots+3.3+4.4+3.6}{25} = \frac{91.8}{25}=3.67.\]</span></p>
<p>In R:</p>
<div class="sourceCode" id="cb295"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb295-1"><a href="m11a-sampling.html#cb295-1" tabindex="-1"></a>almonds_sample <span class="sc">|&gt;</span></span>
<span id="cb295-2"><a href="m11a-sampling.html#cb295-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">sample_mean_weight =</span> <span class="fu">mean</span>(weight))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
  replicate sample_mean_weight
      &lt;int&gt;              &lt;dbl&gt;
1         1               3.67</code></pre>
<p>So, once this sample was observed, the random variable <span class="math inline">\(\overline X\)</span> was realized as <span class="math inline">\(\overline X = 3.67\)</span>: the <strong>sample mean</strong> was 3.67 grams. Note that the possible values that <span class="math inline">\(\overline X\)</span> can take are all the possible sample means from samples of 25 almonds from the bowl. The chances of getting these sample means are determined by the configuration of almond weights in the bowl.</p>
<p>When <span class="math inline">\(\overline X\)</span> is constructed as the sample mean of a given random sample, the sampling distribution of the sample mean is precisely the distribution of <span class="math inline">\(\overline X\)</span>. In this context, recall what we are interested in determining:</p>
<ol style="list-style-type: decimal">
<li>the center of the <em>distribution</em> of <span class="math inline">\(\overline X\)</span>,</li>
<li>the effect of <em>sampling variation</em> on the <em>distribution</em> of <span class="math inline">\(\overline X\)</span> and the effect of the sample size on <em>sampling variation</em>, and</li>
<li>the shape of the <em>distribution</em> of <span class="math inline">\(\overline X\)</span>.</li>
</ol>
<p>As we did when dealing with sample proportions, we can use simulations to produce good approximations of the distribution of <span class="math inline">\(\overline X\)</span>, the sample mean weight of almonds. We’ll also work with samples of size 25, 50, and 100 to learn about changes in sample variation when the sample size changes.</p>
<p>This is the process we follow:</p>
<ul>
<li>we generate 1000 samples,</li>
<li>calculate the sample means of almond weights, and</li>
<li>use them to draw histograms.</li>
</ul>
<p>We do this three times with the <code>size</code> argument set to <code>25</code>, <code>50</code>, and <code>100</code>, respectively. We run each of the following code segments individually and then compare the resulting histograms.</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="m11a-sampling.html#cb297-1" tabindex="-1"></a><span class="co"># Segment 1: sample size = 25 ------------------------------</span></span>
<span id="cb297-2"><a href="m11a-sampling.html#cb297-2" tabindex="-1"></a><span class="co"># 1.a) Calculating the 1000 sample means, each from random samples of size 25</span></span>
<span id="cb297-3"><a href="m11a-sampling.html#cb297-3" tabindex="-1"></a>virtual_mean_weight_25 <span class="ot">&lt;-</span> almonds_bowl <span class="sc">|&gt;</span> </span>
<span id="cb297-4"><a href="m11a-sampling.html#cb297-4" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">25</span>, <span class="at">reps =</span> <span class="dv">1000</span>)<span class="sc">|&gt;</span></span>
<span id="cb297-5"><a href="m11a-sampling.html#cb297-5" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight), <span class="at">n =</span> <span class="fu">n</span>())</span>
<span id="cb297-6"><a href="m11a-sampling.html#cb297-6" tabindex="-1"></a></span>
<span id="cb297-7"><a href="m11a-sampling.html#cb297-7" tabindex="-1"></a><span class="co"># 1.b) Plot distribution via a histogram</span></span>
<span id="cb297-8"><a href="m11a-sampling.html#cb297-8" tabindex="-1"></a><span class="fu">ggplot</span>(virtual_mean_weight_25, <span class="fu">aes</span>(<span class="at">x =</span> mean_weight)) <span class="sc">+</span></span>
<span id="cb297-9"><a href="m11a-sampling.html#cb297-9" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.02</span>, <span class="at">boundary =</span> <span class="fl">3.6</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb297-10"><a href="m11a-sampling.html#cb297-10" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sample mean weights for random samples of 25 almonds&quot;</span>, <span class="at">title =</span> <span class="st">&quot;25&quot;</span>) </span>
<span id="cb297-11"><a href="m11a-sampling.html#cb297-11" tabindex="-1"></a></span>
<span id="cb297-12"><a href="m11a-sampling.html#cb297-12" tabindex="-1"></a><span class="co"># Segment 2: sample size = 50 ------------------------------</span></span>
<span id="cb297-13"><a href="m11a-sampling.html#cb297-13" tabindex="-1"></a><span class="co"># 2.a) Calculating the 1000 sample means, each from random samples of size 50</span></span>
<span id="cb297-14"><a href="m11a-sampling.html#cb297-14" tabindex="-1"></a>virtual_mean_weight_50 <span class="ot">&lt;-</span> almonds_bowl <span class="sc">|&gt;</span> </span>
<span id="cb297-15"><a href="m11a-sampling.html#cb297-15" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">50</span>, <span class="at">reps =</span> <span class="dv">1000</span>)<span class="sc">|&gt;</span></span>
<span id="cb297-16"><a href="m11a-sampling.html#cb297-16" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight), <span class="at">n =</span> <span class="fu">n</span>())</span>
<span id="cb297-17"><a href="m11a-sampling.html#cb297-17" tabindex="-1"></a></span>
<span id="cb297-18"><a href="m11a-sampling.html#cb297-18" tabindex="-1"></a><span class="co"># 2.b) Plot distribution via a histogram</span></span>
<span id="cb297-19"><a href="m11a-sampling.html#cb297-19" tabindex="-1"></a><span class="fu">ggplot</span>(virtual_mean_weight_50, <span class="fu">aes</span>(<span class="at">x =</span> mean_weight)) <span class="sc">+</span></span>
<span id="cb297-20"><a href="m11a-sampling.html#cb297-20" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.02</span>, <span class="at">boundary =</span> <span class="fl">3.6</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb297-21"><a href="m11a-sampling.html#cb297-21" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sample mean weights for random samples of 50 almonds&quot;</span>, <span class="at">title =</span> <span class="st">&quot;50&quot;</span>) </span>
<span id="cb297-22"><a href="m11a-sampling.html#cb297-22" tabindex="-1"></a></span>
<span id="cb297-23"><a href="m11a-sampling.html#cb297-23" tabindex="-1"></a><span class="co"># Segment 3: sample size = 100 ------------------------------</span></span>
<span id="cb297-24"><a href="m11a-sampling.html#cb297-24" tabindex="-1"></a><span class="co"># 3.a) Calculating the 1000 sample means, each from random samples of size 100</span></span>
<span id="cb297-25"><a href="m11a-sampling.html#cb297-25" tabindex="-1"></a>virtual_mean_weight_100 <span class="ot">&lt;-</span> almonds_bowl <span class="sc">|&gt;</span> </span>
<span id="cb297-26"><a href="m11a-sampling.html#cb297-26" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">100</span>, <span class="at">reps =</span> <span class="dv">1000</span>)<span class="sc">|&gt;</span></span>
<span id="cb297-27"><a href="m11a-sampling.html#cb297-27" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mean_weight =</span> <span class="fu">mean</span>(weight), <span class="at">n =</span> <span class="fu">n</span>())</span>
<span id="cb297-28"><a href="m11a-sampling.html#cb297-28" tabindex="-1"></a></span>
<span id="cb297-29"><a href="m11a-sampling.html#cb297-29" tabindex="-1"></a><span class="co"># 3.b) Plot distribution via a histogram</span></span>
<span id="cb297-30"><a href="m11a-sampling.html#cb297-30" tabindex="-1"></a><span class="fu">ggplot</span>(virtual_mean_weight_100, <span class="fu">aes</span>(<span class="at">x =</span> mean_weight)) <span class="sc">+</span></span>
<span id="cb297-31"><a href="m11a-sampling.html#cb297-31" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.02</span>, <span class="at">boundary =</span> <span class="fl">3.6</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb297-32"><a href="m11a-sampling.html#cb297-32" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Sample mean weights for random samples of 100 almonds&quot;</span>, <span class="at">title =</span> <span class="st">&quot;100&quot;</span>) </span></code></pre></div>
<p>We present the three resulting histograms in a single row with matching x and y axes in Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions-means">33.24</a> so the comparison among them is clear.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:comparing-sampling-distributions-means"></span>
<img src="_main_files/figure-html/comparing-sampling-distributions-means-1.png" alt="Comparing histograms of sample means when using different sample sizes." width="\textwidth" />
<p class="caption">
Figure 33.24: Comparing histograms of sample means when using different sample sizes.
</p>
</div>
<p>Observe that all three histograms are bell-shaped and appear to center around the same middle value highlighted by the line at the middle. In addition, the magnitude of the sampling variation decreases when the sample size increases. As it happened with the sampling distribution of the sample proportion, the measures of center and dispersion of these distributions are directly related to the parameters of the population: the population mean, <span class="math inline">\(\mu\)</span>, and the population standard deviation, <span class="math inline">\(\sigma\)</span>. Let’s print these parameters one more time here:</p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="m11a-sampling.html#cb298-1" tabindex="-1"></a>almonds_bowl <span class="sc">|&gt;</span></span>
<span id="cb298-2"><a href="m11a-sampling.html#cb298-2" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mu =</span> <span class="fu">mean</span>(weight), <span class="at">sigma =</span> <span class="fu">sd</span>(weight))</span></code></pre></div>
<pre><code># A tibble: 1 × 2
     mu sigma
  &lt;dbl&gt; &lt;dbl&gt;
1  3.64 0.392</code></pre>
<p>Let’s do the same for our simulations next. Recall that the expected value of <span class="math inline">\(\overline X\)</span> is the value we would expect to observe, on average, when we take many sample means from random samples of a given size. It is located at the center of the distribution of <span class="math inline">\(\overline X\)</span>. Similarly, the standard error of <span class="math inline">\(\overline X\)</span> is the measure of dispersion or magnitude of sampling variation. It is the standard deviation of the sample means calculated from all possible random samples of a given size. Using the data wrangling code <code>mean()</code> and <code>sd()</code> functions inside <code>summarize()</code> and applied to our simulation values, we can estimate the expected value and standard error of <span class="math inline">\(\overline X\)</span>. Three sets of values are found, one for each of the corresponding sample sizes and presented in Table <a href="m11a-sampling.html#tab:comparing-n1">33.1</a>.</p>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="m11a-sampling.html#cb300-1" tabindex="-1"></a><span class="co"># n = 25</span></span>
<span id="cb300-2"><a href="m11a-sampling.html#cb300-2" tabindex="-1"></a>virtual_mean_weight_25 <span class="sc">|&gt;</span> </span>
<span id="cb300-3"><a href="m11a-sampling.html#cb300-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">E_Xbar_25 =</span> <span class="fu">mean</span>(mean_weight), <span class="at">sd =</span> <span class="fu">sd</span>(mean_weight))</span>
<span id="cb300-4"><a href="m11a-sampling.html#cb300-4" tabindex="-1"></a></span>
<span id="cb300-5"><a href="m11a-sampling.html#cb300-5" tabindex="-1"></a><span class="co"># n = 50</span></span>
<span id="cb300-6"><a href="m11a-sampling.html#cb300-6" tabindex="-1"></a>virtual_mean_weight_50 <span class="sc">|&gt;</span> </span>
<span id="cb300-7"><a href="m11a-sampling.html#cb300-7" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">E_Xbar_50 =</span> <span class="fu">mean</span>(mean_weight), <span class="at">sd =</span> <span class="fu">sd</span>(mean_weight))</span>
<span id="cb300-8"><a href="m11a-sampling.html#cb300-8" tabindex="-1"></a></span>
<span id="cb300-9"><a href="m11a-sampling.html#cb300-9" tabindex="-1"></a><span class="co"># n = 100</span></span>
<span id="cb300-10"><a href="m11a-sampling.html#cb300-10" tabindex="-1"></a>virtual_mean_weight_100 <span class="sc">|&gt;</span> </span>
<span id="cb300-11"><a href="m11a-sampling.html#cb300-11" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">E_Xbar_100 =</span> <span class="fu">mean</span>(mean_weight), <span class="at">sd =</span> <span class="fu">sd</span>(mean_weight))</span></code></pre></div>
<table class="table" style="font-size: 16px; color: black; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:comparing-n1">Table 33.1: </span>Comparing expected values and standard errors for three different sample sizes
</caption>
<thead>
<tr>
<th style="text-align:right;">
Sample size
</th>
<th style="text-align:right;">
Expected Value
</th>
<th style="text-align:right;">
Standard Error
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
25
</td>
<td style="text-align:right;">
3.65
</td>
<td style="text-align:right;">
0.077
</td>
</tr>
<tr>
<td style="text-align:right;">
50
</td>
<td style="text-align:right;">
3.65
</td>
<td style="text-align:right;">
0.053
</td>
</tr>
<tr>
<td style="text-align:right;">
100
</td>
<td style="text-align:right;">
3.64
</td>
<td style="text-align:right;">
0.039
</td>
</tr>
</tbody>
</table>
<p>In summary:</p>
<ol style="list-style-type: decimal">
<li>The estimated expected value was either 3.65 or 3.64. This is either near or equal to <span class="math inline">\(\mu = 3.64\)</span>, the population mean weight of almonds in the entire bowl.</li>
<li>The standard error decreases when the sample size increases. If we focus on the result for <span class="math inline">\(n=100\)</span>, the standard error was 0.039. When compared with the population standard deviation <span class="math inline">\(\sigma = 0.392\)</span> this standard error is about one-tenth the value of <span class="math inline">\(\sigma\)</span>. Similarly, when <span class="math inline">\(n=25\)</span> the standard error 0.077 is about one-fifth the value of <span class="math inline">\(\sigma\)</span> and that pattern also holds when <span class="math inline">\(n=50\)</span>. As was the case for the sample proportion, the standard error is inversely proportional to the squared sample size used to construct the distribution of <span class="math inline">\(\overline X\)</span>. This is also a theoretical result that can be expressed as:</li>
</ol>
<p><span class="math display">\[SE_{\overline X} = \frac{\sigma}{\sqrt {n}}\]</span>
where <span class="math inline">\(n\)</span> is the sample size and <span class="math inline">\(\sigma\)</span> is the population standard deviation.</p>
</div>
<div id="CLT-mean" class="section level3 hasAnchor" number="33.4.6">
<h3><span class="header-section-number">33.4.6</span> The Central Limit Theorem revisited<a href="m11a-sampling.html#CLT-mean" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Finally, observe that the shapes of the histograms in Figure <a href="m11a-sampling.html#fig:comparing-sampling-distributions-means">33.24</a> are bell-shaped and seem to approximate the normal distribution. As we did with proportions, in Figures <a href="m11a-sampling.html#fig:sample-mean-25-with-normal">33.25</a> and <a href="m11a-sampling.html#fig:sample-mean-100-with-normal">33.26</a> we compare our histograms with the theoretical curve for the normal distribution.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sample-mean-25-with-normal"></span>
<img src="_main_files/figure-html/sample-mean-25-with-normal-1.png" alt="The distribution of the sample mean (n=25)." width="\textwidth" />
<p class="caption">
Figure 33.25: The distribution of the sample mean (n=25).
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:sample-mean-100-with-normal"></span>
<img src="_main_files/figure-html/sample-mean-100-with-normal-1.png" alt="The distribution of the sample mean (n=100)." width="\textwidth" />
<p class="caption">
Figure 33.26: The distribution of the sample mean (n=100).
</p>
</div>
<p>We can conclude that the distribution of <span class="math inline">\(\overline X\)</span>, that is, the sampling distribution of the sample mean, when the sample size is large enough, follows approximately a normal distribution with mean equal to the population mean, <span class="math inline">\(\mu\)</span>, and standard deviation equal to the population standard deviation divided by the square root of the sample size, <span class="math inline">\(\sigma/\sqrt{n}\)</span>. We can write this as</p>
<p><span class="math display">\[\overline X \sim Normal \left(\mu, \frac{\sigma}{\sqrt n}\right)\]</span></p>
</div>
</div>
<div id="sampling-other-scenarios" class="section level2 hasAnchor" number="33.5">
<h2><span class="header-section-number">33.5</span> The sampling distribution in other scenarios<a href="m11a-sampling.html#sampling-other-scenarios" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Sections <a href="m11a-sampling.html#sampling-activity">33.1</a>, <a href="m11a-sampling.html#central-limit-theorem">33.3</a>, and <a href="m11a-sampling.html#sampling-activity-mean">33.4</a>, we have considered information about the expected value, the standard error, and the shape of the sampling distribution when the statistic of interest are sample proportions or sample means. It is possible to study the sampling distribution of other statistics. In this section we explore some of them.</p>
<div id="sampling-distribution-for-two-samples" class="section level3 hasAnchor" number="33.5.1">
<h3><span class="header-section-number">33.5.1</span> Sampling distribution for two samples<a href="m11a-sampling.html#sampling-distribution-for-two-samples" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Assume that we would like to compare the parameters of two populations, for example, the means or proportion of those populations. To do this a random sample is taken from the first population and another random sample, independent from the first, is retrieved from the second population. Then we can use a statistic from each sample, such as the sample mean or sample proportion, and use them to produce sampling distributions that depend on two independent samples. We provide two examples to illustrate how the sampling distributions are affected.</p>
<div id="difference-in-sample-means" class="section level4 unnumbered hasAnchor">
<h4>Difference in sample means<a href="m11a-sampling.html#difference-in-sample-means" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The problem at hand could be that the chocolate-covered almonds’ weight for almonds in a bowl needs to be compared with the chocolate-covered coffee beans’ weight for coffee beans in a different bowl. The statistic we now consider is the difference in the sample means for samples taken from these two bowls. As it happens, most of the properties we have presented for a single sample mean or sample proportion can be extended directly to two-sample problems.</p>
<p>Let’s now consider the mathematical details for this problem. We assume that for the chocolate-covered almonds’ weight, the population mean and standard deviation are given by <span class="math inline">\(\mu_1\)</span> and <span class="math inline">\(\sigma_1\)</span> and for the chocolate-covered coffee beans’ weight the population mean and standard deviation are given by <span class="math inline">\(\mu_2\)</span> and <span class="math inline">\(\sigma_2\)</span>.</p>
<p>Our sampling exercise has two components. First, we take a random sample of size <span class="math inline">\(n_1\)</span> from the almonds’ bowl and find the sample mean. We let <span class="math inline">\(\overline X_1\)</span> represent the possible sample mean values for each possible almond sample. Then, we let <span class="math inline">\(n_2\)</span> and <span class="math inline">\(\overline X_2\)</span> represent similar quantities for the coffee beans’ bowl. To compare these two sample means, we look at the difference, <span class="math inline">\(\overline X_1 - \overline X_2\)</span>. The distribution of <span class="math inline">\(\overline X_1 - \overline X_2\)</span> is the sampling distribution of the difference in sample means.</p>
<p>The expected value and standard error of <span class="math inline">\(\overline X_1 - \overline X_2\)</span> is given by <span class="math inline">\(\mu_1 - \mu_2\)</span> and</p>
<p><span class="math display">\[\sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma^2_2}{n_2}},\]</span></p>
<p>respectively. If the distributions of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are approximately normal due to the CLT, so is the distribution of <span class="math inline">\(\overline X_1 - \overline X_2\)</span>. We can write all these properties at once:</p>
<p><span class="math display">\[\overline X - \overline Y \sim Normal \left(\mu_1 - \mu_2, \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma^2_2}{n_2}} \right)\]</span></p>
<p>Observe how the standard deviation of the difference is the sum of squared standard deviations from each sample mean. The reason we add standard deviations instead of subtract is because whether you add or subtract statistics, you are effectively adding more uncertainty into your results and the dispersion increases because of it.</p>
</div>
<div id="difference-in-sample-proportions" class="section level4 unnumbered hasAnchor">
<h4>Difference in sample proportions<a href="m11a-sampling.html#difference-in-sample-proportions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Comparing two sample proportions can be very useful. We may be interested in comparing the proportion of patients that improve using one treatment versus the proportion of patients that improve using a different treatment, or the proportion of winter accidents on a highway using one type of tire versus another.</p>
<p>To illustrate how the sampling distribution works for the difference in sample proportions, we can modify the examples used earlier. Assume that we want to compare the proportion of red balls in the first bowl with the proportion of almonds that are heavier than 3.8 grams in the second bowl. This example shows one way to convert numeric data like almond weights into a Boolean result instead. The statistic we now consider is the difference in these sample proportions for samples retrieved from these two bowls.The samples from each bowl do not need to be of the same size; for example, we can take samples of size <span class="math inline">\(n_1 = 50\)</span> from the first bowl and samples of size <span class="math inline">\(n_2 = 60\)</span> from the second bowl.</p>
<p>We proceed by</p>
<ul>
<li>taking a random sample from the first bowl,</li>
<li>calculating the sample proportion of red balls,</li>
<li>getting a random sample from the second bowl,</li>
<li>calculating the proportion of almonds heavier than 3.8 grams, and</li>
<li>finding the difference in sample proportion of red balls minus the sample proportion of almonds greater than 3.8 grams (the resulting statistic).</li>
</ul>
<p>We can use R to produce the required virtual samples and differences. We’ll then use them to approximate the sampling distribution of the difference in sample proportions.</p>
<p>Our sampling exercise has again two components. First, we take a random sample of <span class="math inline">\(n_1 = 50\)</span> balls from the bowl of red balls and calculate the sample proportion or red balls. As we did before, we let <span class="math inline">\(\overline X_1\)</span> represent the possible values that the sample proportion can take for each possible sample. Recall that <span class="math inline">\(\overline X_1\)</span> is the sample proportion in this context, which is also the sample mean of Bernoulli trials. Second, we let <span class="math inline">\(n_2 = 60\)</span> represent the sample size used for samples from the almonds’ bowl and the random variable <span class="math inline">\(\overline X_2\)</span> represent the possible values that the sample proportion of almonds greater than 3.8 grams can take for each possible sample.</p>
<p>To compare these two sample proportions, we find the difference, <span class="math inline">\(\overline X_1 - \overline X_2\)</span>. The distribution of <span class="math inline">\(\overline X_1 - \overline X_2\)</span> is the sampling distribution of the difference in sample proportions. We use virtual sampling to approximate this distribution. We’ll use the <code>rep_slice_sample</code> and <code>summarize</code> functions to produce the random samples and the necessary sample proportions, respectively. A total of 1000 random samples and sample proportions are acquired from each bowl with the appropriate sample sizes, 50 and 60, respectively. Moreover, the <code>inner_join</code> function introduced in Section <a href="m6a-wrangling-and-tidying-data.html#joins">18.2.5</a> is used here to merge the sample proportions into a single data frame and the difference in these sample proportions is calculated for each replication.</p>
<div class="sourceCode" id="cb301"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb301-1"><a href="m11a-sampling.html#cb301-1" tabindex="-1"></a>virtual_prop_red <span class="ot">&lt;-</span> bowl <span class="sc">|&gt;</span> </span>
<span id="cb301-2"><a href="m11a-sampling.html#cb301-2" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">50</span>, <span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span> </span>
<span id="cb301-3"><a href="m11a-sampling.html#cb301-3" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_red =</span> <span class="fu">mean</span>(color <span class="sc">==</span> <span class="st">&quot;red&quot;</span>))</span>
<span id="cb301-4"><a href="m11a-sampling.html#cb301-4" tabindex="-1"></a>virtual_prop_almond <span class="ot">&lt;-</span> almonds_bowl <span class="sc">|&gt;</span></span>
<span id="cb301-5"><a href="m11a-sampling.html#cb301-5" tabindex="-1"></a>  <span class="fu">rep_slice_sample</span>(<span class="at">n =</span> <span class="dv">60</span>, <span class="at">reps =</span> <span class="dv">1000</span>) <span class="sc">|&gt;</span></span>
<span id="cb301-6"><a href="m11a-sampling.html#cb301-6" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">prop_almond =</span> <span class="fu">mean</span>(weight <span class="sc">&gt;</span> <span class="fl">3.8</span>))</span>
<span id="cb301-7"><a href="m11a-sampling.html#cb301-7" tabindex="-1"></a>prop_joined <span class="ot">&lt;-</span> virtual_prop_red <span class="sc">|&gt;</span></span>
<span id="cb301-8"><a href="m11a-sampling.html#cb301-8" tabindex="-1"></a>  <span class="fu">inner_join</span>(virtual_prop_almond, <span class="at">by =</span> <span class="st">&quot;replicate&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb301-9"><a href="m11a-sampling.html#cb301-9" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prop_diff =</span> prop_red <span class="sc">-</span> prop_almond)</span></code></pre></div>
<p>The results are stored in the data frame <code>prop_joined</code>. The variable <code>prop_diff</code> in this data frame represents the difference in sample proportions. Here are the first 10 values of this data frame:</p>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="m11a-sampling.html#cb302-1" tabindex="-1"></a>prop_joined</span></code></pre></div>
<pre><code># A tibble: 1,000 × 4
   replicate prop_red prop_almond prop_diff
       &lt;int&gt;    &lt;dbl&gt;       &lt;dbl&gt;     &lt;dbl&gt;
 1         1     0.24       0.45    -0.21  
 2         2     0.46       0.5     -0.0400
 3         3     0.38       0.35     0.0300
 4         4     0.36       0.433   -0.0733
 5         5     0.38       0.367    0.0133
 6         6     0.3        0.317   -0.0167
 7         7     0.42       0.383    0.0367
 8         8     0.42       0.483   -0.0633
 9         9     0.32       0.5     -0.18  
10        10     0.48       0.433    0.0467
# ℹ 990 more rows</code></pre>
<p>As we did before, we’ll build a histogram for these 1000 differences in Figure <a href="m11a-sampling.html#fig:samplingdistribution-virtual-diff-1000">33.27</a>.</p>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="m11a-sampling.html#cb304-1" tabindex="-1"></a><span class="fu">ggplot</span>(prop_joined, <span class="fu">aes</span>(<span class="at">x =</span> prop_diff)) <span class="sc">+</span></span>
<span id="cb304-2"><a href="m11a-sampling.html#cb304-2" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="fl">0.04</span>, <span class="at">boundary =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;white&quot;</span>) <span class="sc">+</span></span>
<span id="cb304-3"><a href="m11a-sampling.html#cb304-3" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Difference in sample proportions&quot;</span>, </span>
<span id="cb304-4"><a href="m11a-sampling.html#cb304-4" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;Histogram of 1000 differences in sample proportions&quot;</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:samplingdistribution-virtual-diff-1000"></span>
<img src="_main_files/figure-html/samplingdistribution-virtual-diff-1000-1.png" alt="The distribution of 1000 differences in sample proportions based on 1000 random samples of size 50 from the first bowl and 1000 random samples of size 60 from the second bowl." width="\textwidth" />
<p class="caption">
Figure 33.27: The distribution of 1000 differences in sample proportions based on 1000 random samples of size 50 from the first bowl and 1000 random samples of size 60 from the second bowl.
</p>
</div>
<p>The sampling distribution of the difference in sample proportions also looks bell-shaped and it appears to be centered at some negative value somewhere around -0.05. As it happened with a single sample proportion or a sample mean, the sampling distribution of the difference in sample proportions also follows a normal distribution and the expected difference as well as the standard error rely on information from the population and the sample size.</p>
<p>Here are the mathematical details: <span class="math inline">\(\overline X_1\)</span> is the random variable that represents the sample proportion of red balls of size <span class="math inline">\(n_1 = 50\)</span>, <span class="math inline">\(\overline X_2\)</span> is the random variable that represents the sample proportion of almonds heavier than 3.8 grams, taken from samples of size <span class="math inline">\(n_2 = 60\)</span>. The proportion of red balls the population proportion and standard deviation are given by <span class="math inline">\(p_1\)</span> and <span class="math inline">\(\sigma_1 = \sqrt{p_1(1-p_1)}\)</span> and for the almonds’ weight the population proportion and standard deviation are given by <span class="math inline">\(p_2\)</span> and <span class="math inline">\(\sigma_2 = \sqrt{p_2(1-p_2)}\)</span>.</p>
<p>The expected value and standard error of the difference, <span class="math inline">\(\overline X_1 - \overline X_2\)</span>, is given by <span class="math inline">\(p_1 - p_2\)</span> and</p>
<p><span class="math display">\[\sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}},\]</span></p>
<p>respectively. If the distributions of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are approximately normal due to the CLT, so is the distribution of <span class="math inline">\(\overline X_1 - \overline X_2\)</span>. We can write all these properties at once:</p>
<p><span class="math display">\[\overline X_1 - \overline X_2 \sim Normal \left(p_1 - p_2, \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}} \right)\]</span></p>
</div>
</div>
</div>
<div id="sampling-final-remarks" class="section level2 hasAnchor" number="33.6">
<h2><span class="header-section-number">33.6</span> Summary and final remarks<a href="m11a-sampling.html#sampling-final-remarks" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="summary-of-scenarios" class="section level3 hasAnchor" number="33.6.1">
<h3><span class="header-section-number">33.6.1</span> Summary of scenarios<a href="m11a-sampling.html#summary-of-scenarios" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>These are not the only cases where the sampling distribution can be determined. For example, when performing linear regression, we can find the sampling distribution for the slope of the regression line and the behavior will be similar to what we have described here. We will discuss inference in the context of linear regression in the future. For now, let’s look at a summary of the different scenarios presented in this chapter.</p>
<table class="table" style="font-size: 16px; color: black; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:table-ch7">Table 33.2: </span>Scenarios of sampling for inference
</caption>
<thead>
<tr>
<th style="text-align:left;">
Population parameter
</th>
<th style="text-align:left;">
Parameter Notation
</th>
<th style="text-align:left;">
Statistic
</th>
<th style="text-align:left;">
Statistic Symbol(s)
</th>
<th style="text-align:left;">
Sampling Distribution (using CLT)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 0.8in; ">
Population mean
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(\mu\)</span>
</td>
<td style="text-align:left;width: 0.8in; ">
Sample mean
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{\mu}\)</span>
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{X} \sim Normal \left(\mu, \frac{\sigma}{\sqrt n}\right)\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 0.8in; ">
Population proportion
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(p\)</span>
</td>
<td style="text-align:left;width: 0.8in; ">
Sample proportion
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(\overline{x}\)</span> or <span class="math inline">\(\widehat{p}\)</span>
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{X} \sim Normal \left(p, \sqrt{\frac{p(1-p)}{n}} \right)\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 0.8in; ">
Difference in population proportions
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(p_1 - p_2\)</span>
</td>
<td style="text-align:left;width: 0.8in; ">
Difference in sample proportions
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(\overline{x}_1 - \overline{x}_2\)</span> or <span class="math inline">\(\widehat{p}_1 - \widehat{p}_2\)</span>
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{X}_1 - \overline{X}_2\)</span> <span class="math inline">\(\sim Normal(p_1 - p_2, \sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}\)</span>
</td>
</tr>
<tr>
<td style="text-align:left;width: 0.8in; ">
Difference in population means
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(\mu_1 - \mu_2\)</span>
</td>
<td style="text-align:left;width: 0.8in; ">
Difference in sample means
</td>
<td style="text-align:left;width: 0.8in; ">
<span class="math inline">\(\overline{x}_1 - \overline{x}_2\)</span> or <span class="math inline">\(\widehat{\mu}_1 - \widehat{\mu}_2\)</span>
</td>
<td style="text-align:left;width: 1in; ">
<span class="math inline">\(\overline{X}_1 - \overline{X}_2 \sim Normal \left( \mu_1 - \mu_2, \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}} \right)\)</span>
</td>
</tr>
</tbody>
</table>
</div>
<div id="whats-to-come" class="section level3 hasAnchor" number="33.6.2">
<h3><span class="header-section-number">33.6.2</span> What’s to come?<a href="m11a-sampling.html#whats-to-come" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the next module, we will delve deeper into the concept of statistical inference, building upon the foundations we have already established in this chapter on sampling. This chapter introduces us to the idea of estimating population parameters using sample data, a key aspect of inferential statistics.</p>
<p>We will explore how to construct and interpret confidence intervals, particularly focusing on understanding what they imply about population parameters. This involves grasping the concept of a confidence level and recognizing the limitations and proper usage of confidence intervals. The chapter is designed to enhance our practical understanding through examples and applications, enabling us to apply these concepts to real-world scenarios.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>The <code>sd()</code> function actually calculates the sample standard deviation, which divides the sum of squared deviations by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>. The difference is noticeable for small numbers of values but almost irrelevant, for practical purposes, when using a large number of values. It is used here for simplicity.<a href="m11a-sampling.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>As explained earlier, this function produces the sample standard deviation, which divides the sum of square deviations by <span class="math inline">\(n-1\)</span> instead of <span class="math inline">\(n\)</span>, but for a list of 5000 observations the difference is not relevant, for practical purposes.<a href="m11a-sampling.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<script src="https://hypothes.is/embed.js" async></script>
            </section>

          </div>
        </div>
      </div>
<a href="m11u-samples-and-populations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="m11c-explore-sampling-with-your-own-data.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
